"""
Page de pr√©diction pour la version cloud avec Azure ML
"""

import os
import pandas as pd
import streamlit as st
try:
    import spacy
except ImportError:
    spacy = None
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
try:
    import seaborn as sns
except ImportError:
    sns = None
from collections import Counter
import re
try:
    import torch
except ImportError:
    torch = None
from scipy.interpolate import griddata
from azure_client import get_azure_client
# Imports supprim√©s : clients locaux non utilis√©s

# Importer le module d'accessibilit√©
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from accessibility import init_accessibility_state, render_accessibility_sidebar, apply_accessibility_styles

# Initialiser l'√©tat d'accessibilit√©
init_accessibility_state()

st.title("üîÆ Pr√©diction de Cat√©gorie")

# Configuration d'accessibilit√©
ACCESSIBLE_COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']
HIGH_CONTRAST_COLORS = ['#FFFFFF', '#FF0000', '#00FF00', '#0000FF', '#FFFF00']

# Mode de pr√©diction : Azure App Service
st.sidebar.markdown("### üîß Mode de Pr√©diction")
st.sidebar.info("üöÄ **Azure App Service (Cloud)** - Service simplifi√© compatible compte gratuit")
prediction_mode = "Azure App Service (Cloud)"

# Client Azure ML uniquement
simulated_client = None
onnx_client = None
ultra_fast_client = None
azure_client = get_azure_client(show_warning=False)

# Afficher les options d'accessibilit√© dans la sidebar
render_accessibility_sidebar()

# Appliquer les styles d'accessibilit√©
apply_accessibility_styles()

# spaCy will be handled by Azure ML ONNX API, not in the client
nlp = None
st.info("üîÑ spaCy processing will be handled by Azure ML ONNX API")

# Fonction pour charger le produit de test par d√©faut
def load_default_test_product():
    """Charge le produit de test par d√©faut (montre Escort)"""
    try:
        # Charger les donn√©es
        df = pd.read_csv('produits_original.csv')
        
        # Trouver le produit de test
        test_product_id = "1120bc768623572513df956172ffefeb"
        test_product = df[df['uniq_id'] == test_product_id]
        
        if not test_product.empty:
            product = test_product.iloc[0]
            
            # Construire le chemin de l'image
            image_filename = f"{test_product_id}.jpg"
            image_path = f"Images/{image_filename}"
            
            # V√©rifier si l'image existe
            if os.path.exists(image_path):
                return {
                    'name': product['product_name'],
                    'description': product['product_name'],  # Utiliser le nom comme description
                    'specifications': f"Prix: {product['retail_price']} INR, Cat√©gorie: {product['product_category_tree']}",
                    'image_path': image_path,
                    'image_filename': image_filename
                }
            else:
                st.warning(f"‚ö†Ô∏è Image non trouv√©e: {image_path}")
                return None
        else:
            st.warning("‚ö†Ô∏è Produit de test non trouv√© dans les donn√©es")
            return None
            
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement du produit de test: {str(e)}")
        return None

# Charger le produit de test par d√©faut
default_product = load_default_test_product()

# Lancer automatiquement la pr√©diction sur le produit de test au premier chargement
if default_product and not st.session_state.get('auto_prediction_done', False):
    st.session_state['auto_prediction_done'] = True
    st.session_state['test_prediction_launched'] = True
    st.session_state['test_product_name'] = default_product['name']
    st.session_state['test_description'] = default_product['description']
    st.session_state['test_specifications'] = default_product['specifications']
    st.session_state['test_image_path'] = default_product['image_path']

def clean_text(text):
    """Clean text using the same replacement patterns as in training."""
    if not isinstance(text, str):
        return ""
    text = text.lower()
    all_patterns = [
        (r'\(', ' ( '),
        (r'\)', ' ) '),
        (r'\.', ' . '),
        (r'\!', ' ! '),
        (r'\?', ' ? '),
        (r'\:', ' : '),
        (r'\,', ', '),
        # Baby Care
        (r'\b(\d+)\s*[-~to]?\s*(\d+)\s*(m|mth|mths|month|months?)\b', 'month'),
        (r'\bnewborn\s*[-~to]?\s*(\d+)\s*(m|mth|months?)\b', 'month'),
        (r'\b(nb|newborn|baby|bb|bby|babie|babies)\b', 'baby'),
        (r'\b(diaper|diapr|nappy)\b', 'diaper'),
        (r'\b(stroller|pram|buggy)\b', 'stroller'),
        (r'\b(bpa\s*free|non\s*bpa)\b', 'bisphenol A free'),
        (r'\b(\d+)\s*(oz|ounce)\b', 'ounce'),
        # Computer Hardware
        (r'\b(rtx\s*\d+)\b', 'ray tracing graphics'),
        (r'\b(gtx\s*\d+)\b', 'geforce graphics'),
        (r'\bnvidia\b', 'nvidia'),
        (r'\b(amd\s*radeon\s*rx\s*\d+)\b', 'amd radeon graphics'),
        (r'\b(intel\s*(core|xeon)\s*[i\d-]+)\b', 'intel processor'),
        (r'\b(amd\s*ryzen\s*[\d]+)\b', 'amd ryzen processor'),
        (r'\bssd\b', 'solid state drive'),
        (r'\bhdd\b', 'hard disk drive'),
        (r'\bwifi\s*([0-9])\b', 'wi-fi standard'),
        (r'\bbluetooth\s*(\d\.\d)\b', 'bluetooth version'),
        (r'\bethernet\b', 'ethernet'),
        (r'\bfhd\b', 'full high definition'),
        (r'\buhd\b', 'ultra high definition'),
        (r'\bqhd\b', 'quad high definition'),
        (r'\boled\b', 'organic light emitting diode'),
        (r'\bips\b', 'in-plane switching'),
        (r'\bram\b', 'random access memory'),
        (r'\bcpu\b', 'central processing unit'),
        (r'\bgpu\b', 'graphics processing unit'),
        (r'\bhdmi\b', 'high definition multimedia interface'),
        (r'\busb\s*([a-z0-9]*)\b', 'universal serial bus'),
        (r'\brgb\b', 'red green blue'),
        # Home Appliances
        (r'\bfridge\b', 'refrigerator'),
        (r'\bwashing\s*machine\b', 'clothes washer'),
        (r'\bdishwasher\b', 'dish washing machine'),
        (r'\boven\b', 'cooking oven'),
        (r'\bmicrowave\b', 'microwave oven'),
        (r'\bhoover\b', 'vacuum cleaner'),
        (r'\btumble\s*dryer\b', 'clothes dryer'),
        (r'\b(a\+)\b', 'energy efficiency class'),
        (r'\b(\d+)\s*btu\b', 'british thermal unit'),
        # Textiles and Materials
        (r'\bpoly\b', 'polyester'),
        (r'\bacrylic\b', 'acrylic fiber'),
        (r'\bnylon\b', 'nylon fiber'),
        (r'\bspandex\b', 'spandex fiber'),
        (r'\blycra\b', 'lycra fiber'),
        (r'\bpvc\b', 'polyvinyl chloride'),
        (r'\bvinyl\b', 'vinyl material'),
        (r'\bstainless\s*steel\b', 'stainless steel'),
        (r'\baluminum\b', 'aluminum metal'),
        (r'\bplexiglass\b', 'acrylic glass'),
        (r'\bpu\s*leather\b', 'polyurethane leather'),
        (r'\bsynthetic\s*leather\b', 'synthetic leather'),
        (r'\bfaux\s*leather\b', 'faux leather'),
        (r'\bwaterproof\b', 'water resistant'),
        (r'\bbreathable\b', 'air permeable'),
        (r'\bwrinkle-free\b', 'wrinkle resistant'),
        # Beauty and Personal Care
        (r'\bSPF\b', 'Sun Protection Factor'),
        (r'\bUV\b', 'Ultraviolet'),
        (r'\bBB\s*cream\b', 'Blemish Balm cream'),
        (r'\bCC\s*cream\b', 'Color Correcting cream'),
        (r'\bHA\b', 'Hyaluronic Acid'),
        (r'\bAHA\b', 'Alpha Hydroxy Acid'),
        (r'\bBHA\b', 'Beta Hydroxy Acid'),
        (r'\bPHA\b', 'Polyhydroxy Acid'),
        (r'\bNMF\b', 'Natural Moisturizing Factor'),
        (r'\bEGF\b', 'Epidermal Growth Factor'),
        (r'\bVit\s*C\b', 'Vitamin C'),
        (r'\bVit\s*E\b', 'Vitamin E'),
        (r'\bVit\s*B3\b', 'Niacinamide Vitamin B3'),
        (r'\bVit\s*B5\b', 'Panthenol Vitamin B5'),
        (r'\bSOD\b', 'Superoxide Dismutase'),
        (r'\bQ10\b', 'Coenzyme Q10'),
        (r'\bFoam\s*cl\b', 'Foam cleanser'),
        (r'\bMic\s*H2O\b', 'Micellar Water'),
        (r'\bToner\b', 'Skin toner'),
        (r'\bEssence\b', 'Skin essence'),
        (r'\bAmpoule\b', 'Concentrated serum'),
        (r'\bCF\b', 'Cruelty Free'),
        (r'\bPF\b', 'Paraben Free'),
        (r'\bSF\b', 'Sulfate Free'),
        (r'\bGF\b', 'Gluten Free'),
        (r'\bHF\b', 'Hypoallergenic Formula'),
        (r'\bNT\b', 'Non-comedogenic Tested'),
        (r'\bAM\b', 'morning'),
        (r'\bPM\b', 'night'),
        (r'\bBID\b', 'twice daily'),
        (r'\bQD\b', 'once daily'),
        (r'\bAIR\b', 'Airless pump bottle'),
        (r'\bD-C\b', 'Dropper container'),
        (r'\bT-C\b', 'Tube container'),
        (r'\bPDO\b', 'Polydioxanone'),
        (r'\bPCL\b', 'Polycaprolactone'),
        (r'\bPLLA\b', 'Poly-L-lactic Acid'),
        (r'\bHIFU\b', 'High-Intensity Focused Ultrasound'),
        (r'\b(\d+)\s*fl\s*oz\b', 'fluid ounce'),
        (r'\bpH\s*bal\b', 'pH balanced'),
        # General Abbreviations and Units
        (r'\b(\d+)\s*gb\b', 'byte'),
        (r'\b(\d+)\s*tb\b', 'byte'),
        (r'\b(\d+)\s*mb\b', 'byte'),
        (r'\b(\d+)\s*go\b', 'byte'),
        (r'\b(\d+)\s*to\b', 'byte'),
        (r'\b(\d+)\s*mo\b', 'byte'),
        (r'\boctet\b', 'byte'),
        (r'\b(\d+)\s*y\b', 'year'),
        (r'\b(\d+)\s*mth\b', 'month'),
        (r'\b(\d+)\s*d\b', 'day'),
        (r'\b(\d+)\s*h\b', 'hour'),
        (r'\b(\d+)\s*min\b', 'minute'),
        (r'\b(\d+)\s*rpm\b', 'revolution per minute'),
        (r'\b(\d+)\s*mw\b', 'watt'),
        (r'\b(\d+)\s*cw\b', 'watt'),
        (r'\b(\d+)\s*kw\b', 'watt'),
        (r'\b(\d+)\s*ma\b', 'ampere'),
        (r'\b(\d+)\s*ca\b', 'ampere'),
        (r'\b(\d+)\s*ka\b', 'ampere'),
        (r'\b(\d+)\s*mv\b', 'volt'),
        (r'\b(\d+)\s*cv\b', 'volt'),
        (r'\b(\d+)\s*kv\b', 'volt'),
        (r'\b(\d+)\s*mm\b', 'meter'),
        (r'\b(\d+)\s*cm\b', 'meter'),
        (r'\b(\d+)\s*m\b', 'meter'),
        (r'\b(\d+)\s*km\b', 'meter'),
        (r'\binch\b', 'meter'),
        (r'\b(\d+)\s*ml\b', 'liter'),
        (r'\b(\d+)\s*cl\b', 'liter'),
        (r'\b(\d+)\s*dl\b', 'liter'),
        (r'\b(\d+)\s*l\b', 'liter'),
        (r'\b(\d+)\s*oz\b', 'liter'),
        (r'\b(\d+)\s*gal\b', 'liter'),
        (r'\bounce\b', 'liter'),
        (r'\bgallon\b', 'liter'),
        (r'\b(\d+)\s*mg\b', 'gram'),
        (r'\b(\d+)\s*cg\b', 'gram'),
        (r'\b(\d+)\s*dg\b', 'gram'),
        (r'\b(\d+)\s*g\b', 'gram'),
        (r'\b(\d+)\s*kg\b', 'gram'),
        (r'\b(\d+)\s*lb\b', 'gram'),
        (r'\bpound\b', 'gram'),
        (r'\b(\d+)\s*¬∞c\b', 'celsius'),
        (r'\b(\d+)\s*¬∞f\b', 'celcius'),
        (r'\bfahrenheit\b', 'celcius'),
        (r'\bflipkart\.com\b', ''),
        (r'\bapprox\.?\b', 'approximately'),
        (r'\bw/o\b', 'without'),
        (r'\bw/\b', 'with'),
        (r'\bant-\b', 'anti'),
        (r'\byes\b', ''),
        (r'\bno\b', ''),
        (r'\bna\b', ''),
        (r'\brs\.?\b', ''),
    ]
    for pattern, replacement in all_patterns:
        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
    return text

def extract_keywords_fallback(text, top_n=15):
    """Fallback keyword extraction without spaCy."""
    import re
    from collections import Counter
    
    # Simple stopwords list
    stopwords = {
        'a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from',
        'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the',
        'to', 'was', 'will', 'with', 'this', 'these', 'they', 'them',
        'their', 'there', 'then', 'than', 'or', 'but', 'if', 'when',
        'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few',
        'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',
        'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can',
        'could', 'should', 'would', 'may', 'might', 'must', 'shall'
    }
    
    # Clean and tokenize text
    text = re.sub(r'[^\w\s]', ' ', text.lower())
    words = text.split()
    
    # Filter out stopwords and short words
    keywords = [word for word in words if len(word) > 2 and word not in stopwords]
    
    # Count and return top keywords
    word_counts = Counter(keywords)
    return [word for word, count in word_counts.most_common(top_n)]

def extract_keywords(text, nlp, top_n=15):
    """Extract keywords from text using lemmatization and stopword removal."""
    if pd.isna(text) or text == '':
        return []
    # Clean text before processing
    text = clean_text(text)
    
    # If spaCy is not available, use simple text processing
    if nlp is None:
        return extract_keywords_fallback(text, top_n)
    
    try:
        doc = nlp(text)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Error processing text with spaCy: {str(e)}")
        return extract_keywords_fallback(text, top_n)
    keywords = []
    for token in doc:
        lemma = token.lemma_.lower().strip()
        if (len(lemma) < 2 or token.is_punct or not lemma or token.is_stop or
            token.text.isdigit() or
            re.match(r'^[\d.,]+$', token.text) or
            re.match(r'^[\d.,]+\s*[a-zA-Z%]+$', token.text) or
            re.match(r'^-[0-9]+$', token.text) or
            (re.match(r'^[A-Z0-9]+(?:[-_][A-Z0-9]+)*$', token.text, re.IGNORECASE) and
             (re.search(r'\d', token.text) and re.search(r'[a-zA-Z]', token.text)) or
             re.match(r'^[A-Z0-9]+$', token.text))):
            continue
        keywords.append(lemma)
    keyword_counts = Counter(keywords)
    return [word for word, count in keyword_counts.most_common(top_n)]

st.header("Entr√©e des Donn√©es du Produit")

# Section pour le produit de test par d√©faut
if default_product:
    st.info("üéØ **Produit de test charg√© automatiquement** - Montre Escort E-1700-906")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.write(f"**Nom:** {default_product['name']}")
        st.write(f"**Description:** {default_product['description']}")
        st.write(f"**Sp√©cifications:** {default_product['specifications']}")
    
    with col2:
        if os.path.exists(default_product['image_path']):
            st.image(default_product['image_path'], caption="Image du produit de test", width=200)
        else:
            st.warning("Image non trouv√©e")
    
    # Bouton pour lancer la pr√©diction sur le produit de test
    if st.button("üöÄ Lancer la pr√©diction sur le produit de test", type="primary", key="test_prediction_btn"):
        # Simuler les donn√©es du formulaire
        product_name = default_product['name']
        description = default_product['description']
        specifications = default_product['specifications']
        uploaded_image = default_product['image_path']
        
        # Stocker dans session state pour √©viter la re-ex√©cution
        st.session_state['test_prediction_launched'] = True
        st.session_state['test_product_name'] = product_name
        st.session_state['test_description'] = description
        st.session_state['test_specifications'] = specifications
        st.session_state['test_image_path'] = uploaded_image
        
        st.rerun()

st.divider()

# Formulaire manuel
st.subheader("Ou saisir manuellement un produit")
product_name = st.text_input("Nom du Produit", placeholder="Exemple : Montre pour homme", 
                            help="Saisissez le nom complet du produit", key="product_name_input",
                            label_visibility="visible")
description = st.text_area("Description", placeholder="Exemple : Une montre √©l√©gante en cuir noir pour homme",
                          help="D√©crivez le produit en d√©tail", key="description_input",
                          label_visibility="visible")
specifications = st.text_area("Sp√©cifications Techniques", placeholder="Exemple : R√©sistant √† l'eau, affichage analogique",
                             help="Listez les sp√©cifications techniques importantes", key="specifications_input",
                             label_visibility="visible")
uploaded_image = st.file_uploader("T√©l√©charger une Image du Produit", type=['jpg', 'png', 'jpeg'],
                                 help="Image du produit √† analyser", key="image_uploader",
                                 label_visibility="visible")

# Ajouter des labels ARIA pour l'accessibilit√©
st.markdown("""
<div role="region" aria-label="Formulaire de pr√©diction de produit">
""", unsafe_allow_html=True)

# V√©rifier si une pr√©diction de test a √©t√© lanc√©e
if st.session_state.get('test_prediction_launched', False):
    # Utiliser les donn√©es du produit de test
    product_name = st.session_state.get('test_product_name', '')
    description = st.session_state.get('test_description', '')
    specifications = st.session_state.get('test_specifications', '')
    uploaded_image = st.session_state.get('test_image_path', '')
    
    # R√©initialiser le flag
    st.session_state['test_prediction_launched'] = False
    
    # Afficher les informations du produit de test
    st.success("üéØ **Pr√©diction lanc√©e sur le produit de test**")
    st.write(f"**Produit analys√©:** {product_name}")
    
    if os.path.exists(uploaded_image):
        st.image(uploaded_image, caption="Image du produit de test", width=200)
    else:
        st.error(f"‚ùå Image non trouv√©e: {uploaded_image}")
        st.stop()
    
    # Lancer la pr√©diction
    prediction_launched = True
else:
    # Logique normale pour le formulaire manuel
    prediction_launched = st.button("Pr√©dire", key="predict_button", help="Lancer la pr√©diction de cat√©gorie", type="primary")
    
    if prediction_launched:
        if not (uploaded_image and product_name and description and specifications):
            st.error("Veuillez fournir un nom de produit, une description, des sp√©cifications techniques et une image.")
            st.stop()
        
        st.image(uploaded_image, caption="Image T√©l√©charg√©e", width=200)
        st.caption(f"Image analys√©e: {product_name}")

# Lancer la pr√©diction si demand√©e
if prediction_launched:
    
    # Extract keywords
    combined_text = f"{description} {specifications}"
    combined_text = clean_text(combined_text)
    keywords = extract_keywords(combined_text, nlp)
    if not keywords:
        st.error("Aucun mot-cl√© extrait. Veuillez fournir une description et des sp√©cifications plus d√©taill√©es.")
        st.stop()
    
    st.write(f"**Mots-cl√©s extraits :** {', '.join(keywords)}")
    
    # Pr√©diction via le client appropri√©
    if azure_client:
        with st.spinner("üîÑ Pr√©diction en cours via le mod√®le fine-tun√© ONNX..."):
            # G√©rer √† la fois les fichiers upload√©s et les chemins d'images
            if isinstance(uploaded_image, str):
                # C'est un chemin d'image (produit de test)
                image = Image.open(uploaded_image)
            else:
                # C'est un fichier upload√©
                image = Image.open(uploaded_image)
            
            text_description = f"{product_name} {description} {specifications}"
            
            # R√©cup√©rer les mots-cl√©s du produit si c'est le produit de test
            product_keywords = None
            if hasattr(st.session_state, 'test_product_name') and st.session_state.test_product_name:
                try:
                    df = pd.read_csv('produits_original.csv')
                    product_row = df[df['uniq_id'] == '1120bc768623572513df956172ffefeb']
                    if not product_row.empty:
                        product_keywords = product_row['keywords'].iloc[0]
                        st.write(f"üîç Utilisation des mots-cl√©s du CSV pour la pr√©diction: {product_keywords}")
                except Exception as e:
                    st.write(f"‚ö†Ô∏è Impossible de charger les mots-cl√©s du CSV: {e}")
            
        # Pr√©diction avec Azure ML ONNX uniquement (LOGIQUE IDENTIQUE AU NOTEBOOK)
        result = azure_client.predict_category(image, text_description, product_keywords)
        
        # G√©n√©rer l'interpr√©tabilit√© ONNX (100% cloud)
        if azure_client.is_onnx and not azure_client.use_simulated:
            with st.spinner("üîÑ G√©n√©ration de l'interpr√©tabilit√© ONNX..."):
                attention_result = azure_client.generate_attention_heatmap(image, text_description, product_keywords)
                if attention_result:
                    result['attention_result'] = attention_result
                    st.success("‚úÖ Interpr√©tabilit√© ONNX g√©n√©r√©e avec succ√®s")
                else:
                    st.warning("‚ö†Ô∏è Interpr√©tabilit√© ONNX non disponible")
        else:
            st.info("‚ÑπÔ∏è **Configuration requise** - Pour utiliser l'interpr√©tabilit√© ONNX, configurez un endpoint Azure ML ONNX valide")
            st.info("üí° **Solution** : Remplacez l'endpoint par d√©faut par votre vrai endpoint Azure ML ONNX dans la configuration")
    elif azure_client:
        with st.spinner("üîÑ Pr√©diction en cours via Azure ML ONNX..."):
            # G√©rer √† la fois les fichiers upload√©s et les chemins d'images
            if isinstance(uploaded_image, str):
                # C'est un chemin d'image (produit de test)
                image = Image.open(uploaded_image)
            else:
                # C'est un fichier upload√©
                image = Image.open(uploaded_image)
            
            text_description = f"{product_name} {description} {specifications}"
            
            result = azure_client.predict_category(image, text_description)
    else:
        st.error("‚ùå Aucun client de pr√©diction disponible. Veuillez v√©rifier la configuration.")
        st.stop()
    
    if result['success']:
        st.header("R√©sultats de la Pr√©diction")
        st.write(f"**Mots-cl√©s analys√©s :** {', '.join(keywords)}")
        st.write(f"**Cat√©gorie pr√©dite :** {result['predicted_category']}")
        st.write(f"**Confiance :** {result['confidence']:.3f}")
        st.write(f"**Source :** {result['source']}")
        
        # Afficher les scores de toutes les cat√©gories
        st.subheader("Scores de Toutes les Cat√©gories")
        category_data = []
        
        # G√©rer les diff√©rentes structures de donn√©es
        if 'category_scores' in result:
            scores_dict = result['category_scores']
        elif 'all_scores' in result:
            # Convertir all_scores en dictionnaire avec les cat√©gories
            categories = result.get('categories', [
                "Baby Care", "Beauty and Personal Care", "Computers", 
                "Home Decor & Festive Needs", "Home Furnishing", 
                "Kitchen & Dining", "Watches"
            ])
            scores_dict = dict(zip(categories, result['all_scores']))
        else:
            st.error("‚ùå Aucun score de cat√©gorie disponible")
            scores_dict = {}
        
        for category, score in scores_dict.items():
            category_data.append({"Cat√©gorie": category, "Score": f"{score:.4f}"})
        st.table(category_data)
        
        # Graphique des scores
        st.subheader("Visualisation des Scores")
        
        # Configuration des couleurs selon le mode d'accessibilit√©
        if st.session_state.accessibility.get('color_blind', False):
            palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']
        elif st.session_state.accessibility.get('high_contrast', False):
            palette = HIGH_CONTRAST_COLORS
        else:
            palette = ACCESSIBLE_COLORS
        
        fig, ax = plt.subplots(figsize=(12, 8))
        categories = list(result['category_scores'].keys())
        scores = list(result['category_scores'].values())
        
        bars = ax.barh(categories, scores, color=palette[:len(categories)])
        
        # Ajouter des motifs pour le mode daltonien
        if st.session_state.accessibility.get('color_blind', False):
            patterns = ['/', '\\', '|', '-', '+', 'x', 'o', '.', '*']
            for i, bar in enumerate(bars):
                bar.set_hatch(patterns[i % len(patterns)])
        
        ax.set_title(f"Scores de Classification - {product_name[:50]}...", 
                     fontsize=16 if not st.session_state.accessibility.get('large_text', False) else 20, 
                     pad=20)
        ax.set_xlabel("Score de probabilit√©", fontsize=14 if not st.session_state.accessibility.get('large_text', False) else 18)
        ax.set_ylabel("Cat√©gories", fontsize=14 if not st.session_state.accessibility.get('large_text', False) else 18)
        ax.invert_yaxis()
        
        # Appliquer les styles d'accessibilit√© aux graphiques
        if st.session_state.accessibility.get('high_contrast', False):
            ax.set_facecolor('black')
            fig.set_facecolor('black')
            ax.tick_params(colors='white')
            ax.xaxis.label.set_color('white')
            ax.yaxis.label.set_color('white')
            ax.set_title(ax.get_title(), color='white')
        
        # Ajouter les valeurs sur les barres
        for i, (category, score) in enumerate(zip(categories, scores)):
            ax.text(score + 0.01, i, f'{score:.3f}', va='center', ha='left', 
                    fontsize=12 if not st.session_state.accessibility.get('large_text', False) else 16)
        
        ax.grid(axis='x', alpha=0.3)
        plt.tight_layout()
        
        # Corriger l'erreur matplotlib en utilisant fig au lieu de plt
        st.pyplot(fig, use_container_width=True)
        
        # Heatmap des scores (simulation)
        st.subheader("Heatmap des Scores de Classification")
        
        # Cr√©er une matrice pour la heatmap
        categories = list(result['category_scores'].keys())
        scores = list(result['category_scores'].values())
        
        # Cr√©er une matrice 1D pour la heatmap
        score_matrix = np.array(scores).reshape(1, -1)
        
        fig, ax = plt.subplots(figsize=(12, 4))
        
        # G√©n√©rer la heatmap
        if sns is not None:
            # Utiliser seaborn si disponible
            sns.heatmap(score_matrix, 
                       xticklabels=categories,
                       yticklabels=['Scores'],
                       annot=True, 
                       fmt='.3f',
                       cmap='RdYlBu_r' if not st.session_state.accessibility.get('color_blind', False) else 'viridis',
                       cbar_kws={'label': 'Score de probabilit√©'},
                       ax=ax)
        else:
            # Fallback avec matplotlib
            im = ax.imshow(score_matrix, cmap='RdYlBu_r' if not st.session_state.accessibility.get('color_blind', False) else 'viridis', aspect='auto')
            ax.set_xticks(range(len(categories)))
            ax.set_xticklabels(categories, rotation=45, ha='right')
            ax.set_yticks([0])
            ax.set_yticklabels(['Scores'])
            plt.colorbar(im, label='Score de probabilit√©', ax=ax)
            
            # Ajouter les annotations
            for i in range(len(categories)):
                ax.text(i, 0, f'{scores[i]:.3f}', ha='center', va='center', 
                        color='white' if scores[i] > 0.5 else 'black', fontweight='bold')
        
        ax.set_title(f"Heatmap des Scores - {product_name[:50]}...", 
                     fontsize=16 if not st.session_state.accessibility.get('large_text', False) else 20, 
                     pad=20)
        plt.tight_layout()
        
        # Corriger l'erreur matplotlib en utilisant fig au lieu de plt
        st.pyplot(fig, use_container_width=True)
        
        # Section Interpr√©tabilit√© des Mots-cl√©s (avant la heatmap d'image)
        if uploaded_image:
            # Charger l'image pour l'analyse des mots-cl√©s
            if isinstance(uploaded_image, str):
                # C'est un chemin d'image (produit de test)
                image = Image.open(uploaded_image)
            else:
                # C'est un fichier upload√©
                image = Image.open(uploaded_image)
            
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # G√©n√©rer l'analyse des mots-cl√©s selon le mode
            if azure_client:
                # G√©n√©rer seulement les scores de mots-cl√©s (plus rapide)
                with st.spinner("üîÑ Calcul des scores de similarit√© des mots-cl√©s..."):
                    # Utiliser les mots-cl√©s du CSV si disponibles, sinon extraire de la description
                    if product_keywords:
                        keywords = [kw.strip() for kw in product_keywords.split(',') if kw.strip()]
                        st.write(f"üîç Utilisation des mots-cl√©s du CSV: {', '.join(keywords)}")
                    else:
                        # Fallback: extraction simple des mots-cl√©s
                        import re
                        from collections import Counter
                        
                        # Nettoyer le texte
                        cleaned_text = re.sub(r'[^\w\s]', ' ', text_description.lower())
                        words = re.findall(r'\b[a-zA-Z]{2,}\b', cleaned_text)
                        
                        # Stopwords simples
                        stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
                                   'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',
                                   'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those'}
                        
                        keywords = [word for word in words if word not in stopwords and len(word) > 2]
                        keyword_counts = Counter(keywords)
                        keywords = [word for word, count in keyword_counts.most_common(10)]
                        st.write(f"üîç Mots-cl√©s extraits: {', '.join(keywords)}")
                    
                     if keywords:
                         # Utiliser les vraies donn√©es d'interpr√©tabilit√© du backend Azure
                         attention_result = result.get('attention_result')
                         if attention_result:
                             st.info("‚úÖ **Vraies donn√©es d'interpr√©tabilit√© ONNX** - Scores calcul√©s par le mod√®le CLIP fine-tun√© d√©ploy√© sur Azure ML")
                         else:
                             st.info("‚ÑπÔ∏è **Configuration requise** - Pour utiliser l'interpr√©tabilit√© ONNX, configurez un endpoint Azure ML ONNX valide")
                             st.info("üí° **Solution** : Remplacez l'endpoint par d√©faut par votre vrai endpoint Azure ML ONNX dans la configuration")
                             attention_result = None
                
                # Afficher les scores de similarit√© des mots-cl√©s (seulement si disponibles)
                if attention_result and attention_result is not None and 'keyword_similarities' in attention_result:
                    st.subheader("üìä Interpr√©tabilit√© des Mots-cl√©s")
                    
                    # Cr√©er le diagramme en barres des scores de similarit√© (version optimis√©e)
                    keywords_list = list(attention_result['keyword_similarities'].keys())
                    scores_list = list(attention_result['keyword_similarities'].values())
                    
                    # Trier par score d√©croissant et limiter √† 10 mots-cl√©s max pour la vitesse
                    sorted_data = sorted(zip(keywords_list, scores_list), key=lambda x: x[1], reverse=True)[:10]
                    keywords_list, scores_list = zip(*sorted_data)
                    
                    # Version optimis√©e : utiliser Streamlit native au lieu de matplotlib/seaborn
                    if len(keywords_list) > 0:
                        # Cr√©er un DataFrame pour st.bar_chart (plus rapide)
                        import pandas as pd
                        chart_data = pd.DataFrame({
                            'Mots-cl√©s': keywords_list,
                            'Score': scores_list
                        })
                        
                        # Utiliser st.bar_chart (plus rapide que matplotlib)
                        st.bar_chart(chart_data.set_index('Mots-cl√©s'), use_container_width=True)
                        
                        # Ajouter un tableau des scores pour plus de d√©tails
                        st.write("**D√©tails des scores :**")
                        score_df = pd.DataFrame({
                            'Mot-cl√©': keywords_list,
                            'Score': [f"{score:.3f}" for score in scores_list],
                            'Importance': ['üî¥ Tr√®s √©lev√©' if score > 0.7 else 'üü° √âlev√©' if score > 0.4 else 'üü¢ Mod√©r√©' for score in scores_list]
                        })
                        st.dataframe(score_df, use_container_width=True, hide_index=True)
                        
                        # Description textuelle pour les non-voyants
                        st.write("**Description des scores de similarit√© :**")
                        max_score = max(scores_list)
                        min_score = min(scores_list)
                        top_keyword = keywords_list[0]
                        st.write(f"""
                        - Les scores de similarit√© montrent l'importance de chaque mot-cl√© pour la pr√©diction
                        - Score maximum: {max_score:.3f} (mot-cl√©: {top_keyword})
                        - Score minimum: {min_score:.3f}
                        - Les mots-cl√©s avec des scores √©lev√©s sont plus influents dans la d√©cision du mod√®le
                         - **Note:** Ces scores sont calcul√©s par le vrai mod√®le CLIP fine-tun√© ONNX d√©ploy√© sur Azure ML.
                        """)
            else:
                # Service Azure App Service simplifi√© - pas de scores de similarit√©
                st.info("‚ÑπÔ∏è **Service Azure App Service simplifi√©** - Les scores de similarit√© des mots-cl√©s ne sont pas disponibles dans cette version.")
                st.info("üí° **Pourquoi ?** Cette version utilise un service simplifi√© compatible avec le compte Azure gratuit, qui se concentre sur la classification bas√©e sur le texte.")
                # Mode d√©mo - scores simul√©s
                st.subheader("üìä Interpr√©tabilit√© des Mots-cl√©s (Mode D√©mo)")
                
                # Extraire les mots-cl√©s du texte (version optimis√©e)
                keywords = text_description.lower().split()
                keywords = [kw for kw in keywords if len(kw) > 2 and kw.isalpha()][:8]  # Limiter √† 8 mots-cl√©s pour la vitesse
                
                if keywords:
                    # Cr√©er des scores simul√©s bas√©s sur la cat√©gorie pr√©dite (version optimis√©e)
                    keyword_similarities = {}
                    for keyword in keywords:
                        # Score de base al√©atoire
                        base_score = np.random.random() * 0.3
                        
                        # Bonus selon la cat√©gorie pr√©dite
                        if predicted_category == "Watches" and any(w in keyword for w in ['watch', 'time', 'clock', 'hour', 'minute']):
                            base_score += 0.4
                        elif predicted_category == "Computers" and any(w in keyword for w in ['computer', 'laptop', 'screen', 'keyboard']):
                            base_score += 0.4
                        elif predicted_category == "Beauty and Personal Care" and any(w in keyword for w in ['beauty', 'care', 'skin', 'cream']):
                            base_score += 0.4
                        
                        keyword_similarities[keyword] = min(base_score, 1.0)
                    
                    # Trier par score d√©croissant
                    sorted_keywords = sorted(keyword_similarities.items(), key=lambda x: x[1], reverse=True)
                    keywords_list, scores_list = zip(*sorted_keywords)
                    
                    # Version optimis√©e : utiliser Streamlit native au lieu de matplotlib/seaborn
                    import pandas as pd
                    chart_data = pd.DataFrame({
                        'Mots-cl√©s': keywords_list,
                        'Score': scores_list
                    })
                    
                    # Utiliser st.bar_chart (plus rapide que matplotlib)
                    st.bar_chart(chart_data.set_index('Mots-cl√©s'), use_container_width=True)
                    
                    # Ajouter un tableau des scores pour plus de d√©tails
                    st.write("**D√©tails des scores (Mode D√©mo) :**")
                    score_df = pd.DataFrame({
                        'Mot-cl√©': keywords_list,
                        'Score': [f"{score:.3f}" for score in scores_list],
                        'Importance': ['üî¥ Tr√®s √©lev√©' if score > 0.7 else 'üü° √âlev√©' if score > 0.4 else 'üü¢ Mod√©r√©' for score in scores_list]
                    })
                    st.dataframe(score_df, use_container_width=True, hide_index=True)
                    
                    # Description textuelle pour les non-voyants
                    st.write("**Description des scores de similarit√© (Mode D√©mo) :**")
                    max_score = max(scores_list)
                    min_score = min(scores_list)
                    top_keyword = keywords_list[0]
                    st.write(f"""
                    - Les scores de similarit√© montrent l'importance simul√©e de chaque mot-cl√© pour la pr√©diction
                    - Score maximum: {max_score:.3f} (mot-cl√©: {top_keyword})
                    - Score minimum: {min_score:.3f}
                    - **Note:** Ces scores sont simul√©s pour le mode d√©monstration. En mode production Azure ML, ils seraient calcul√©s par le vrai mod√®le.
                    """)
                else:
                    st.info("‚ÑπÔ∏è Aucun mot-cl√© significatif trouv√© dans la description pour l'analyse de similarit√©.")
        
        # Heatmap d'attention sur l'image
        if uploaded_image:
            if azure_client:
                st.subheader("Interpr√©tabilit√© Image (Heatmap d'Attention CLIP)")
            else:
                st.subheader("Interpr√©tabilit√© Image (Heatmap d'Attention Simul√©e)")
            
             # V√©rifier si on a les vraies donn√©es d'interpr√©tabilit√©
             attention_result = result.get('attention_result')
             if attention_result and 'heatmap' in attention_result:
                 st.info("‚úÖ **Vraie heatmap d'attention ONNX** - G√©n√©r√©e par le mod√®le CLIP fine-tun√©")
             else:
                 st.info("‚ÑπÔ∏è **Service Azure App Service simplifi√©** - Les heatmaps d'attention ne sont pas disponibles dans cette version.")
                 st.info("üí° **Pourquoi ?** Cette version utilise un service simplifi√© compatible avec le compte Azure gratuit, qui se concentre sur la classification bas√©e sur le texte.")
            
            # Charger l'image
            if isinstance(uploaded_image, str):
                # C'est un chemin d'image (produit de test)
                image = Image.open(uploaded_image)
            else:
                # C'est un fichier upload√©
                image = Image.open(uploaded_image)
            
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # G√©n√©rer la heatmap d'attention selon le mode
            if azure_client:
                # Option pour activer/d√©sactiver la heatmap d'attention
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.write("**Options d'analyse avanc√©e :**")
                with col2:
                    generate_heatmap = st.checkbox("G√©n√©rer heatmap d'attention", value=True, help="D√©sactiver pour acc√©l√©rer l'analyse")
                
                attention_result = None
                if generate_heatmap:
                    # Chronom√®tre pour la g√©n√©ration de heatmap
                    import time
                    start_time = time.time()
                    
                    # Barre de progression et statut
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # Fonction de callback pour la progression
                    def update_progress(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    status_text.text("üîÑ G√©n√©ration de la heatmap d'attention CLIP (version ultra-rapide)...")
                    progress_bar.progress(5)
                    
                    # R√©cup√©rer les mots-cl√©s du produit si c'est le produit de test
                    product_keywords = None
                    if hasattr(st.session_state, 'test_product_name') and st.session_state.test_product_name:
                        try:
                            df = pd.read_csv('produits_original.csv')
                            product_row = df[df['uniq_id'] == '1120bc768623572513df956172ffefeb']
                            if not product_row.empty:
                                product_keywords = product_row['keywords'].iloc[0]
                                st.write(f"üîç Utilisation des mots-cl√©s du CSV: {product_keywords}")
                        except Exception as e:
                            st.write(f"‚ö†Ô∏è Impossible de charger les mots-cl√©s du CSV: {e}")
                    
         # Utiliser les vraies donn√©es d'interpr√©tabilit√© si disponibles
         if attention_result and 'heatmap' in attention_result:
             st.info("‚úÖ **G√©n√©ration de la vraie heatmap d'attention ONNX**")
         else:
             st.info("‚ÑπÔ∏è Service Azure App Service simplifi√© - Pas de heatmap d'attention disponible")
             attention_result = None
        
        # Calcul du temps √©coul√©
        end_time = time.time()
        generation_time = end_time - start_time
        
        # Mise √† jour de la barre de progression
        progress_bar.progress(100)
        status_text.text(f"‚úÖ Heatmap g√©n√©r√©e en {generation_time:.2f} secondes")
        
        # Service simplifi√© - pas de heatmap
        st.info("‚ÑπÔ∏è **Service Azure App Service simplifi√©** - Classification bas√©e sur le texte uniquement")
        
        if attention_result and attention_result is not None and 'heatmap' in attention_result:
            # Utiliser la vraie heatmap d'attention
            attention_map = attention_result  # Passer tout l'objet attention_result
            image_array = np.array(image.convert('L'))
            
            # Description textuelle pour les non-voyants
            st.write("**Description de l'analyse d'attention :**")
            heatmap_data = np.array(attention_map['heatmap'])
            max_attention = np.max(heatmap_data)
            min_attention = np.min(heatmap_data)
            keywords_list = attention_map.get('keywords', [])
            st.write(f"""
            - La heatmap superpos√©e montre les zones de l'image o√π le mod√®le CLIP se concentre pour faire sa pr√©diction
            - Intensit√© d'attention maximale: {max_attention:.3f}
            - Intensit√© d'attention minimale: {min_attention:.3f}
            - Les zones les plus claires indiquent une attention plus forte
            - **Note:** Cette heatmap est g√©n√©r√©e par le vrai mod√®le CLIP fine-tun√© ONNX.
            - Mots-cl√©s analys√©s: {', '.join(keywords_list)}
            """)
        else:
            st.warning("‚ö†Ô∏è Impossible de g√©n√©rer la heatmap d'attention")
            attention_map = None
            # Cr√©er une heatmap d'attention simul√©e pour le mode Azure ML
            # Convertir en niveaux de gris pour l'affichage
            image_gray = image.convert('L')
            image_array = np.array(image_gray)
            
            # Simuler une carte d'attention bas√©e sur la cat√©gorie pr√©dite
            height, width = image_array.shape
            
            # Cr√©er une attention map simul√©e
            # Pour les montres, concentrer l'attention sur le centre (cadran)
            if result['predicted_category'] == 'Watches':
                # Cr√©er une attention concentr√©e sur le centre (cadran de montre)
                y, x = np.ogrid[:height, :width]
                center_y, center_x = height // 2, width // 2
                sigma = min(height, width) // 4
                attention_map = np.exp(-((x - center_x)**2 + (y - center_y)**2) / (2 * sigma**2))
            elif result['predicted_category'] == 'Computers':
                # Pour les ordinateurs, attention sur les bords (√©cran, clavier)
                y, x = np.ogrid[:height, :width]
                attention_map = np.zeros((height, width))
                # Attention sur les bords
                attention_map[0:height//4, :] = 0.8  # Haut
                attention_map[3*height//4:, :] = 0.8  # Bas
                attention_map[:, 0:width//4] = 0.6  # Gauche
                attention_map[:, 3*width//4:] = 0.6  # Droite
            else:
                # Pour les autres cat√©gories, attention uniforme avec quelques zones d'int√©r√™t
                attention_map = np.random.rand(height, width) * 0.3
                # Ajouter quelques zones d'attention
                for _ in range(3):
                    center_y = np.random.randint(height//4, 3*height//4)
                    center_x = np.random.randint(width//4, 3*width//4)
                    sigma = min(height, width) // 8
                    y, x = np.ogrid[:height, :width]
                    attention_map += 0.4 * np.exp(-((x - center_x)**2 + (y - center_y)**2) / (2 * sigma**2))
                attention_map = np.clip(attention_map, 0, 1)
            
            # Normaliser l'attention map
            attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min() + 1e-8)
        
        # Message si la heatmap n'est pas g√©n√©r√©e
        if attention_map is None and azure_client:
            st.info("‚ÑπÔ∏è Heatmap d'attention non g√©n√©r√©e (option d√©sactiv√©e pour acc√©l√©rer l'analyse)")
        
        # Afficher la heatmap si elle existe
        if attention_map is not None:
            # Copier exactement le code du notebook
            # Utiliser smooth_heatmap si disponible (comme dans le notebook)
            if isinstance(attention_map, dict) and 'heatmap' in attention_map:
                smooth_heatmap = attention_map['heatmap']
                attention_scores = attention_map.get('attention_scores', np.array([]))
                keywords = attention_map.get('keywords', [])
                positions = attention_map.get('positions', [])
            else:
                smooth_heatmap = attention_map
                attention_scores = np.array([])
                keywords = []
                positions = []
            
            height, width = smooth_heatmap.shape
            # Utiliser les dimensions de l'image originale (comme dans le notebook)
            if hasattr(image, 'size'):
                img_width, img_height = image.size
            else:
                img_width, img_height = width, height
            
            # Convertir l'image en noir et blanc (exactement comme dans le notebook)
            from PIL import ImageEnhance
            # Convertir l'image PIL en noir et blanc avec am√©lioration du contraste
            if hasattr(image, 'convert'):  # Si c'est une image PIL
                img_bw = image.convert('L')
                enhancer = ImageEnhance.Contrast(img_bw)
                img_bw = enhancer.enhance(1.5)
                img_bw = np.array(img_bw)
            else:  # Si c'est un array numpy
                if len(image_array.shape) == 3:
                    img_bw = np.mean(image_array, axis=2)
                else:
                    img_bw = image_array
            
            # Cr√©er la figure exactement comme dans le notebook (plt.figure, pas subplots)
            plt.figure(figsize=(16, 10))
            
            # Afficher l'image en noir et blanc (exactement comme dans le notebook)
            plt.imshow(img_bw, cmap='gray', vmin=0, vmax=255)
            
            # Superposer la heatmap d'attention (exactement comme dans le notebook)
            heatmap_layer = plt.imshow(smooth_heatmap.T, cmap='inferno', alpha=0.55,  # Transpose heatmap
                                    extent=[0, img_width, img_height, 0], interpolation='bicubic')
            
            # Ajouter les points et textes pour les mots-cl√©s (comme dans le notebook)
            if len(keywords) > 0 and len(attention_scores) > 0 and len(positions) > 0:
                # Debug: afficher les informations
                st.write(f"üîç Debug: {len(keywords)} mots-cl√©s, {attention_scores.shape} scores, {len(positions)} positions")
                
                # Top 3 mots-cl√©s comme dans le notebook
                top_keywords = sorted(zip(keywords, attention_scores.mean(axis=0)), key=lambda x: x[1], reverse=True)[:3]
                st.write(f"üîç Top keywords: {top_keywords}")
                
                for kw, score in top_keywords:
                    kw_idx = keywords.index(kw)
                    max_pos_idx = np.argmax(attention_scores[:, kw_idx])
                    max_pos = positions[max_pos_idx]
                    st.write(f"üîç Mot-cl√©: {kw}, Position: {max_pos}, Score: {score:.3f}")
                    plt.scatter(max_pos[0], max_pos[1], s=300, edgecolors='white', linewidths=2, facecolors='none')
                    plt.text(max_pos[0], max_pos[1]+img_height*0.03, f"{kw}\n({score:.2f})",
                           color='white', ha='center', va='top', fontsize=11,
                           bbox=dict(facecolor='black', alpha=0.7, boxstyle='round,pad=0.5', edgecolor='white', linewidth=1))
            else:
                st.write(f"üîç Debug: Pas de mots-cl√©s - keywords: {len(keywords)}, scores: {len(attention_scores)}, positions: {len(positions)}")
            
            # Ajouter la colorbar (exactement comme dans le notebook)
            cbar = plt.colorbar(heatmap_layer, fraction=0.03, pad=0.01)
            cbar.set_label('Intensit√© d\'attention', rotation=270, labelpad=15)
            
            # Titre (comme dans le notebook)
            if azure_client:
                plt.title("Heatmap d'attention CLIP (Fine-Tun√©)", pad=20, fontsize=12)
            else:
                plt.title("Heatmap d'Attention Simul√©e", pad=20, fontsize=12)
            
            # D√©sactiver les axes (exactement comme dans le notebook)
            plt.axis('off')
            
            plt.tight_layout()
            st.pyplot(plt, use_container_width=True)
        
        # Description textuelle pour les non-voyants (seulement pour le mode simul√©)
        if not azure_client:
            st.write("**Description de l'analyse d'attention :**")
            max_attention = np.max(attention_map)
            min_attention = np.min(attention_map)
            st.write(f"""
            - La heatmap superpos√©e montre les zones de l'image o√π le mod√®le se concentre pour faire sa pr√©diction
            - Intensit√© d'attention maximale: {max_attention:.3f}
            - Intensit√© d'attention minimale: {min_attention:.3f}
            - Les zones les plus claires indiquent une attention plus forte
            - **Note:** Cette heatmap est simul√©e pour le mode d√©monstration. En mode production avec Azure ML, vous obtiendriez la vraie analyse d'attention CLIP.
            """)
        
    else:
        st.error(f"‚ùå Erreur lors de la pr√©diction: {result['error']}")
        
        # Messages d'aide sp√©cifiques selon le type d'erreur
        if 'timeout' in result['error'].lower():
            st.warning("‚è±Ô∏è **Probl√®me de timeout d√©tect√©**")
            st.info("üí° **Solutions possibles :**")
            st.info("‚Ä¢ L'endpoint Azure ML n'est pas disponible ou ne r√©pond pas")
            st.info("‚Ä¢ Le service est surcharg√© ou en maintenance")
            st.info("‚Ä¢ V√©rifiez la configuration de l'endpoint dans les secrets")
            st.info("‚Ä¢ Utilisez le mode d√©monstration pour tester l'application")
        elif '503' in result['error'] or 'application error' in result['error'].lower():
            st.warning("üö´ **Service Azure ML indisponible (503)**")
            st.info("üí° **Solutions possibles :**")
            st.info("‚Ä¢ Le service Azure ML est en maintenance ou surcharg√©")
            st.info("‚Ä¢ L'application Azure a des probl√®mes de ressources")
            st.info("‚Ä¢ Le syst√®me bascule automatiquement vers le mode simul√©")
            st.info("‚Ä¢ Contactez l'administrateur du service Azure ML")
        else:
            st.info("üí° V√©rifiez la configuration de l'API Azure ML.")

st.markdown("</div>", unsafe_allow_html=True)
