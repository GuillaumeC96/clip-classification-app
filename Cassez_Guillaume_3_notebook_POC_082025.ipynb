{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "799041a5"
      },
      "source": [
        "# 1. Configuration Initiale et Chargement des Modèles\n",
        "Objectif : Cette cellule configure l'environnement et charge les modèles nécessaires (CLIP et spaCy) pour l'analyse multimodale.\n",
        "Description : Configure les variables d'environnement pour la reproductibilité (graines aléatoires, déterminisme CUDA). Initialise le modèle CLIP pré-entraîné pour l'extraction de caractéristiques visuelles et textuelles, ainsi que le modèle spaCy pour le traitement du texte. Vérifie également la disponibilité et l'utilisation du GPU."
      ],
      "id": "799041a5"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pillow torchvision transformers scikit-learn\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageFile, ImageEnhance\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import CLIPModel, CLIPTokenizer, CLIPProcessor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score\n",
        "from sklearn.metrics import adjusted_rand_score, confusion_matrix, precision_score, recall_score, roc_auc_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, cross_val_predict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import random\n",
        "from scipy.interpolate import griddata\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# Configuration for large images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# Reproducibility configuration\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "# GPU/CPU configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize CLIP model\n",
        "MODEL_NAME = 'openai/clip-vit-base-patch32'  # Changed to smaller model\n",
        "try:\n",
        "    model = CLIPModel.from_pretrained(MODEL_NAME).to(device)\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(MODEL_NAME)\n",
        "    processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
        "    print(\"✅ CLIP model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to load CLIP model: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_trf\")\n",
        "    print(\"✅ spaCy model loaded successfully\")\n",
        "except:\n",
        "    print(\"⏳ Downloading spaCy model...\")\n",
        "    os.system(\"python -m spacy download en_core_web_trf\")\n",
        "    nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "# Ensure spaCy uses GPU if available\n",
        "try:\n",
        "    spacy.require_gpu()\n",
        "    print(\"✅ spaCy using GPU\")\n",
        "except:\n",
        "    print(\"⚠️ spaCy not using GPU (CUDA not found or configured)\")"
      ],
      "metadata": {
        "id": "iDzYZbsLs0B-"
      },
      "id": "iDzYZbsLs0B-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56c062bb"
      },
      "source": [
        "# 2. Chargement et Nettoyage des Données\n",
        "Objectif : Cette cellule charge le jeu de données des produits, nettoie les informations textuelles et prépare les chemins d'accès aux images pour un traitement ultérieur.\n",
        "Description : Lit les données à partir d'un fichier CSV. Effectue un nettoyage approfondi des champs textuels (nom du produit, description, spécifications), y compris la gestion des valeurs manquantes et l'application de règles de nettoyage spécifiques. Vérifie l'existence et la validité des fichiers image associés et filtre les entrées problématiques. Extrait également la catégorie principale de chaque produit."
      ],
      "id": "56c062bb"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text by replacing specific patterns and removing unwanted symbols, numbers, and punctuation.\n",
        "       Apply patterns twice to ensure complete replacement.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    all_patterns = [\n",
        "        # Transformation des motifs comme iphone4s en iphone s\n",
        "        (r'([a-zA-Z]+)(\\d+)([a-zA-Z])', r'\\1 \\3'),\n",
        "        # Abréviations d'indice solaire\n",
        "        (r'\\bpa\\+{1,3}\\b', 'sun protection factor'),\n",
        "        # Symboles indésirables\n",
        "        (r'[@*/±&%#]', ' '),  # Supprime @, *, /, ±, &, %, #\n",
        "        # Codes alphanumériques non pertinents (ex. ms004pktbl, r&m0179)\n",
        "        (r'\\b[A-Z0-9]+[-_][A-Z0-9]+\\b', ' '),\n",
        "        # Nombres seuls\n",
        "        (r'\\b\\d+\\b', ' '),\n",
        "        # Ponctuation spécifique\n",
        "        (r'\\(', ' ( '),\n",
        "        (r'\\)', ' ) '),\n",
        "        (r'\\.', ' . '),\n",
        "        (r'\\!', ' ! '),\n",
        "        (r'\\?', ' ? '),\n",
        "        (r'\\:', ' : '),\n",
        "        (r'\\,', ', '),\n",
        "        # Motifs spécifiques du domaine\n",
        "        (r'\\b(\\d+)\\s*[-~to]?\\s*(\\d+)\\s*(m|mth|mths|month|months?)\\b', 'month'),\n",
        "        (r'\\bnewborn\\s*[-~to]?\\s*(\\d+)\\s*(m|mth|months?)\\b', 'month'),\n",
        "        (r'\\b(nb|newborn|baby|bb|bby|babie|babies)\\b', 'baby'),\n",
        "        (r'\\b(diaper|diapr|nappy)\\b', 'diaper'),\n",
        "        (r'\\b(stroller|pram|buggy)\\b', 'stroller'),\n",
        "        (r'\\b(bpa\\s*free|non\\s*bpa)\\b', 'bisphenol a free'),\n",
        "        (r'\\b(\\d+)\\s*(oz|ounce)\\b', 'ounce'),\n",
        "        (r'\\b(rtx\\s*\\d+)\\b', 'ray tracing graphics'),\n",
        "        (r'\\b(gtx\\s*\\d+)\\b', 'geforce graphics'),\n",
        "        (r'\\bnvidia\\b', 'nvidia'),\n",
        "        (r'\\b(amd\\s*radeon\\s*rx\\s*\\d+)\\b', 'amd radeon graphics'),\n",
        "        (r'\\b(intel\\s*(core|xeon)\\s*[i\\d-]+)\\b', 'intel processor'),\n",
        "        (r'\\b(amd\\s*ryzen\\s*[\\d]+)\\b', 'amd ryzen processor'),\n",
        "        (r'\\bssd\\b', 'solid state drive'),\n",
        "        (r'\\bhdd\\b', 'hard disk drive'),\n",
        "        (r'\\bwifi\\s*([0-9])\\b', 'wi-fi standard'),\n",
        "        (r'\\bbluetooth\\s*(\\d\\.\\d)\\b', 'bluetooth version'),\n",
        "        (r'\\bethernet\\b', 'ethernet'),\n",
        "        (r'\\bfhd\\b', 'full high definition'),\n",
        "        (r'\\buhd\\b', 'ultra high definition'),\n",
        "        (r'\\bqhd\\b', 'quad high definition'),\n",
        "        (r'\\boled\\b', 'organic light emitting diode'),\n",
        "        (r'\\bips\\b', 'in-plane switching'),\n",
        "        (r'\\bram\\b', 'random access memory'),\n",
        "        (r'\\bcpu\\b', 'central processing unit'),\n",
        "        (r'\\bgpu\\b', 'graphics processing unit'),\n",
        "        (r'\\bhdmi\\b', 'high definition multimedia interface'),\n",
        "        (r'\\busb\\s*([a-z0-9]*)\\b', 'universal serial bus'),\n",
        "        (r'\\brgb\\b', 'red green blue'),\n",
        "        (r'\\bfridge\\b', 'refrigerator'),\n",
        "        (r'\\bwashing\\s*machine\\b', 'clothes washer'),\n",
        "        (r'\\bdishwasher\\b', 'dish washing machine'),\n",
        "        (r'\\boven\\b', 'cooking oven'),\n",
        "        (r'\\bmicrowave\\b', 'microwave oven'),\n",
        "        (r'\\bhoover\\b', 'vacuum cleaner'),\n",
        "        (r'\\btumble\\s*dryer\\b', 'clothes dryer'),\n",
        "        (r'\\b(a\\+\\++)\\b', 'energy efficiency class'),\n",
        "        (r'\\b(\\d+)\\s*btu\\b', 'british thermal unit'),\n",
        "        (r'\\bpoly\\b', 'polyester'),\n",
        "        (r'\\bacrylic\\b', 'acrylic fiber'),\n",
        "        (r'\\bnylon\\b', 'nylon fiber'),\n",
        "        (r'\\bspandex\\b', 'spandex fiber'),\n",
        "        (r'\\blycra\\b', 'lycra fiber'),\n",
        "        (r'\\bpvc\\b', 'polyvinyl chloride'),\n",
        "        (r'\\bvinyl\\b', 'vinyl material'),\n",
        "        (r'\\bstainless\\s*steel\\b', 'stainless steel'),\n",
        "        (r'\\baluminum\\b', 'aluminum metal'),\n",
        "        (r'\\bplexiglass\\b', 'acrylic glass'),\n",
        "        (r'\\bpu\\s*leather\\b', 'polyurethane leather'),\n",
        "        (r'\\bsynthetic\\s*leather\\b', 'synthetic leather'),\n",
        "        (r'\\bfaux\\s*leather\\b', 'faux leather'),\n",
        "        (r'\\bwaterproof\\b', 'water resistant'),\n",
        "        (r'\\bbreathable\\b', 'air permeable'),\n",
        "        (r'\\bwrinkle-free\\b', 'wrinkle resistant'),\n",
        "        (r'\\bSPF\\b', 'sun protection factor'),\n",
        "        (r'\\bUV\\b', 'ultraviolet'),\n",
        "        (r'\\bBB\\s*cream\\b', 'blemish balm cream'),\n",
        "        (r'\\bCC\\s*cream\\b', 'color correcting cream'),\n",
        "        (r'\\bHA\\b', 'hyaluronic acid'),\n",
        "        (r'\\bAHA\\b', 'alpha hydroxy acid'),\n",
        "        (r'\\bBHA\\b', 'beta hydroxy acid'),\n",
        "        (r'\\bPHA\\b', 'polyhydroxy acid'),\n",
        "        (r'\\bNMF\\b', 'natural moisturizing factor'),\n",
        "        (r'\\bEGF\\b', 'epidermal growth factor'),\n",
        "        (r'\\bVit\\s*C\\b', 'vitamin c'),\n",
        "        (r'\\bVit\\s*E\\b', 'vitamin e'),\n",
        "        (r'\\bVit\\s*B3\\b', 'niacinamide vitamin b3'),\n",
        "        (r'\\bVit\\s*B5\\b', 'panthenol vitamin b5'),\n",
        "        (r'\\bSOD\\b', 'superoxide dismutase'),\n",
        "        (r'\\bQ10\\b', 'coenzyme q10'),\n",
        "        (r'\\bFoam\\s*cl\\b', 'foam cleanser'),\n",
        "        (r'\\bMic\\s*H2O\\b', 'micellar water'),\n",
        "        (r'\\bToner\\b', 'skin toner'),\n",
        "        (r'\\bEssence\\b', 'skin essence'),\n",
        "        (r'\\bAmpoule\\b', 'concentrated serum'),\n",
        "        (r'\\bCF\\b', 'cruelty free'),\n",
        "        (r'\\bPF\\b', 'paraben free'),\n",
        "        (r'\\bSF\\b', 'sulfate free'),\n",
        "        (r'\\bGF\\b', 'gluten free'),\n",
        "        (r'\\bHF\\b', 'hypoallergenic formula'),\n",
        "        (r'\\bNT\\b', 'non-comedogenic tested'),\n",
        "        (r'\\bAM\\b', 'morning'),\n",
        "        (r'\\bPM\\b', 'night'),\n",
        "        (r'\\bBID\\b', 'twice daily'),\n",
        "        (r'\\bQD\\b', 'once daily'),\n",
        "        (r'\\bAIR\\b', 'airless pump bottle'),\n",
        "        (r'\\bD-C\\b', 'dropper container'),\n",
        "        (r'\\bT-C\\b', 'tube container'),\n",
        "        (r'\\bPDO\\b', 'polydioxanone'),\n",
        "        (r'\\bPCL\\b', 'polycaprolactone'),\n",
        "        (r'\\bPLLA\\b', 'poly-l-lactic acid'),\n",
        "        (r'\\bHIFU\\b', 'high-intensity focused ultrasound'),\n",
        "        (r'\\b(\\d+)\\s*fl\\s*oz\\b', 'fluid ounce'),\n",
        "        (r'\\bpH\\s*bal\\b', 'ph balanced'),\n",
        "        (r'\\b(\\d+)\\s*(gb|tb|mb|go|to|mo)\\b', 'byte'),\n",
        "        (r'\\boctet\\b', 'byte'),\n",
        "        (r'\\b(\\d+)\\s*y\\b', 'year'),\n",
        "        (r'\\b(\\d+)\\s*mth\\b', 'month'),\n",
        "        (r'\\b(\\d+)\\s*d\\b', 'day'),\n",
        "        (r'\\b(\\d+)\\s*h\\b', 'hour'),\n",
        "        (r'\\b(\\d+)\\s*min\\b', 'minute'),\n",
        "        (r'\\b(\\d+)\\s*rpm\\b', 'revolution per minute'),\n",
        "        (r'\\b(\\d+)\\s*(mw|cw|kw)\\b', 'watt'),\n",
        "        (r'\\b(\\d+)\\s*(ma|ca|ka)\\b', 'ampere'),\n",
        "        (r'\\b(\\d+)\\s*(mv|cv|kv)\\b', 'volt'),\n",
        "        (r'\\b(\\d+)\\s*(mm|cm|m|km)\\b', 'meter'),\n",
        "        (r'\\binch\\b', 'meter'),\n",
        "        (r'\\b(\\d+)\\s*(ml|cl|dl|l|oz|gal)\\b', 'liter'),\n",
        "        (r'\\b(gallon|ounce)\\b', 'liter'),\n",
        "        (r'\\b(\\d+)\\s*(mg|cg|dg|g|kg|lb)\\b', 'gram'),\n",
        "        (r'\\bpound\\b', 'gram'),\n",
        "        (r'\\b(\\d+)\\s*(°c|°f)\\b', 'celsius'),\n",
        "        (r'\\bfahrenheit\\b', 'celsius'),\n",
        "        (r'\\bflipkart\\.com\\b', ''),\n",
        "        (r'\\bapprox\\.?\\b', 'approximately'),\n",
        "        (r'\\bw/o\\b', 'without'),\n",
        "        (r'\\bw/\\b', 'with'),\n",
        "        (r'\\bant-\\b', 'anti'),\n",
        "        (r'\\byes\\b', ''),\n",
        "        (r'\\bno\\b', ''),\n",
        "        (r'\\bna\\b', ''),\n",
        "        (r'\\brs\\.?\\b', ''),\n",
        "        # Normaliser les espaces\n",
        "        (r'\\s+', ' '),\n",
        "    ]\n",
        "    # Apply patterns twice to ensure complete replacement\n",
        "    for _ in range(2):\n",
        "        for pattern, replacement in all_patterns:\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_keywords(text, nlp, top_n=15):\n",
        "    \"\"\"Extract keywords from text using lemmatization and stopword removal,\n",
        "       filtering out potential product references, specific codes, and short words.\"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    doc = nlp(text)\n",
        "    keywords = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower().strip()\n",
        "        # Skip short words, punctuation, stopwords, empty lemmas, and unwanted patterns\n",
        "        if (len(lemma) < 2 or\n",
        "            token.is_punct or\n",
        "            not lemma or\n",
        "            token.is_stop or\n",
        "            re.match(r'.*[@*/±&%#].*', lemma)):  # Exclure les mots avec symboles indésirables\n",
        "            continue\n",
        "        keywords.append(lemma)\n",
        "    keyword_counts = Counter(keywords)\n",
        "    return [word for word, count in keyword_counts.most_common(top_n)]\n",
        "\n",
        "def process_descriptions_to_keywords(df, uniq_id=None):\n",
        "    \"\"\"Convert processed_text to comma-separated keywords and generate keyword frequencies CSV.\n",
        "       If uniq_id is provided, generate CSV for that specific product only.\"\"\"\n",
        "    print(\"⏳ Loading spaCy model...\")\n",
        "    try:\n",
        "        nlp = spacy.load(\"en_core_web_trf\")\n",
        "        # Ensure spaCy uses GPU if available\n",
        "        try:\n",
        "            spacy.require_gpu()\n",
        "            print(\"✅ spaCy using GPU\")\n",
        "        except:\n",
        "            print(\"⚠️ spaCy not using GPU (CUDA not found or configured)\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load spaCy model: {str(e)}\")\n",
        "        print(\"⏳ Downloading spaCy model...\")\n",
        "        os.system(\"python -m spacy download en_core_web_trf\")\n",
        "        nlp = spacy.load(\"en_core_web_trf\")\n",
        "    print(\"🔍 Extracting keywords from descriptions...\")\n",
        "\n",
        "    # Extract keywords for all products or a specific product\n",
        "    if uniq_id is not None:\n",
        "        df_subset = df[df['uniq_id'] == uniq_id].copy()\n",
        "        if df_subset.empty:\n",
        "            print(f\"❌ No product found with uniq_id: {uniq_id}\")\n",
        "            return df\n",
        "        df_subset['keywords'] = df_subset['processed_text'].apply(lambda x: \", \".join(extract_keywords(x, nlp)))\n",
        "        df_subset['keywords'] = df_subset['keywords'].replace('', 'no_keywords_found')\n",
        "        all_keywords = []\n",
        "        for kws in df_subset['keywords']:\n",
        "            if kws != 'no_keywords_found':\n",
        "                all_keywords.extend(kws.split(\", \"))\n",
        "        output_csv = f'keyword_frequencies_{uniq_id}.csv'\n",
        "        print(f\"✅ Keywords extracted for product {uniq_id}\")\n",
        "    else:\n",
        "        df['keywords'] = df['processed_text'].apply(lambda x: \", \".join(extract_keywords(x, nlp)))\n",
        "        df['keywords'] = df['keywords'].replace('', 'no_keywords_found')\n",
        "        all_keywords = []\n",
        "        for kws in df['keywords']:\n",
        "            if kws != 'no_keywords_found':\n",
        "                all_keywords.extend(kws.split(\", \"))\n",
        "        output_csv = 'keyword_frequencies.csv'\n",
        "        print(f\"✅ Keywords extracted for {len(df)} products\")\n",
        "\n",
        "    # Generate keyword frequencies\n",
        "    keyword_freq = Counter(all_keywords)\n",
        "    keyword_freq_df = pd.DataFrame(list(keyword_freq.items()), columns=['Mot Clé', 'Fréquence'])\n",
        "    keyword_freq_df = keyword_freq_df.sort_values(by='Fréquence', ascending=False)\n",
        "\n",
        "    # Save to CSV\n",
        "    keyword_freq_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
        "    print(f\"✅ Keyword frequencies saved to {output_csv}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_data(filepath, image_folder, uniq_id=None):\n",
        "    \"\"\"\n",
        "    Load data and prepare image paths with advanced text cleaning and handling of problematic images.\n",
        "    Allow description and product_specifications to be NaN or null. Resize large images to fit pixel limit.\n",
        "    Suppress image size logging. Optionally process a single product by uniq_id.\n",
        "    Save the updated DataFrame with keywords back to produits_original.csv.\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = pd.read_csv(filepath)\n",
        "    original_count = len(df)\n",
        "    print(f\"Initial product count: {original_count}\")\n",
        "\n",
        "    # If uniq_id is provided, filter to that product\n",
        "    if uniq_id is not None:\n",
        "        df = df[df['uniq_id'] == uniq_id]\n",
        "        if df.empty:\n",
        "            raise ValueError(f\"No product found with uniq_id: {uniq_id}\")\n",
        "        print(f\"Processing single product with uniq_id: {uniq_id}\")\n",
        "\n",
        "    # Step 1: Drop rows with NaN in required fields (product_name, product_category_tree, image)\n",
        "    required_columns = ['product_name', 'product_category_tree', 'image']\n",
        "    df = df.dropna(subset=required_columns)\n",
        "    print(f\"After dropping NaN in required columns ({required_columns}): {len(df)} rows remain\")\n",
        "    dropped_nan = df[df[required_columns].isna().any(axis=1)]\n",
        "    if not dropped_nan.empty:\n",
        "        print(\"Dropped due to NaN in required columns:\", dropped_nan['uniq_id'].tolist())\n",
        "\n",
        "    # Step 2: Filter empty strings in required fields\n",
        "    df = df[(df['product_name'] != '') & (df['product_category_tree'] != '') & (df['image'] != '')]\n",
        "    print(f\"After filtering empty strings in required columns: {len(df)} rows remain\")\n",
        "    dropped_empty = df[(df['product_name'] == '') | (df['product_category_tree'] == '') | (df['image'] == '')]\n",
        "    if not dropped_empty.empty:\n",
        "        print(\"Dropped due to empty strings in required columns:\", dropped_empty['uniq_id'].tolist())\n",
        "\n",
        "    # Step 3: Extract and clean main category\n",
        "    df['main_category'] = df['product_category_tree'].str.split(' >> ').str[0]\n",
        "    df['main_category'] = df['main_category'].str.replace(r'[\\[\\]\\\"\\']', '', regex=True)\n",
        "    df = df[df['main_category'] != '']\n",
        "    print(f\"After filtering empty categories: {len(df)} rows remain\")\n",
        "    dropped_category = df[df['main_category'] == '']\n",
        "    if not dropped_category.empty:\n",
        "        print(\"Dropped due to empty categories:\", dropped_category['uniq_id'].tolist())\n",
        "\n",
        "    # Step 4: Check image existence and validity\n",
        "    df['image_path'] = df['uniq_id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n",
        "    df['image_exists'] = df['image_path'].apply(lambda x: any(\n",
        "        os.path.exists(os.path.join(image_folder, f\"{x}.{ext}\"))\n",
        "        for ext in ['jpg', 'JPG', 'jpeg', 'JPEG']\n",
        "    ))\n",
        "    def is_valid_image(path):\n",
        "        try:\n",
        "            with Image.open(path) as img:\n",
        "                img.verify()  # Verify image integrity\n",
        "                img = Image.open(path)  # Re-open after verify\n",
        "                pixel_count = img.size[0] * img.size[1]\n",
        "                max_pixels = 89478485\n",
        "                if pixel_count > max_pixels:\n",
        "                    # Calculate scaling factor to fit within max_pixels while preserving aspect ratio\n",
        "                    scale = (max_pixels / pixel_count) ** 0.5\n",
        "                    new_size = (int(img.size[0] * scale), int(img.size[1] * scale))\n",
        "                    img = img.resize(new_size, Image.LANCZOS)\n",
        "                    # Save resized image to a temporary path to avoid modifying original\n",
        "                    temp_path = path.replace('.jpg', '_resized.jpg')\n",
        "                    img.save(temp_path, 'JPEG', quality=95)\n",
        "                    return temp_path\n",
        "                return path\n",
        "        except Exception as e:\n",
        "            print(f\"Invalid image {path}: {str(e)}\")\n",
        "            return False\n",
        "    df['image_valid_path'] = df['image_path'].apply(is_valid_image)\n",
        "    dropped_images = df[df['image_valid_path'] == False]\n",
        "    if not dropped_images.empty:\n",
        "        print(\"Dropped due to missing or invalid images:\", dropped_images['uniq_id'].tolist())\n",
        "    df = df[df['image_valid_path'] != False].copy()\n",
        "    df['image_path'] = df['image_valid_path']  # Update image_path with resized path if applicable\n",
        "    df = df.drop(columns=['image_exists', 'image_valid_path'])\n",
        "    print(f\"After filtering invalid images: {len(df)} rows remain\")\n",
        "\n",
        "    # Step 5: Process text, allowing NaN for description and product_specifications\n",
        "    def process_specs(spec_string):\n",
        "        if not isinstance(spec_string, str):\n",
        "            return \"\"\n",
        "        matches = re.findall(r'\\{\"key\"=>\"(.*?)\", \"value\"=>\"(.*?)\"\\}', spec_string)\n",
        "        return \". \".join(f\"{k.strip().lower()} {v.strip().lower()}\" for k, v in matches if k.strip() and v.strip())\n",
        "\n",
        "    # Replace NaN with empty strings for description and product_specifications\n",
        "    df['description'] = df['description'].fillna('')\n",
        "    df['product_specifications'] = df['product_specifications'].fillna('')\n",
        "    df['cleaned_specs'] = df['product_specifications'].apply(process_specs)\n",
        "    df['combined_text'] = (\n",
        "        df['product_name'].str.lower() + '. ' +\n",
        "        df['brand'].fillna('').str.lower() + '. ' +\n",
        "        df['cleaned_specs'].str.lower() + '. ' +\n",
        "        df['description'].str.lower()\n",
        "    )\n",
        "    df['processed_text'] = df['combined_text'].apply(clean_text)\n",
        "    dropped_text = df[(df['processed_text'].str.strip() == '') | (df['processed_text'].str.split().str.len() <= 3)]\n",
        "    if not dropped_text.empty:\n",
        "        print(\"Dropped due to empty or short text:\", dropped_text['uniq_id'].tolist())\n",
        "    df = df[(df['processed_text'].str.strip() != '') & (df['processed_text'].str.split().str.len() > 3)]\n",
        "    print(f\"After filtering short text: {len(df)} rows remain\")\n",
        "\n",
        "    # Step 6: Extract keywords\n",
        "    df = process_descriptions_to_keywords(df, uniq_id=uniq_id)\n",
        "\n",
        "    # Step 7: Save the updated DataFrame to produits_original.csv (only if processing all products)\n",
        "    if uniq_id is None:\n",
        "        # Keep only the original columns plus 'keywords'\n",
        "        original_columns = pd.read_csv(filepath).columns.tolist()\n",
        "        save_columns = original_columns + ['keywords']\n",
        "        df[save_columns].to_csv(filepath, index=False, encoding='utf-8')\n",
        "        print(f\"✅ Updated DataFrame with keywords saved to {filepath}\")\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(\"DataFrame vide après nettoyage. Vérifiez les données sources.\")\n",
        "    return df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5ekN_03Fs0Ey"
      },
      "id": "5ekN_03Fs0Ey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0370a258"
      },
      "source": [
        "# 3. Fine-Tuning du Modèle CLIP\n",
        "Objectif : Cette cellule adapte le modèle CLIP à la tâche spécifique de classification des produits en le fine-tunant sur le jeu de données préparé.\n",
        "Description : Définit une classe personnalisée `CLIPForClassification` qui ajoute une couche de classification sur le modèle CLIP. Crée un `ProductDataset` personnalisé pour gérer le chargement des images et du texte, y compris le redimensionnement des images et la tokenisation du texte. Configure l'entraînement du modèle avec un optimiseur et un scaler pour l'autocasting GPU. Effectue le fine-tuning sur plusieurs époques et sauvegarde le modèle fine-tuné."
      ],
      "id": "0370a258"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "class CLIPForClassification(CLIPModel):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__(config)\n",
        "        self.clip = CLIPModel.from_pretrained(MODEL_NAME)\n",
        "        self.classifier = nn.Linear(config.projection_dim * 2, num_labels)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pixel_values, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.clip(pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = torch.cat((outputs.image_embeds, outputs.text_embeds), dim=-1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return type('Output', (), {\n",
        "            'loss': loss,\n",
        "            'logits': logits,\n",
        "            'image_embeds': outputs.image_embeds,\n",
        "            'text_embeds': outputs.text_embeds\n",
        "        })()\n",
        "\n",
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, df, processor, tokenizer, max_size=128, max_length=77):  # Reduced max_size\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_size = max_size\n",
        "        self.max_length = max_length\n",
        "        self.labels = pd.factorize(df['main_category'])[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image_path']\n",
        "        text = row['keywords']\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                if max(img.size) > self.max_size:\n",
        "                    ratio = self.max_size / max(img.size)\n",
        "                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
        "                    img = img.resize(new_size, Image.LANCZOS)\n",
        "                image_inputs = self.processor(images=img, return_tensors=\"pt\", padding=True).pixel_values.squeeze(0)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Skipping image {img_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            text_inputs = self.tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=self.max_length\n",
        "            )\n",
        "            return {\n",
        "                'pixel_values': image_inputs,\n",
        "                'input_ids': text_inputs['input_ids'].squeeze(0),\n",
        "                'attention_mask': text_inputs['attention_mask'].squeeze(0),\n",
        "                'labels': torch.tensor(label, dtype=torch.long)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Skipping text for index {idx}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "def fine_tune_clip(df, processor, tokenizer, epochs=5, batch_size=4, accum_steps=4, save_path=\"finetuned_clip\"):\n",
        "    \"\"\"Fine-tune the CLIP model with a classification head and save it.\"\"\"\n",
        "    num_labels = len(df['main_category'].unique())\n",
        "    try:\n",
        "        config = CLIPModel.from_pretrained(MODEL_NAME).config\n",
        "        model = CLIPForClassification(config, num_labels=num_labels).to(device)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to initialize CLIPForClassification: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-6)\n",
        "    scaler = GradScaler('cuda')\n",
        "    dataset = ProductDataset(df, processor, tokenizer, max_size=128, max_length=77)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        batch = [item for item in batch if item is not None]\n",
        "        if not batch:\n",
        "            return None\n",
        "        return {\n",
        "            'pixel_values': torch.stack([item['pixel_values'] for item in batch]),\n",
        "            'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
        "            'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
        "            'labels': torch.stack([item['labels'] for item in batch])\n",
        "        }\n",
        "\n",
        "    # Split dataset into train and validation\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED)\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "    effective_batch_size = batch_size * accum_steps\n",
        "    print(f\"Using batch_size={batch_size}, accum_steps={accum_steps}, effective_batch_size={effective_batch_size}\")\n",
        "\n",
        "    # Store training history\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_accuracy': [],\n",
        "        'val_accuracy': [],\n",
        "        'train_f1': [],\n",
        "        'val_f1': [],\n",
        "        'train_precision': [],\n",
        "        'val_precision': [],\n",
        "        'train_recall': [],\n",
        "        'val_recall': [],\n",
        "        'train_balanced_accuracy': [],\n",
        "        'val_balanced_accuracy': [],\n",
        "        'train_roc_auc': [],\n",
        "        'val_roc_auc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        train_preds = []\n",
        "        train_labels = []\n",
        "        train_probs = []\n",
        "\n",
        "        step = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            if batch is None:\n",
        "                continue\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            with autocast('cuda'):\n",
        "                outputs = model(**inputs, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            if loss is not None:\n",
        "                loss = loss / accum_steps\n",
        "                scaler.scale(loss).backward()\n",
        "                step += 1\n",
        "\n",
        "                if step % accum_steps == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                total_train_loss += loss.item() * accum_steps\n",
        "\n",
        "            # Store predictions for metrics\n",
        "            with torch.no_grad():\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                train_preds.extend(preds.cpu().numpy())\n",
        "                train_labels.extend(labels.cpu().numpy())\n",
        "                train_probs.extend(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "        train_f1 = f1_score(train_labels, train_preds, average='weighted')\n",
        "        train_precision = precision_score(train_labels, train_preds, average='weighted')\n",
        "        train_recall = recall_score(train_labels, train_preds, average='weighted')\n",
        "        train_balanced_accuracy = balanced_accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        # Calculate ROC AUC if possible\n",
        "        try:\n",
        "            train_roc_auc = roc_auc_score(train_labels, train_probs, multi_class='ovr', average='weighted')\n",
        "        except:\n",
        "            train_roc_auc = np.nan\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        val_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                if batch is None:\n",
        "                    continue\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                with autocast('cuda'):\n",
        "                    outputs = model(**inputs, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "\n",
        "                if loss is not None:\n",
        "                    total_val_loss += loss.item()\n",
        "\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_probs.extend(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "        val_precision = precision_score(val_labels, val_preds, average='weighted')\n",
        "        val_recall = recall_score(val_labels, val_preds, average='weighted')\n",
        "        val_balanced_accuracy = balanced_accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        try:\n",
        "            val_roc_auc = roc_auc_score(val_labels, val_probs, multi_class='ovr', average='weighted')\n",
        "        except:\n",
        "            val_roc_auc = np.nan\n",
        "\n",
        "        # Store metrics\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['train_loss'].append(total_train_loss / len(train_dataloader))\n",
        "        history['val_loss'].append(total_val_loss / len(val_dataloader))\n",
        "        history['train_accuracy'].append(train_accuracy)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "        history['train_f1'].append(train_f1)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        history['train_precision'].append(train_precision)\n",
        "        history['val_precision'].append(val_precision)\n",
        "        history['train_recall'].append(train_recall)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['train_balanced_accuracy'].append(train_balanced_accuracy)\n",
        "        history['val_balanced_accuracy'].append(val_balanced_accuracy)\n",
        "        history['train_roc_auc'].append(train_roc_auc)\n",
        "        history['val_roc_auc'].append(val_roc_auc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"  Train Loss: {history['train_loss'][-1]:.4f}, Val Loss: {history['val_loss'][-1]:.4f}\")\n",
        "        print(f\"  Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "        print(f\"  Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}\")\n",
        "        print(f\"  Train-Validation Gap: {train_accuracy - val_accuracy:.4f}\")\n",
        "\n",
        "    # Save model in the Hugging Face format\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    model.save_pretrained(save_path)\n",
        "    processor.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"✅ Fine-tuned model saved to {save_path}\")\n",
        "\n",
        "    # Save model state_dict as a single .pth file\n",
        "    pth_save_path = \"new_clip_product_classifier.pth\"\n",
        "    torch.save(model.state_dict(), pth_save_path)\n",
        "    print(f\"✅ Model state_dict saved to {pth_save_path}\")\n",
        "\n",
        "    # Save training history\n",
        "    history_df = pd.DataFrame(history)\n",
        "    history_df.to_csv(os.path.join(save_path, 'training_history.csv'), index=False)\n",
        "\n",
        "    print(f\"✅ Training history saved to {os.path.join(save_path, 'training_history.csv')}\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "RAtrAqF6s0H2"
      },
      "id": "RAtrAqF6s0H2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(history, save_path):\n",
        "    \"\"\"Plot training and validation curves to detect overfitting.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # Loss curve\n",
        "    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
        "    axes[0, 0].plot(history['epoch'], history['val_loss'], label='Validation Loss', marker='o')\n",
        "    axes[0, 0].set_title('Training and Validation Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy curve\n",
        "    axes[0, 1].plot(history['epoch'], history['train_accuracy'], label='Train Accuracy', marker='o')\n",
        "    axes[0, 1].plot(history['epoch'], history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
        "    axes[0, 1].set_title('Training and Validation Accuracy')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 score curve\n",
        "    axes[0, 2].plot(history['epoch'], history['train_f1'], label='Train F1', marker='o')\n",
        "    axes[0, 2].plot(history['epoch'], history['val_f1'], label='Validation F1 Score', marker='o')\n",
        "    axes[0, 2].set_title('Training and Validation F1 Score')\n",
        "    axes[0, 2].set_xlabel('Epoch')\n",
        "    axes[0, 2].set_ylabel('F1 Score')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision curve\n",
        "    axes[1, 0].plot(history['epoch'], history['train_precision'], label='Train Precision', marker='o')\n",
        "    axes[1, 0].plot(history['epoch'], history['val_precision'], label='Validation Precision', marker='o')\n",
        "    axes[1, 0].set_title('Training and Validation Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Recall curve\n",
        "    axes[1, 1].plot(history['epoch'], history['train_recall'], label='Train Recall', marker='o')\n",
        "    axes[1, 1].plot(history['epoch'], history['val_recall'], label='Validation Recall', marker='o')\n",
        "    axes[1, 1].set_title('Training and Validation Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy gap (overfitting indicator)\n",
        "    accuracy_gap = [train - val for train, val in zip(history['train_accuracy'], history['val_accuracy'])]\n",
        "    axes[1, 2].plot(history['epoch'], accuracy_gap, label='Accuracy Gap (Train - Val)', marker='o', color='red')\n",
        "    axes[1, 2].axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
        "    axes[1, 2].set_title('Accuracy Gap (Indicator of Overfitting)')\n",
        "    axes[1, 2].set_xlabel('Epoch')\n",
        "    axes[1, 2].set_ylabel('Accuracy Gap')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Create summary table\n",
        "    final_metrics = {\n",
        "        'Metric': ['Loss', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'Balanced Accuracy', 'ROC AUC'],\n",
        "        'Train_Final': [\n",
        "            history['train_loss'][-1],\n",
        "            history['train_accuracy'][-1],\n",
        "            history['train_f1'][-1],\n",
        "            history['train_precision'][-1],\n",
        "            history['train_recall'][-1],\n",
        "            history['train_balanced_accuracy'][-1],\n",
        "            history['train_roc_auc'][-1] if not np.isnan(history['train_roc_auc'][-1]) else None\n",
        "        ],\n",
        "        'Validation_Final': [\n",
        "            history['val_loss'][-1],\n",
        "            history['val_accuracy'][-1],\n",
        "            history['val_f1'][-1],\n",
        "            history['val_precision'][-1],\n",
        "            history['val_recall'][-1],\n",
        "            history['val_balanced_accuracy'][-1],\n",
        "            history['val_roc_auc'][-1] if not np.isnan(history['val_roc_auc'][-1]) else None\n",
        "        ],\n",
        "        'Gap': [\n",
        "            history['train_loss'][-1] - history['val_loss'][-1],\n",
        "            history['train_accuracy'][-1] - history['val_accuracy'][-1],\n",
        "            history['train_f1'][-1] - history['val_f1'][-1],\n",
        "            history['train_precision'][-1] - history['val_precision'][-1],\n",
        "            history['train_recall'][-1] - history['val_recall'][-1],\n",
        "            history['train_balanced_accuracy'][-1] - history['val_balanced_accuracy'][-1],\n",
        "            (history['train_roc_auc'][-1] - history['val_roc_auc'][-1]) if not np.isnan(history['train_roc_auc'][-1]) and not np.isnan(history['val_roc_auc'][-1]) else None\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    summary_df = pd.DataFrame(final_metrics)\n",
        "    summary_df.to_csv(os.path.join(save_path, 'final_metrics_summary.csv'), index=False)\n",
        "\n",
        "    print(f\"✅ Training curves saved to {os.path.join(save_path, 'training_curves.png')}\")\n",
        "    print(f\"✅ Final metrics summary saved to {os.path.join(save_path, 'final_metrics_summary.csv')}\")\n",
        "\n",
        "    return summary_df"
      ],
      "metadata": {
        "id": "r8eSmdtXfh16"
      },
      "id": "r8eSmdtXfh16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baf0647d"
      },
      "source": [
        "# 4. Extraction des Caractéristiques Textuelles et Visuelles\n",
        "Objectif : Cette cellule utilise le modèle CLIP fine-tuné pour extraire des représentations numériques (caractéristiques) distinctes pour les modalités textuelle et visuelle de chaque produit, puis les combine.\n",
        "Description : Définit des fonctions pour extraire les caractéristiques textuelles à partir des mots-clés en utilisant l'encodeur de texte de CLIP, et les caractéristiques visuelles à partir des images en utilisant l'encodeur d'image de CLIP. Normalise ces caractéristiques. Propose une méthode pour combiner ces deux types de caractéristiques en utilisant une pondération alpha, créant ainsi une représentation multimodale."
      ],
      "id": "baf0647d"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_features(df, model, tokenizer):\n",
        "    \"\"\"Extract text features using the fine-tuned CLIP model.\"\"\"\n",
        "    texts = df['keywords'].tolist()\n",
        "    if not texts:\n",
        "        return np.array([])\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(texts, padding=True, truncation=True, max_length=77, return_tensors=\"pt\").to(device)\n",
        "        text_features = model.clip.get_text_features(**inputs)\n",
        "    return text_features.cpu().numpy()\n",
        "\n",
        "def extract_image_features(df, model, processor, max_size=128):  # Reduced max_size\n",
        "    \"\"\"Extract image features using the fine-tuned CLIP model.\"\"\"\n",
        "    features = []\n",
        "    valid_indices = []\n",
        "    for idx, img_path in enumerate(df['image_path']):\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                if max(img.size) > max_size:\n",
        "                    ratio = max_size / max(img.size)\n",
        "                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
        "                    img = img.resize(new_size, Image.LANCZOS)\n",
        "                with torch.no_grad():\n",
        "                    inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "                    features.append(model.clip.get_image_features(**inputs).cpu().numpy())\n",
        "                    valid_indices.append(idx)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Skipping image {img_path}: {str(e)}\")\n",
        "            continue\n",
        "    if not features:\n",
        "        raise ValueError(\"No valid images processed.\")\n",
        "    return np.vstack(features), df.iloc[valid_indices].copy()\n",
        "\n",
        "def combine_features(text_features, image_features, alpha=0.6):\n",
        "    \"\"\"Combine text and image features with a weighting factor.\"\"\"\n",
        "    text_features = normalize(text_features, norm='l2')\n",
        "    image_features = normalize(image_features, norm='l2')\n",
        "    min_samples = min(text_features.shape[0], image_features.shape[0])\n",
        "    return normalize(alpha * text_features[:min_samples] + (1 - alpha) * image_features[:min_samples])"
      ],
      "metadata": {
        "id": "JQYIR9ins0Kw"
      },
      "id": "JQYIR9ins0Kw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68c0fd1b"
      },
      "source": [
        "# 5. Évaluation et Comparaison des Modalités\n",
        "Objectif : Cette cellule évalue les performances de classification en utilisant les caractéristiques textuelles, visuelles et combinées pour déterminer l'efficacité de chaque modalité et de leur combinaison.\n",
        "Description : Implémente une fonction `evaluate_classification` qui utilise la validation croisée Stratified K-Fold avec un pipeline comprenant une PCA pour la réduction de dimensionnalité et un classificateur RandomForest. Calcule et affiche plusieurs métriques de performance courantes (Accuracy, F1-score, Precision, Recall, Balanced Accuracy, ARI, ROC AUC). La fonction `compare_modalities` appelle l'évaluation pour chaque ensemble de caractéristiques et sauvegarde les résultats dans un fichier CSV et génère une visualisation comparative des métriques."
      ],
      "id": "68c0fd1b"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(features, true_labels, method_name, n_splits=5):\n",
        "    \"\"\"Evaluate classification performance with cross-validation, including additional metrics.\"\"\"\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "\n",
        "    # Define scoring metrics\n",
        "    scoring = {\n",
        "        'accuracy': 'accuracy',\n",
        "        'f1_weighted': 'f1_weighted',\n",
        "        'precision_weighted': 'precision_weighted',\n",
        "        'recall_weighted': 'recall_weighted',\n",
        "        'balanced_accuracy': 'balanced_accuracy'\n",
        "    }\n",
        "\n",
        "    # Perform cross-validation\n",
        "    scores = cross_validate(\n",
        "        pipeline, features, true_labels, cv=cv, scoring=scoring, n_jobs=1, return_train_score=False\n",
        "    )\n",
        "\n",
        "    # Compute ARI and get predictions using cross_val_predict\n",
        "    y_pred = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "    ari_score = adjusted_rand_score(true_labels, y_pred)\n",
        "\n",
        "    # Compute ROC AUC (One-vs-Rest) if multi-class\n",
        "    try:\n",
        "        le = LabelEncoder()\n",
        "        y_true_encoded = le.fit_transform(true_labels)\n",
        "        y_score = cross_val_predict(\n",
        "            pipeline, features, true_labels, cv=cv, method='predict_proba', n_jobs=1\n",
        "        )\n",
        "        roc_auc = roc_auc_score(y_true_encoded, y_score, multi_class='ovr', average='weighted')\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ ROC AUC calculation failed for {method_name}: {str(e)}\")\n",
        "        roc_auc = np.nan\n",
        "\n",
        "    # Aggregate results\n",
        "    avg_accuracy = np.mean(scores['test_accuracy'])\n",
        "    avg_f1 = np.mean(scores['test_f1_weighted'])\n",
        "    avg_precision = np.mean(scores['test_precision_weighted'])\n",
        "    avg_recall = np.mean(scores['test_recall_weighted'])\n",
        "    avg_balanced_accuracy = np.mean(scores['test_balanced_accuracy'])\n",
        "\n",
        "    print(f\"\\nMéthode: {method_name}\")\n",
        "    print(f\"Accuracy (CV): {avg_accuracy:.3f}\")\n",
        "    print(f\"F1-score (weighted): {avg_f1:.3f}\")\n",
        "    print(f\"Precision (weighted): {avg_precision:.3f}\")\n",
        "    print(f\"Recall (weighted): {avg_recall:.3f}\")\n",
        "    print(f\"Balanced Accuracy: {avg_balanced_accuracy:.3f}\")\n",
        "    print(f\"Adjusted Rand Index: {ari_score:.3f}\")\n",
        "    print(f\"ROC AUC (OvR, weighted): {roc_auc:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'method': method_name,\n",
        "        'accuracy': avg_accuracy,\n",
        "        'f1_weighted': avg_f1,\n",
        "        'precision_weighted': avg_precision,\n",
        "        'recall_weighted': avg_recall,\n",
        "        'balanced_accuracy': avg_balanced_accuracy,\n",
        "        'ari': ari_score,\n",
        "        'roc_auc': roc_auc\n",
        "    }, true_labels, y_pred # Return true and predicted labels from CV\n",
        "\n",
        "def compare_modalities(df, text_features, image_features, combined_features, true_labels, valid_df, valid_categories, save_folder=\"result\"):\n",
        "    \"\"\"Compare text, image, and combined modalities with extended metrics and save to CSV.\"\"\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    results = []\n",
        "    # Capture true and predicted labels from CV for each modality\n",
        "    text_results, text_true_labels_cv, text_pred_labels_cv = evaluate_classification(text_features, true_labels, \"Texte seul\")\n",
        "    results.append(text_results)\n",
        "\n",
        "    img_results, img_true_labels_cv, img_pred_labels_cv = evaluate_classification(image_features, valid_categories, \"Image seule\")\n",
        "    results.append(img_results)\n",
        "\n",
        "    comb_results, comb_true_labels_cv, comb_pred_labels_cv = evaluate_classification(combined_features, valid_categories, \"Texte+Image\")\n",
        "    results.append(comb_results)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df.to_csv(os.path.join(save_folder, 'comparison_results.csv'), index=False)\n",
        "    print(f\"✅ Results saved to '{save_folder}/comparison_results.csv'\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 3, 1)\n",
        "    sns.barplot(x='method', y='accuracy', hue='method', data=results_df, palette=\"Blues_d\", legend=False)\n",
        "    plt.title(\"Accuracy moyenne (validation croisée)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "\n",
        "    # F1-score\n",
        "    plt.subplot(2, 3, 2)\n",
        "    sns.barplot(x='method', y='f1_weighted', hue='method', data=results_df, palette=\"Greens_d\", legend=False)\n",
        "    plt.title(\"F1-score moyen (pondéré)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"F1-score\")\n",
        "\n",
        "    # Precision\n",
        "    plt.subplot(2, 3, 3)\n",
        "    sns.barplot(x='method', y='precision_weighted', hue='method', data=results_df, palette=\"Oranges_d\", legend=False)\n",
        "    plt.title(\"Precision moyenne (pondérée)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Precision\")\n",
        "\n",
        "    # Recall\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.barplot(x='method', y='recall_weighted', hue='method', data=results_df, palette=\"Purples_d\", legend=False)\n",
        "    plt.title(\"Recall moyen (pondéré)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Recall\")\n",
        "\n",
        "    # Balanced Accuracy\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.barplot(x='method', y='balanced_accuracy', hue='method', data=results_df, palette=\"Reds_d\", legend=False)\n",
        "    plt.title(\"Balanced Accuracy moyenne\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Balanced Accuracy\")\n",
        "\n",
        "    # ARI\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.barplot(x='method', y='ari', hue='method', data=results_df, palette=\"YlOrBr_d\", legend=False)\n",
        "    plt.title(\"Adjusted Rand Index\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"ARI\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_folder, 'comparison_supervised_finetuned_extended.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"✅ Visualization saved to '{save_folder}/comparison_supervised_finetuned_extended.png'\")\n",
        "\n",
        "    return results_df, comb_true_labels_cv, comb_pred_labels_cv # Return results and CV labels for combined features"
      ],
      "metadata": {
        "id": "gAUz5ylss0Nm"
      },
      "id": "gAUz5ylss0Nm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "571e9c80"
      },
      "source": [
        "# 6. Génération de la Matrice de Confusion\n",
        "Objectif : Cette cellule visualise la matrice de confusion pour comprendre où le modèle fine-tuné fait des erreurs de classification entre les différentes catégories de produits.\n",
        "Description : Divise les données (caractéristiques combinées et étiquettes) en ensembles d'entraînement et de test. Entraîne un pipeline PCA + RandomForest sur l'ensemble d'entraînement et prédit les étiquettes sur l'ensemble de test. Calcule la matrice de confusion normalisée. Utilise Seaborn pour visualiser la matrice de confusion sous forme de heatmap, affichant les proportions de vrais positifs, faux positifs et faux négatifs pour chaque paire de catégories. Sauvegarde l'image de la matrice de confusion."
      ],
      "id": "571e9c80"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(features, labels, category_names, save_path=\"result\"):\n",
        "    \"\"\"Generate and plot a normalized confusion matrix.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, labels, test_size=0.2, random_state=SEED, stratify=labels)\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True))\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "    cleaned_category_names = [re.sub(r'^[\\[\\\"\\]]|[\\]\\\"]$', '', name) for name in category_names]\n",
        "\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=sns.light_palette(\"#3498db\", as_cmap=True),\n",
        "                xticklabels=cleaned_category_names, yticklabels=cleaned_category_names,\n",
        "                linewidths=0.5, linecolor='lightgray')\n",
        "    plt.title(\"Matrice de confusion normalisée (Fine-Tuned CLIP)\", fontsize=14, pad=20)\n",
        "    plt.xlabel('Prédictions', fontsize=12)\n",
        "    plt.ylabel('Vraies classes', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "    plt.yticks(rotation=0, fontsize=10)\n",
        "    for _, spine in plt.gca().spines.items():\n",
        "        spine.set_visible(True)\n",
        "        spine.set_color('lightgray')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, 'confusion_matrix_finetuned.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"✅ Confusion matrix saved to '{save_path}/confusion_matrix_finetuned.png'\")"
      ],
      "metadata": {
        "id": "7_Q6oi54s0Qj"
      },
      "id": "7_Q6oi54s0Qj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "790f6e1d"
      },
      "source": [
        "# 7. Visualisation t-SNE\n",
        "Objectif : Cette cellule réduit la dimensionnalité des caractéristiques combinées pour visualiser leur distribution dans un espace 2D et observer la séparation des clusters par catégorie.\n",
        "Description : Applique une PCA pour réduire initialement les caractéristiques combinées, puis utilise t-SNE pour projeter les caractéristiques dans un espace bidimensionnel. Crée un DataFrame avec les coordonnées t-SNE et les étiquettes de catégorie. Utilise Seaborn pour générer un nuage de points (scatterplot) coloré par catégorie, permettant d'évaluer visuellement la qualité du clustering et la distinction entre les différentes classes de produits dans l'espace des caractéristiques apprises par le modèle fine-tuné. Sauvegarde la visualisation t-SNE."
      ],
      "id": "790f6e1d"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tsne(features, labels, category_names, save_path=\"result\"):\n",
        "    \"\"\"Generate t-SNE visualization of features.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    print(\"⏳ Computing t-SNE...\")\n",
        "    pca = PCA(n_components=min(50, features.shape[1]), random_state=SEED)\n",
        "    features_pca = pca.fit_transform(features)\n",
        "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=SEED, init='pca')\n",
        "    tsne_features = tsne.fit_transform(features_pca)\n",
        "    cleaned_category_names = [re.sub(r'^[\\[\\\"\\]]|[\\]\\\"]$', '', name) for name in category_names]\n",
        "    tsne_df = pd.DataFrame({\n",
        "        'x': tsne_features[:, 0],\n",
        "        'y': tsne_features[:, 1],\n",
        "        'category': [cleaned_category_names[i] for i in labels]\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    sns.scatterplot(data=tsne_df, x='x', y='y', hue='category',\n",
        "                    palette=sns.color_palette(\"husl\", len(cleaned_category_names)),\n",
        "                    s=70, alpha=0.8, legend='full')\n",
        "    plt.title(\"Visualisation t-SNE (Fine-Tuned CLIP)\", fontsize=16)\n",
        "    plt.xlabel(\"t-SNE 1\", fontsize=14)\n",
        "    plt.ylabel(\"t-SNE 2\", fontsize=14)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, fontsize=10, title='Catégories', title_fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.2)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, 'tsne_finetuned.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"✅ t-SNE visualization saved ('{save_path}/tsne_finetuned.png')\")"
      ],
      "metadata": {
        "id": "ecvZQJ_Ts0Tk"
      },
      "id": "ecvZQJ_Ts0Tk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80e292d9"
      },
      "source": [
        "# 8. Analyse d'Attention CLIP\n",
        "Objectif : Cette cellule explore les mécanismes d'attention du modèle CLIP fine-tuné pour comprendre quelles parties de l'image et quels mots-clés sont les plus influents dans la représentation apprise pour un produit donné.\n",
        "Description : Définit une fonction `clip_attention_analysis` qui prend l'ID d'un produit, le DataFrame, le modèle, le processeur et le tokenizer. Effectue une décomposition de l'image en patches et calcule la similarité des caractéristiques de chaque patch avec les caractéristiques des mots-clés associés au produit. Visualise ces similarités sur une grille d'images. Calcule également une heatmap d'attention en utilisant des patchs glissants sur l'image entière et la moyenne des scores de similarité avec tous les mots-clés, superposant cette heatmap sur l'image originale pour montrer les régions les plus \"attendues\". Affiche et sauvegarde les visualisations ainsi que les scores de similarité des mots-clés."
      ],
      "id": "80e292d9"
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_attention_analysis(uniq_id, df, model, processor, tokenizer, patch_size=128, resolution=50, category_folder=\"Home Furnishing\"):\n",
        "    \"\"\"Generate CLIP attention interpretability visualizations.\"\"\"\n",
        "    try:\n",
        "        product = df[df['uniq_id'] == uniq_id].iloc[0]\n",
        "        img = Image.open(product['image_path'])\n",
        "        img = img.convert('RGB')  # Ensure RGB format\n",
        "        img_width, img_height = img.size\n",
        "        img_bw = img.convert('L')\n",
        "        enhancer = ImageEnhance.Contrast(img_bw)\n",
        "        img_bw = enhancer.enhance(1.5)\n",
        "        img_bw = np.array(img_bw)\n",
        "        keywords = list(set(kw.strip() for kw in product['keywords'].split(',') if kw.strip()))\n",
        "        print(f\"🔍 Analyse du produit: {product['product_name'][:50]}...\")\n",
        "        print(\"🔠 Mots-clés uniques:\", \", \".join(keywords))\n",
        "\n",
        "        # Create the category folder\n",
        "        os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "        # Decomposition\n",
        "        patches = []\n",
        "        positions = []\n",
        "        step = patch_size\n",
        "        for y in range(0, img_height, step):\n",
        "            for x in range(0, img_width, step):\n",
        "                patch = img.crop((x, y, min(x+patch_size, img_width), min(y+patch_size, img_height)))\n",
        "                if patch.size[0] > 0 and patch.size[1] > 0:\n",
        "                    patch = patch.convert('RGB')  # Ensure patch is RGB\n",
        "                    patch = patch.resize((224, 224), Image.LANCZOS)\n",
        "                    patches.append(patch)\n",
        "                    positions.append((x, y, min(x+patch_size, img_width), min(y+patch_size, img_height)))\n",
        "\n",
        "        if not patches:\n",
        "            raise ValueError(\"No valid patches extracted for decomposition.\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_inputs = tokenizer(keywords[:5], return_tensors=\"pt\", padding=True, truncation=True, max_length=77).to(device)\n",
        "            # Access text features directly from the model instance\n",
        "            text_features = model.get_text_features(**text_inputs)\n",
        "            patch_features = []\n",
        "            for p in patches:\n",
        "                inputs = processor(images=p, return_tensors=\"pt\", padding=True).pixel_values.to(device).float()\n",
        "                if inputs.shape[1] != 3:  # Check for 3 channels (RGB)\n",
        "                    print(f\"⚠️ Patch non-RGB détecté, saut du patch\")\n",
        "                    continue\n",
        "                # Access image features directly from the model instance\n",
        "                features = model.get_image_features(pixel_values=inputs)\n",
        "                patch_features.append(features)\n",
        "                torch.cuda.empty_cache()\n",
        "            if not patch_features:\n",
        "                raise ValueError(\"No valid patch features extracted.\")\n",
        "            patch_features = torch.cat(patch_features)\n",
        "            similarities = (patch_features @ text_features.T).softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "        n = int(np.ceil(len(patches)**0.5))\n",
        "        fig, axes = plt.subplots(n, n, figsize=(15, 15))\n",
        "        axes = axes.flatten()\n",
        "        for idx, (patch, ax) in enumerate(zip(patches, axes)):\n",
        "            ax.imshow(patch)\n",
        "            ax.axis('off')\n",
        "            if idx < len(similarities):\n",
        "                top_concept = keywords[similarities[idx].argmax()]\n",
        "                ax.set_title(f\"{top_concept}\\n{similarities[idx].max():.2f}\", fontsize=8)\n",
        "        for ax in axes[len(patches):]:\n",
        "            ax.axis('off')\n",
        "        plt.suptitle(f\"CLIP Decomposition (Fine-Tuned) - {product['product_name'][:50]}...\", y=0.92)\n",
        "        plt.tight_layout()\n",
        "        decomposition_path = os.path.join(category_folder, f'clip_decomposition_finetuned_{uniq_id}.png')\n",
        "        plt.savefig(decomposition_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Keyword Similarity\n",
        "        with torch.no_grad():\n",
        "            text_inputs = tokenizer(keywords, return_tensors=\"pt\", padding=True, truncation=True, max_length=77).to(device)\n",
        "            image_inputs = processor(images=img, return_tensors=\"pt\").pixel_values.to(device).float()\n",
        "            # Access text features directly from the model instance\n",
        "            text_features = model.get_text_features(**text_inputs)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "            # Access image features directly from the model instance\n",
        "            image_features = model.get_image_features(pixel_values=image_inputs)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "            logits_per_image = (image_features @ text_features.T) / 0.07\n",
        "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()[0]\n",
        "        results = dict(zip(keywords, probs))\n",
        "        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        print(\"\\n📊 Scores de similarité:\")\n",
        "        for kw, prob in sorted_results:\n",
        "            print(f\"- {kw}: {prob:.4f}\")\n",
        "\n",
        "        # Smooth Heatmap with batched processing\n",
        "        torch.cuda.empty_cache()\n",
        "        x = np.linspace(0, img_width, resolution, dtype=int)\n",
        "        y = np.linspace(0, img_height, resolution, dtype=int)\n",
        "        xx, yy = np.meshgrid(x, y)\n",
        "        positions = []\n",
        "        batch_size = 10\n",
        "        patch_features = []\n",
        "        size = min(img_width, img_height) // 10\n",
        "        for i in range(0, resolution * resolution, batch_size):\n",
        "            batch_patches = []\n",
        "            batch_positions = []\n",
        "            for j in range(i, min(i + batch_size, resolution * resolution)):\n",
        "                x_idx = j // resolution\n",
        "                y_idx = j % resolution\n",
        "                x_pos = xx[x_idx, y_idx]\n",
        "                y_pos = yy[x_idx, y_idx]\n",
        "                patch = img.crop((max(0, x_pos - size//2), max(0, y_pos - size//2),\n",
        "                                  min(img_width, x_pos + size//2), min(img_height, y_pos + size//2)))\n",
        "                if patch.size[0] > 0 and patch.size[1] > 0:\n",
        "                    patch = patch.convert('RGB')  # Ensure patch is RGB\n",
        "                    patch = patch.resize((224, 224), Image.LANCZOS)\n",
        "                    batch_patches.append(patch)\n",
        "                    batch_positions.append((x_pos, y_pos))\n",
        "            if batch_patches:\n",
        "                with torch.no_grad():\n",
        "                    inputs = processor(images=batch_patches, return_tensors=\"pt\").pixel_values.to(device).float()\n",
        "                    if inputs.shape[1] != 3:  # Check for 3 channels (RGB)\n",
        "                        print(f\"⚠️ Batch non-RGB détecté, saut du batch\")\n",
        "                        continue\n",
        "                    # Access image features directly from the model instance\n",
        "                    features = model.get_image_features(pixel_values=inputs)\n",
        "                    patch_features.append(features)\n",
        "                positions.extend(batch_positions)\n",
        "                torch.cuda.empty_cache()\n",
        "        if not patch_features:\n",
        "            raise ValueError(\"No valid patches extracted for heatmap.\")\n",
        "        patch_features = torch.cat(patch_features)\n",
        "        patch_features = patch_features / patch_features.norm(dim=-1, keepdim=True)\n",
        "        with torch.no_grad():\n",
        "            # Access text features directly from the model instance\n",
        "            text_features = model.get_text_features(**text_inputs)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "            attention_scores = (patch_features @ text_features.T).cpu().numpy()\n",
        "        points = np.array(positions)\n",
        "        grid_x, grid_y = np.mgrid[0:img_width:complex(0, img_width), 0:img_height:complex(0, img_height)]\n",
        "        smooth_heatmap = griddata(points, attention_scores.mean(axis=1), (grid_x, grid_y), method='cubic', fill_value=0)\n",
        "        smooth_heatmap = (smooth_heatmap - smooth_heatmap.min()) / (smooth_heatmap.max() - smooth_heatmap.min())\n",
        "\n",
        "        plt.figure(figsize=(16, 10))\n",
        "        plt.imshow(img_bw, cmap='gray', vmin=0, vmax=255)\n",
        "        heatmap_layer = plt.imshow(smooth_heatmap.T, cmap='inferno', alpha=0.55, # Transpose heatmap\n",
        "                                  extent=[0, img_width, img_height, 0], interpolation='bicubic')\n",
        "        top_keywords = sorted(zip(keywords, attention_scores.mean(axis=0)), key=lambda x: x[1], reverse=True)[:3]\n",
        "        for kw, score in top_keywords:\n",
        "            kw_idx = keywords.index(kw)\n",
        "            max_pos_idx = np.argmax(attention_scores[:, kw_idx])\n",
        "            max_pos = positions[max_pos_idx]\n",
        "            plt.scatter(max_pos[0], max_pos[1], s=300, edgecolors='white', linewidths=2, facecolors='none')\n",
        "            plt.text(max_pos[0], max_pos[1]+img_height*0.03, f\"{kw}\\n({score:.2f})\",\n",
        "                     color='white', ha='center', va='top', fontsize=11,\n",
        "                     bbox=dict(facecolor='black', alpha=0.7, boxstyle='round,pad=0.5', edgecolor='white', linewidth=1))\n",
        "        cbar = plt.colorbar(heatmap_layer, fraction=0.03, pad=0.01)\n",
        "        cbar.set_label('Intensité d\\'attention', rotation=270, labelpad=15)\n",
        "        plt.title(f\"Heatmap d'attention CLIP (Fine-Tuné) - {product['product_name'][:50]}...\\nProduit: {uniq_id}\", pad=20, fontsize=12)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        heatmap_path = os.path.join(category_folder, f'smooth_attention_finetuned_{uniq_id}.png')\n",
        "        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight', facecolor='black')\n",
        "        plt.close()\n",
        "        print(f\"✅ Heatmap saved as {heatmap_path}\")\n",
        "\n",
        "        return {\n",
        "            'decomposition': similarities,\n",
        "            'keyword_similarities': dict(sorted_results),\n",
        "            'heatmap': smooth_heatmap,\n",
        "            'top_keywords': top_keywords\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ekRUFcPos0Wk"
      },
      "id": "ekRUFcPos0Wk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5821cf1"
      },
      "source": [
        "# 9. Analyse des Produits Représentatifs et des Erreurs de Prédiction par Catégorie\n",
        "Objectif : Cette cellule analyse en détail les produits qui sont les plus \"typiques\" de chaque catégorie (représentatifs) et ceux qui sont le plus souvent mal classés, en utilisant l'analyse d'attention pour comprendre les raisons.\n",
        "Description : Définit la fonction `find_closest_to_centers` pour identifier les produits dont les caractéristiques combinées sont les plus proches du centre (moyenne) de leur cluster (catégorie), les considérant comme des représentants typiques. La fonction `analyze_classification_errors` utilise la validation croisée pour identifier les paires de catégories où les erreurs de classification sont les plus fréquentes, en se basant sur la matrice de confusion. Pour les erreurs les plus courantes, elle sélectionne les produits mal classés et applique l'analyse d'attention CLIP (définie dans la cellule précédente) pour visualiser ce qui a pu conduire à la mauvaise prédiction. Sauvegarde les visualisations et génère un rapport CSV des erreurs."
      ],
      "id": "c5821cf1"
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        original_indices = np.where(labels == label)[0][closest_idx]\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "    results = df.iloc[closest_indices].copy()\n",
        "    results['cluster'] = labels[closest_indices]\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[closest_indices],\n",
        "        [np.mean(features[labels == l], axis=0) for l in labels[closest_indices]]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs('error', exist_ok=True)\n",
        "    print(\"\\n⏳ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\n🔴 Erreur fréquente: '{true_cat}' classé comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"⚠️ Aucun produit trouvé pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = valid_df.iloc[misclassified_indices]\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join('error',\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   🔍 Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=valid_df,\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ✅ MÊME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarité des mots-clés - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarité\")\n",
        "                    plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ✅ Diagramme en barres sauvegardé: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv('error/classification_errors_report.csv', index=False)\n",
        "        print(\"\\n✅ Rapport d'erreurs sauvegardé: 'error/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un résumé\n",
        "        print(\"\\n📊 RÉSUMÉ DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} → {row['predicted_category']}: {row['product_name'][:30]}...\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Aucune erreur de classification trouvée\")\n",
        "\n",
        "    return error_df"
      ],
      "metadata": {
        "id": "-GEG7YK_s0Zq"
      },
      "id": "-GEG7YK_s0Zq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "\n",
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        if cluster_points.shape[0] == 0:\n",
        "            print(f\"⚠️ No points found for label {label}\")\n",
        "            continue\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        # Ensure original_indices correspond to the original dataframe df\n",
        "        original_indices = df[labels == label].iloc[closest_idx].index.tolist()\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "\n",
        "    results = df.loc[closest_indices].copy()\n",
        "    # Map original indices back to labels\n",
        "    results['cluster'] = labels[results.index]\n",
        "    # Recalculate distance to center using the features of the selected products\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[results.index],\n",
        "        [np.mean(features[labels == l], axis=0) for l in results['cluster']]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs('error', exist_ok=True)\n",
        "    print(\"\\n⏳ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\n🔴 Erreur fréquente: '{true_cat}' classé comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"⚠️ Aucun produit trouvé pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = df.iloc[misclassified_indices] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join('error',\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   🔍 Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=df, # Pass the input df which should be the valid_df\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ✅ MÊME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarité des mots-clés - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarité\")\n",
        "                    plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ✅ Diagramme en barres sauvegardé: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv('error/classification_errors_report.csv', index=False)\n",
        "        print(\"\\n✅ Rapport d'erreurs sauvegardé: 'error/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un résumé\n",
        "        print(\"\\n📊 RÉSUMÉ DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} → {row['predicted_category']}: {row['product_name'][:30]}...\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Aucune erreur de classification trouvée\")\n",
        "\n",
        "    return error_df"
      ],
      "metadata": {
        "id": "8yzEznG_YUyA"
      },
      "id": "8yzEznG_YUyA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0436cf4c"
      },
      "source": [
        "# 10. Exécution du Pipeline Complet\n",
        "Objectif : Cette cellule exécute l'ensemble du pipeline d'analyse multimodale, du chargement des données à l'analyse détaillée des résultats, y compris l'évaluation, la visualisation et l'interprétabilité des erreurs.\n",
        "Description : Appelle séquentiellement les fonctions définies dans les cellules précédentes : chargement et nettoyage des données (`load_data`, `process_descriptions_to_keywords`), fine-tuning du modèle CLIP (`fine_tune_clip`), extraction des caractéristiques (`extract_text_features`, `extract_image_features`, `combine_features`), évaluation comparative (`compare_modalities`), génération des visualisations (matrice de confusion et t-SNE), et analyse unifiée des produits représentatifs et des erreurs (`unified_analysis_pipeline`). La fonction `unified_analysis_pipeline` est redéfinie ici pour s'assurer qu'elle est disponible dans ce bloc d'exécution, intégrant les appels aux fonctions d'analyse d'attention et de recherche des représentants. Gère également la gestion de la mémoire GPU et les erreurs potentielles."
      ],
      "id": "0436cf4c"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "\n",
        "# Definition de la fonction unified_analysis_pipeline included here for assurance\n",
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        if cluster_points.shape[0] == 0:\n",
        "            print(f\"⚠️ No points found for label {label}\")\n",
        "            continue\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        # Ensure original_indices correspond to the original dataframe df\n",
        "        original_indices = df[labels == label].iloc[closest_idx].index.tolist()\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "\n",
        "    results = df.loc[closest_indices].copy()\n",
        "    # Map original indices back to labels\n",
        "    results['cluster'] = labels[results.index]\n",
        "    # Recalculate distance to center using the features of the selected products\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[results.index],\n",
        "        [np.mean(features[labels == l], axis=0) for l in results['cluster']]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5, save_folder=\"error\"):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    print(\"\\n⏳ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\n🔴 Erreur fréquente: '{true_cat}' classé comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"⚠️ Aucun produit trouvé pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = df.iloc[misclassified_indices] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join(save_folder,\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   🔍 Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=df, # Pass the input df which should be the valid_df\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ✅ MÊME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values()) # Corrected access\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarité des mots-clés - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarité\")\n",
        "                    plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ✅ Diagramme en barres sauvegardé: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv(os.path.join(save_folder, 'classification_errors_report.csv'), index=False)\n",
        "        print(f\"\\n✅ Rapport d'erreurs sauvegardé: '{save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un résumé\n",
        "        print(\"\\n📊 RÉSUMÉ DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} → {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n✅ Aucune erreur de classification trouvée\")\n",
        "\n",
        "    return error_df\n",
        "\n",
        "def unified_analysis_pipeline(features, true_labels, df, category_names, model, processor, tokenizer,\n",
        "                             analysis_type=\"both\", n_representatives=3, top_n_errors=5):\n",
        "    \"\"\"\n",
        "    Pipeline unifié pour l'analyse des produits représentatifs et des erreurs de classification.\n",
        "\n",
        "    Args:\n",
        "        features: Caractéristiques combinées\n",
        "        true_labels: Étiquettes vraies\n",
        "        df: DataFrame original (should be the valid_df from the main pipeline)\n",
        "        category_names: Noms des catégories\n",
        "        model: Modèle CLIP fine-tuné\n",
        "        processor: Processeur CLIP\n",
        "        tokenizer: Tokenizer CLIP\n",
        "        analysis_type: Type d'analyse (\"representatives\", \"errors\", ou \"both\")\n",
        "        n_representatives: Nombre de produits représentatifs par catégorie\n",
        "        top_n_errors: Nombre d'erreurs principales à analyser\n",
        "    \"\"\"\n",
        "\n",
        "    # Créer les dossiers nécessaires\n",
        "    category_save_folder = 'category'\n",
        "    error_save_folder = 'error'\n",
        "    os.makedirs(category_save_folder, exist_ok=True)\n",
        "    os.makedirs(error_save_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "    if analysis_type in [\"representatives\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES PRODUITS REPRÉSENTATIFS PAR CATÉGORIE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Trouver les produits les plus proches des centres de clusters\n",
        "        print(\"\\n⏳ Recherche des produits les plus proches des centres de clusters...\")\n",
        "        closest_products = find_closest_to_centers(features, true_labels, df, n_examples=n_representatives)\n",
        "\n",
        "\n",
        "        # Traiter chaque catégorie\n",
        "        unique_labels = np.unique(true_labels)\n",
        "        for cluster_id in unique_labels:\n",
        "            category_name = category_names[cluster_id]\n",
        "            print(f\"\\n🏠 Top {n_representatives} produits pour la catégorie '{category_name}':\")\n",
        "\n",
        "            # Créer un dossier pour la catégorie\n",
        "            category_folder = os.path.join(category_save_folder, category_name.replace('/', '_').replace(' ', '_'))\n",
        "            os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "            # Sélectionner les produits pour cette catégorie\n",
        "            category_products = closest_products[closest_products['cluster'] == cluster_id].head(n_representatives)\n",
        "\n",
        "            if category_products.empty:\n",
        "                print(f\"⚠️ Aucun produit trouvé pour la catégorie '{category_name}'\")\n",
        "                continue\n",
        "\n",
        "            # Traiter chaque produit représentatif\n",
        "            for idx, row in category_products.iterrows():\n",
        "                print(f\"\\n🔹 Produit: {row['product_name'][:50]}...\")\n",
        "                print(f\"   📏 Distance au centre: {row['distance_to_center']:.4f}\")\n",
        "\n",
        "                try:\n",
        "                    # Générer l'analyse d'attention CLIP\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=category_folder # Pass the category-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # Générer le diagramme en barres des similarités\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Blues_d\", legend=False)\n",
        "                        plt.title(f\"Scores de similarité - {row['product_name'][:50]}...\")\n",
        "                        plt.xlabel(\"Score de similarité\")\n",
        "                        plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                        # Ajouter les valeurs aux barres\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(category_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        print(f\"✅ Visualisations sauvegardées dans: {category_folder}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Erreur lors de l'analyse du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    if analysis_type in [\"errors\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES ERREURS DE CLASSIFICATION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Générer les prédictions par validation croisée\n",
        "        pipeline = make_pipeline(\n",
        "            PCA(n_components=0.95, random_state=SEED),\n",
        "            RandomForestClassifier(n_estimators=100, random_state=SEED,\n",
        "                                 max_features='sqrt', bootstrap=True)\n",
        "        )\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "        pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "        # Obtenir la matrice de confusion\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "        # Trouver les paires d'erreurs les plus fréquentes\n",
        "        error_pairs = []\n",
        "        for i in range(len(category_names)):\n",
        "            for j in range(len(category_names)):\n",
        "                if i != j and cm[i, j] > 0:\n",
        "                    error_pairs.append((i, j, cm[i, j]))\n",
        "\n",
        "        # Trier par nombre d'erreurs\n",
        "        error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Créer le dataframe d'analyse d'erreurs\n",
        "        error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                       'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "        # Traiter les principales erreurs\n",
        "        for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "            true_cat = category_names[true_idx]\n",
        "            pred_cat = category_names[pred_idx]\n",
        "\n",
        "            print(f\"\\n🔴 Erreur: '{true_cat}' → '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "            # Obtenir les indices des produits mal classés\n",
        "            misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "            if len(misclassified_indices) == 0:\n",
        "                print(\"⚠️ Aucun produit trouvé pour cette paire d'erreur\")\n",
        "                continue\n",
        "\n",
        "            # Créer un sous-dossier pour ce type d'erreur\n",
        "            error_folder = os.path.join(error_save_folder,\n",
        "                                      f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "            os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "            # Traiter chaque produit mal classé\n",
        "            for idx in misclassified_indices:\n",
        "                row = df.iloc[idx] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "                try:\n",
        "                    print(f\"   🔍 Traitement: {row['product_name'][:50]}...\")\n",
        "\n",
        "                    # Générer l'analyse d'attention\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=error_folder # Pass the error-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # Générer le diagramme en barres\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        # CORRECTED: Use 'keyword_similarities' (plural)\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Reds_d\", legend=False)\n",
        "                        plt.title(f\"Erreur: {true_cat} → {pred_cat} - {row['product_name'][:30]}...\")\n",
        "                        plt.xlabel(\"Score de similarité\")\n",
        "                        plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(error_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        # Ajouter au rapport d'erreurs\n",
        "                        error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                            'true_category': true_cat,\n",
        "                            'predicted_category': pred_cat,\n",
        "                            'uniq_id': row['uniq_id'],\n",
        "                            'product_name': row['product_name'],\n",
        "                            'keywords': row['keywords'],\n",
        "                            'error_count': error_count\n",
        "                        }])], ignore_index=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "        # Sauvegarder le rapport d'erreurs\n",
        "        if not error_df.empty:\n",
        "            error_df.to_csv(os.path.join(error_save_folder, 'classification_errors_report.csv'), index=False)\n",
        "            print(f\"\\n✅ Rapport d'erreurs sauvegardé: '{error_save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "            # Afficher le résumé\n",
        "            print(\"\\n📊 RÉSUMÉ DES ERREURS:\")\n",
        "            for _, row in error_df.iterrows():\n",
        "                print(f\"   - {row['true_category']} → {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n✅ Aucune erreur de classification trouvée\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ANALYSE TERMINÉE AVEC SUCCÈS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "# Créer les dossier au début de l'exécution du pipeline\n",
        "os.makedirs('result', exist_ok=True)\n",
        "print(\"✅ Created 'result' folder.\")\n",
        "os.makedirs('category', exist_ok=True)\n",
        "print(\"✅ Created 'category' folder.\")\n",
        "os.makedirs('error', exist_ok=True)\n",
        "print(\"✅ Created 'error' folder.\")\n",
        "os.makedirs('training_analysis', exist_ok=True)\n",
        "print(\"✅ Created 'training_analysis' folder.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    print(\"\\n⏳ Loading data...\")\n",
        "    df = load_data('produits_original.csv', 'images_original')\n",
        "    df = process_descriptions_to_keywords(df)\n",
        "    print(f\"✅ {len(df)} products loaded\")\n",
        "\n",
        "    print(\"\\n⏳ Clearing GPU memory...\")\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    print(\"✅ GPU memory cleared\")\n",
        "\n",
        "    print(\"\\n⏳ Fine-tuning CLIP model...\")\n",
        "    # Modifier l'appel pour récupérer l'historique\n",
        "    model, training_history = fine_tune_clip(df, processor, tokenizer, epochs=5, batch_size=4, accum_steps=4, save_path=\"finetuned_clip\")\n",
        "    model.eval()\n",
        "    print(\"✅ Loaded fine-tuned CLIP model\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "z9ho69Kys0c4"
      },
      "id": "z9ho69Kys0c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "\n",
        "# Definition de la fonction unified_analysis_pipeline included here for assurance\n",
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        if cluster_points.shape[0] == 0:\n",
        "            print(f\"⚠️ No points found for label {label}\")\n",
        "            continue\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        # Ensure original_indices correspond to the original dataframe df\n",
        "        original_indices = df[labels == label].iloc[closest_idx].index.tolist()\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "\n",
        "    results = df.loc[closest_indices].copy()\n",
        "    # Map original indices back to labels\n",
        "    results['cluster'] = labels[results.index]\n",
        "    # Recalculate distance to center using the features of the selected products\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[results.index],\n",
        "        [np.mean(features[labels == l], axis=0) for l in results['cluster']]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5, save_folder=\"error\"):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    print(\"\\n⏳ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\n🔴 Erreur fréquente: '{true_cat}' classé comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"⚠️ Aucun produit trouvé pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = df.iloc[misclassified_indices] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join(save_folder,\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   🔍 Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=df, # Pass the input df which should be the valid_df\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ✅ MÊME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values()) # Corrected access\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarité des mots-clés - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarité\")\n",
        "                    plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ✅ Diagramme en barres sauvegardé: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv(os.path.join(save_folder, 'classification_errors_report.csv'), index=False)\n",
        "        print(f\"\\n✅ Rapport d'erreurs sauvegardé: '{save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un résumé\n",
        "        print(\"\\n📊 RÉSUMÉ DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} → {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n✅ Aucune erreur de classification trouvée\")\n",
        "\n",
        "    return error_df\n",
        "\n",
        "def unified_analysis_pipeline(features, true_labels, df, category_names, model, processor, tokenizer,\n",
        "                             analysis_type=\"both\", n_representatives=3, top_n_errors=5):\n",
        "    \"\"\"\n",
        "    Pipeline unifié pour l'analyse des produits représentatifs et des erreurs de classification.\n",
        "\n",
        "    Args:\n",
        "        features: Caractéristiques combinées\n",
        "        true_labels: Étiquettes vraies\n",
        "        df: DataFrame original (should be the valid_df from the main pipeline)\n",
        "        category_names: Noms des catégories\n",
        "        model: Modèle CLIP fine-tuné\n",
        "        processor: Processeur CLIP\n",
        "        tokenizer: Tokenizer CLIP\n",
        "        analysis_type: Type d'analyse (\"representatives\", \"errors\", ou \"both\")\n",
        "        n_representatives: Nombre de produits représentatifs par catégorie\n",
        "        top_n_errors: Nombre d'erreurs principales à analyser\n",
        "    \"\"\"\n",
        "\n",
        "    # Créer les dossiers nécessaires\n",
        "    category_save_folder = 'category'\n",
        "    error_save_folder = 'error'\n",
        "    os.makedirs(category_save_folder, exist_ok=True)\n",
        "    os.makedirs(error_save_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "    if analysis_type in [\"representatives\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES PRODUITS REPRÉSENTATIFS PAR CATÉGORIE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Trouver les produits les plus proches des centres de clusters\n",
        "        print(\"\\n⏳ Recherche des produits les plus proches des centres de clusters...\")\n",
        "        closest_products = find_closest_to_centers(features, true_labels, df, n_examples=n_representatives)\n",
        "\n",
        "\n",
        "        # Traiter chaque catégorie\n",
        "        unique_labels = np.unique(true_labels)\n",
        "        for cluster_id in unique_labels:\n",
        "            category_name = category_names[cluster_id]\n",
        "            print(f\"\\n🏠 Top {n_representatives} produits pour la catégorie '{category_name}':\")\n",
        "\n",
        "            # Créer un dossier pour la catégorie\n",
        "            category_folder = os.path.join(category_save_folder, category_name.replace('/', '_').replace(' ', '_'))\n",
        "            os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "            # Sélectionner les produits pour cette catégorie\n",
        "            category_products = closest_products[closest_products['cluster'] == cluster_id].head(n_representatives)\n",
        "\n",
        "            if category_products.empty:\n",
        "                print(f\"⚠️ Aucun produit trouvé pour la catégorie '{category_name}'\")\n",
        "                continue\n",
        "\n",
        "            # Traiter chaque produit représentatif\n",
        "            for idx, row in category_products.iterrows():\n",
        "                print(f\"\\n🔹 Produit: {row['product_name'][:50]}...\")\n",
        "                print(f\"   📏 Distance au centre: {row['distance_to_center']:.4f}\")\n",
        "\n",
        "                try:\n",
        "                    # Générer l'analyse d'attention CLIP\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=category_folder # Pass the category-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # Générer le diagramme en barres des similarités\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Blues_d\", legend=False)\n",
        "                        plt.title(f\"Scores de similarité - {row['product_name'][:50]}...\")\n",
        "                        plt.xlabel(\"Score de similarité\")\n",
        "                        plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                        # Ajouter les valeurs aux barres\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(category_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        print(f\"✅ Visualisations sauvegardées dans: {category_folder}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Erreur lors de l'analyse du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    if analysis_type in [\"errors\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES ERREURS DE CLASSIFICATION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Générer les prédictions par validation croisée\n",
        "        pipeline = make_pipeline(\n",
        "            PCA(n_components=0.95, random_state=SEED),\n",
        "            RandomForestClassifier(n_estimators=100, random_state=SEED,\n",
        "                                 max_features='sqrt', bootstrap=True)\n",
        "        )\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "        pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "        # Obtenir la matrice de confusion\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "        # Trouver les paires d'erreurs les plus fréquentes\n",
        "        error_pairs = []\n",
        "        for i in range(len(category_names)):\n",
        "            for j in range(len(category_names)):\n",
        "                if i != j and cm[i, j] > 0:\n",
        "                    error_pairs.append((i, j, cm[i, j]))\n",
        "\n",
        "        # Trier par nombre d'erreurs\n",
        "        error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Créer le dataframe d'analyse d'erreurs\n",
        "        error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                       'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "        # Traiter les principales erreurs\n",
        "        for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "            true_cat = category_names[true_idx]\n",
        "            pred_cat = category_names[pred_idx]\n",
        "\n",
        "            print(f\"\\n🔴 Erreur: '{true_cat}' → '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "            # Obtenir les indices des produits mal classés\n",
        "            misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "            if len(misclassified_indices) == 0:\n",
        "                print(\"⚠️ Aucun produit trouvé pour cette paire d'erreur\")\n",
        "                continue\n",
        "\n",
        "            # Créer un sous-dossier pour ce type d'erreur\n",
        "            error_folder = os.path.join(error_save_folder,\n",
        "                                      f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "            os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "            # Traiter chaque produit mal classé\n",
        "            for idx in misclassified_indices:\n",
        "                row = df.iloc[idx] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "                try:\n",
        "                    print(f\"   🔍 Traitement: {row['product_name'][:50]}...\")\n",
        "\n",
        "                    # Générer l'analyse d'attention\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=error_folder # Pass the error-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # Générer le diagramme en barres\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        # CORRECTED: Use 'keyword_similarities' (plural)\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Reds_d\", legend=False)\n",
        "                        plt.title(f\"Erreur: {true_cat} → {pred_cat} - {row['product_name'][:30]}...\")\n",
        "                        plt.xlabel(\"Score de similarité\")\n",
        "                        plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(error_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        # Ajouter au rapport d'erreurs\n",
        "                        error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                            'true_category': true_cat,\n",
        "                            'predicted_category': pred_cat,\n",
        "                            'uniq_id': row['uniq_id'],\n",
        "                            'product_name': row['product_name'],\n",
        "                            'keywords': row['keywords'],\n",
        "                            'error_count': error_count\n",
        "                        }])], ignore_index=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "        # Sauvegarder le rapport d'erreurs\n",
        "        if not error_df.empty:\n",
        "            error_df.to_csv(os.path.join(error_save_folder, 'classification_errors_report.csv'), index=False)\n",
        "            print(f\"\\n✅ Rapport d'erreurs sauvegardé: '{error_save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "            # Afficher le résumé\n",
        "            print(\"\\n📊 RÉSUMÉ DES ERREURS:\")\n",
        "            for _, row in error_df.iterrows():\n",
        "                print(f\"   - {row['true_category']} → {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n✅ Aucune erreur de classification trouvée\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ANALYSE TERMINÉE AVEC SUCCÈS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "# Créer les dossier au début de l'exécution du pipeline\n",
        "os.makedirs('result', exist_ok=True)\n",
        "print(\"✅ Created 'result' folder.\")\n",
        "os.makedirs('category', exist_ok=True)\n",
        "print(\"✅ Created 'category' folder.\")\n",
        "os.makedirs('error', exist_ok=True)\n",
        "print(\"✅ Created 'error' folder.\")\n",
        "os.makedirs('training_analysis', exist_ok=True)\n",
        "print(\"✅ Created 'training_analysis' folder.\")\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    # Tracer les courbes d'apprentissage\n",
        "    print(\"\\n📊 Plotting training curves...\")\n",
        "    # Correct the parameter name to save_path\n",
        "    summary_df = plot_training_curves(training_history, save_path=\"result/training_analysis\")\n",
        "\n",
        "    # Afficher le résumé des métriques finales\n",
        "    print(\"\\n📊 FINAL METRICS SUMMARY:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Analyser l'overfitting\n",
        "    accuracy_gap = summary_df[summary_df['Metric'] == 'Accuracy']['Gap'].values[0]\n",
        "    if accuracy_gap > 0.1:\n",
        "        print(f\"\\n⚠️  WARNING: Potential overfitting detected! Accuracy gap: {accuracy_gap:.4f}\")\n",
        "    elif accuracy_gap > 0.05:\n",
        "        print(f\"\\nℹ️  Moderate overfitting detected. Accuracy gap: {accuracy_gap:.4f}\")\n",
        "    else:\n",
        "        print(f\"\\n✅ Good generalization. Accuracy gap: {accuracy_gap:.4f}\")\n",
        "\n",
        "    # Le reste du code reste inchangé...\n",
        "    categories_encoded, category_names = pd.factorize(df['main_category'])\n",
        "    print(\"\\n🔍 Extracting features...\")\n",
        "    text_features = extract_text_features(df, model, tokenizer)\n",
        "    image_features, valid_df = extract_image_features(df, model, processor, max_size=128)\n",
        "    valid_categories = categories_encoded[valid_df.index]\n",
        "    combined_features = combine_features(text_features[valid_df.index], image_features, alpha=0.6)\n",
        "\n",
        "    print(\"\\n📊 Evaluating modalities...\")\n",
        "    results_df, true_labels_cv, pred_labels_cv = compare_modalities(df, text_features, image_features, combined_features, categories_encoded, valid_df, valid_categories, save_folder=\"result\")\n",
        "\n",
        "    print(\"\\n📊 Generating visualizations...\")\n",
        "    # Explicitly call with correct parameter name\n",
        "    print(\"Calling plot_confusion_matrix with save_path='result'\")\n",
        "    plot_confusion_matrix(combined_features, valid_categories, category_names, save_path=\"result\")\n",
        "\n",
        "    print(\"Calling plot_tsne with save_path='result'\")\n",
        "    plot_tsne(combined_features, valid_categories, category_names, save_path=\"result\")\n",
        "\n",
        "    print(\"\\n📊 Analyzing classification errors...\")\n",
        "    # Pass the true and predicted labels from cross-validation to the error analysis function\n",
        "    # The error was likely here, passing the wrong arguments.\n",
        "    # We need to pass the valid_categories (true labels for the processed data)\n",
        "    # and the predicted labels from the cross-validation on the combined features.\n",
        "    error_report = analyze_classification_errors(\n",
        "        combined_features,   # Features used for classification (for indexing)\n",
        "        valid_categories,    # True labels for the processed data\n",
        "        valid_df,            # Original DataFrame (for product info)\n",
        "        category_names,      # List of category names\n",
        "        model,               # Fine-tuned CLIP model\n",
        "        processor,           # CLIP processor\n",
        "        tokenizer,           # CLIP tokenizer\n",
        "        top_n_errors=5,\n",
        "        n_splits=5,\n",
        "        save_folder=\"error\"\n",
        "    )\n",
        "    print(\"\\n✅ Error analysis completed\")\n",
        "\n",
        "    print(\"\\n📊 Analyzing representatives and errors...\")\n",
        "    # Utilisation de la fonction unifiée\n",
        "    # The unified_analysis_pipeline also needs the correct true labels (valid_categories)\n",
        "    # and the valid_df (processed dataframe)\n",
        "    unified_analysis_pipeline(\n",
        "        features=combined_features,\n",
        "        true_labels=valid_categories,\n",
        "        df=valid_df,\n",
        "        category_names=category_names,\n",
        "        model=model,\n",
        "        processor=processor,\n",
        "        tokenizer=tokenizer,\n",
        "        analysis_type=\"both\",  # \"representatives\", \"errors\", ou \"both\"\n",
        "        n_representatives=3,\n",
        "        top_n_errors=5\n",
        "    )\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "cycvUxg049om"
      },
      "id": "cycvUxg049om",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06335939"
      },
      "source": [
        "# Specify the product unique ID for attention analysis\n",
        "product_uniq_id_to_analyze = '1120bc768623572513df956172ffefeb'\n",
        "\n",
        "# Find the product in the DataFrame\n",
        "product_row = df[df['uniq_id'] == product_uniq_id_to_analyze]\n",
        "\n",
        "if not product_row.empty:\n",
        "    print(f\"✅ Found product with uniq_id: {product_uniq_id_to_analyze}\")\n",
        "    # Specify a folder for this specific analysis\n",
        "    analysis_folder = \"attention_analysis\"\n",
        "    os.makedirs(analysis_folder, exist_ok=True)\n",
        "\n",
        "    # Call the attention analysis function\n",
        "    attention_results = clip_attention_analysis(\n",
        "        uniq_id=product_uniq_id_to_analyze,\n",
        "        df=df,\n",
        "        model=model,\n",
        "        processor=processor,\n",
        "        tokenizer=tokenizer,\n",
        "        category_folder=analysis_folder # Pass the analysis folder\n",
        "    )\n",
        "\n",
        "    if attention_results:\n",
        "        print(f\"\\n✅ Attention analysis completed for {product_uniq_id_to_analyze}. Results saved in '{analysis_folder}' folder.\")\n",
        "\n",
        "        # Generate and save the keyword similarity bar chart\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        keywords_list = list(attention_results['keyword_similarities'].keys())\n",
        "        scores_list = list(attention_results['keyword_similarities'].values())\n",
        "\n",
        "        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "        plt.title(f\"Scores de similarité des mots-clés - {product_row['product_name'].iloc[0][:50]}...\")\n",
        "        plt.xlabel(\"Score de similarité\")\n",
        "        plt.ylabel(\"Mots-clés\")\n",
        "\n",
        "        # Ajouter les valeurs au bout des barres\n",
        "        for i, score in enumerate(scores_list):\n",
        "            ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        barchart_path = os.path.join(analysis_folder, f'keyword_similarity_barchart_{product_uniq_id_to_analyze}.png')\n",
        "        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(f\"   ✅ Diagramme en barres sauvegardé: {barchart_path}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"❌ Attention analysis failed for {product_uniq_id_to_analyze}.\")\n",
        "else:\n",
        "    print(f\"❌ Product with uniq_id '{product_uniq_id_to_analyze}' not found in the DataFrame.\")"
      ],
      "id": "06335939",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dccf28c"
      },
      "source": [
        "import torch\n",
        "from transformers import CLIPModel, CLIPTokenizer, CLIPProcessor\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "# Ensure the CLIPForClassification class is defined (copying from a previous cell for clarity)\n",
        "# In a real notebook, you would just need to ensure the cell defining this class has been run.\n",
        "class CLIPForClassification(CLIPModel):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__(config)\n",
        "        self.clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\") # Use the same base model name\n",
        "        self.classifier = nn.Linear(config.projection_dim * 2, num_labels)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pixel_values, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.clip(pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = torch.cat((outputs.image_embeds, outputs.text_embeds), dim=-1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return type('Output', (), {\n",
        "            'loss': loss,\n",
        "            'logits': logits,\n",
        "            'image_embeds': outputs.image_embeds,\n",
        "            'text_embeds': outputs.text_embeds\n",
        "        })()\n",
        "\n",
        "def load_finetuned_clip_model(pth_path, num_labels, device):\n",
        "    \"\"\"\n",
        "    Loads the fine-tuned CLIPForClassification model from a .pth state_dict file.\n",
        "    Handles the mismatched keys by loading relevant parts into the model's components.\n",
        "    \"\"\"\n",
        "    # Initialize the model architecture\n",
        "    # Ensure you use the same config and num_labels as during training\n",
        "    config = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").config # Use the same base model name\n",
        "    model = CLIPForClassification(config, num_labels=num_labels).to(device)\n",
        "\n",
        "    # Load the state dictionary\n",
        "    state_dict = torch.load(pth_path, map_location=device)\n",
        "\n",
        "    # Create a new state_dict that matches the CLIPForClassification structure\n",
        "    # This requires knowing the keys saved in the .pth file.\n",
        "    # Based on the error message, the .pth contains the full CLIPModel state_dict.\n",
        "    # We need to load the 'clip' and 'classifier' parts.\n",
        "    model_state_dict = model.state_dict()\n",
        "    new_state_dict = {}\n",
        "\n",
        "    # Manually copy keys for the 'clip' part\n",
        "    # The keys in the loaded state_dict for the base CLIP model don't have the 'clip.' prefix.\n",
        "    # We need to add it to match the keys in model.state_dict()\n",
        "    for k, v in state_dict.items():\n",
        "        if k in model_state_dict:\n",
        "             new_state_dict[k] = v # This handles the classifier keys\n",
        "        elif 'clip.' + k in model_state_dict:\n",
        "             new_state_dict['clip.' + k] = v # This handles the base CLIP model keys\n",
        "\n",
        "    # Load the modified state dictionary into the model\n",
        "    # Use strict=False to ignore keys in model_state_dict that are not in new_state_dict (e.g., logit_scale)\n",
        "    # and keys in new_state_dict that are not in model_state_dict (shouldn't happen if we copied correctly).\n",
        "    # Report missing and unexpected keys for debugging if needed.\n",
        "    load_result = model.load_state_dict(new_state_dict, strict=False)\n",
        "\n",
        "    print(f\"✅ Model loaded successfully from {pth_path}\")\n",
        "    print(f\"Missing keys: {load_result.missing_keys}\")\n",
        "    print(f\"Unexpected keys: {load_result.unexpected_keys}\")\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage (you need to define num_labels based on your training data)\n",
        "# Let's assume num_labels is the number of unique categories in your training data.\n",
        "# You would need to get this value from your original data loading step.\n",
        "# For demonstration, let's assume you know the number of categories.\n",
        "# In a real scenario, you might save the number of labels during training or reload the data.\n",
        "# For now, replace 'YOUR_NUMBER_OF_LABELS' with the actual number of unique categories.\n",
        "# You can get this from the 'category_names' variable after running the data loading cell.\n",
        "\n",
        "# Assuming 'category_names' is available from previous execution\n",
        "if 'category_names' in locals():\n",
        "    num_labels = len(category_names)\n",
        "    print(f\"Detected {num_labels} labels from previous execution.\")\n",
        "    try:\n",
        "        finetuned_model = load_finetuned_clip_model(\n",
        "            pth_path=\"new_clip_product_classifier.pth\",\n",
        "            num_labels=num_labels,\n",
        "            device=device # Use the device defined in the first cell\n",
        "        )\n",
        "        print(\"✅ Fine-tuned model loaded for inference.\")\n",
        "        # You can now use 'finetuned_model' for predictions or feature extraction\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"❌ Error: 'new_clip_product_classifier.pth' not found. Please run the fine-tuning cell first.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred during model loading: {str(e)}\")\n",
        "else:\n",
        "    print(\"⚠️ 'category_names' variable not found. Please run the data loading cell (Cell 2) first to define it.\")\n",
        "    print(\"You will need to manually set 'num_labels' or ensure 'category_names' is available before running this cell.\")"
      ],
      "id": "0dccf28c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}