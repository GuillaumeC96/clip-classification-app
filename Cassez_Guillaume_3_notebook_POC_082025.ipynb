{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "799041a5"
      },
      "source": [
        "# 1. Configuration Initiale et Chargement des Mod√®les\n",
        "Objectif : Cette cellule configure l'environnement et charge les mod√®les n√©cessaires (CLIP et spaCy) pour l'analyse multimodale.\n",
        "Description : Configure les variables d'environnement pour la reproductibilit√© (graines al√©atoires, d√©terminisme CUDA). Initialise le mod√®le CLIP pr√©-entra√Æn√© pour l'extraction de caract√©ristiques visuelles et textuelles, ainsi que le mod√®le spaCy pour le traitement du texte. V√©rifie √©galement la disponibilit√© et l'utilisation du GPU."
      ],
      "id": "799041a5"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pillow torchvision transformers scikit-learn\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageFile, ImageEnhance\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import CLIPModel, CLIPTokenizer, CLIPProcessor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score\n",
        "from sklearn.metrics import adjusted_rand_score, confusion_matrix, precision_score, recall_score, roc_auc_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, cross_val_predict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import random\n",
        "from scipy.interpolate import griddata\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# Configuration for large images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "# Reproducibility configuration\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "# GPU/CPU configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize CLIP model\n",
        "MODEL_NAME = 'openai/clip-vit-base-patch32'  # Changed to smaller model\n",
        "try:\n",
        "    model = CLIPModel.from_pretrained(MODEL_NAME).to(device)\n",
        "    tokenizer = CLIPTokenizer.from_pretrained(MODEL_NAME)\n",
        "    processor = CLIPProcessor.from_pretrained(MODEL_NAME)\n",
        "    print(\"‚úÖ CLIP model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to load CLIP model: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_trf\")\n",
        "    print(\"‚úÖ spaCy model loaded successfully\")\n",
        "except:\n",
        "    print(\"‚è≥ Downloading spaCy model...\")\n",
        "    os.system(\"python -m spacy download en_core_web_trf\")\n",
        "    nlp = spacy.load(\"en_core_web_trf\")\n",
        "\n",
        "# Ensure spaCy uses GPU if available\n",
        "try:\n",
        "    spacy.require_gpu()\n",
        "    print(\"‚úÖ spaCy using GPU\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è spaCy not using GPU (CUDA not found or configured)\")"
      ],
      "metadata": {
        "id": "iDzYZbsLs0B-"
      },
      "id": "iDzYZbsLs0B-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56c062bb"
      },
      "source": [
        "# 2. Chargement et Nettoyage des Donn√©es\n",
        "Objectif : Cette cellule charge le jeu de donn√©es des produits, nettoie les informations textuelles et pr√©pare les chemins d'acc√®s aux images pour un traitement ult√©rieur.\n",
        "Description : Lit les donn√©es √† partir d'un fichier CSV. Effectue un nettoyage approfondi des champs textuels (nom du produit, description, sp√©cifications), y compris la gestion des valeurs manquantes et l'application de r√®gles de nettoyage sp√©cifiques. V√©rifie l'existence et la validit√© des fichiers image associ√©s et filtre les entr√©es probl√©matiques. Extrait √©galement la cat√©gorie principale de chaque produit."
      ],
      "id": "56c062bb"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text by replacing specific patterns and removing unwanted symbols, numbers, and punctuation.\n",
        "       Apply patterns twice to ensure complete replacement.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    all_patterns = [\n",
        "        # Transformation des motifs comme iphone4s en iphone s\n",
        "        (r'([a-zA-Z]+)(\\d+)([a-zA-Z])', r'\\1 \\3'),\n",
        "        # Abr√©viations d'indice solaire\n",
        "        (r'\\bpa\\+{1,3}\\b', 'sun protection factor'),\n",
        "        # Symboles ind√©sirables\n",
        "        (r'[@*/¬±&%#]', ' '),  # Supprime @, *, /, ¬±, &, %, #\n",
        "        # Codes alphanum√©riques non pertinents (ex. ms004pktbl, r&m0179)\n",
        "        (r'\\b[A-Z0-9]+[-_][A-Z0-9]+\\b', ' '),\n",
        "        # Nombres seuls\n",
        "        (r'\\b\\d+\\b', ' '),\n",
        "        # Ponctuation sp√©cifique\n",
        "        (r'\\(', ' ( '),\n",
        "        (r'\\)', ' ) '),\n",
        "        (r'\\.', ' . '),\n",
        "        (r'\\!', ' ! '),\n",
        "        (r'\\?', ' ? '),\n",
        "        (r'\\:', ' : '),\n",
        "        (r'\\,', ', '),\n",
        "        # Motifs sp√©cifiques du domaine\n",
        "        (r'\\b(\\d+)\\s*[-~to]?\\s*(\\d+)\\s*(m|mth|mths|month|months?)\\b', 'month'),\n",
        "        (r'\\bnewborn\\s*[-~to]?\\s*(\\d+)\\s*(m|mth|months?)\\b', 'month'),\n",
        "        (r'\\b(nb|newborn|baby|bb|bby|babie|babies)\\b', 'baby'),\n",
        "        (r'\\b(diaper|diapr|nappy)\\b', 'diaper'),\n",
        "        (r'\\b(stroller|pram|buggy)\\b', 'stroller'),\n",
        "        (r'\\b(bpa\\s*free|non\\s*bpa)\\b', 'bisphenol a free'),\n",
        "        (r'\\b(\\d+)\\s*(oz|ounce)\\b', 'ounce'),\n",
        "        (r'\\b(rtx\\s*\\d+)\\b', 'ray tracing graphics'),\n",
        "        (r'\\b(gtx\\s*\\d+)\\b', 'geforce graphics'),\n",
        "        (r'\\bnvidia\\b', 'nvidia'),\n",
        "        (r'\\b(amd\\s*radeon\\s*rx\\s*\\d+)\\b', 'amd radeon graphics'),\n",
        "        (r'\\b(intel\\s*(core|xeon)\\s*[i\\d-]+)\\b', 'intel processor'),\n",
        "        (r'\\b(amd\\s*ryzen\\s*[\\d]+)\\b', 'amd ryzen processor'),\n",
        "        (r'\\bssd\\b', 'solid state drive'),\n",
        "        (r'\\bhdd\\b', 'hard disk drive'),\n",
        "        (r'\\bwifi\\s*([0-9])\\b', 'wi-fi standard'),\n",
        "        (r'\\bbluetooth\\s*(\\d\\.\\d)\\b', 'bluetooth version'),\n",
        "        (r'\\bethernet\\b', 'ethernet'),\n",
        "        (r'\\bfhd\\b', 'full high definition'),\n",
        "        (r'\\buhd\\b', 'ultra high definition'),\n",
        "        (r'\\bqhd\\b', 'quad high definition'),\n",
        "        (r'\\boled\\b', 'organic light emitting diode'),\n",
        "        (r'\\bips\\b', 'in-plane switching'),\n",
        "        (r'\\bram\\b', 'random access memory'),\n",
        "        (r'\\bcpu\\b', 'central processing unit'),\n",
        "        (r'\\bgpu\\b', 'graphics processing unit'),\n",
        "        (r'\\bhdmi\\b', 'high definition multimedia interface'),\n",
        "        (r'\\busb\\s*([a-z0-9]*)\\b', 'universal serial bus'),\n",
        "        (r'\\brgb\\b', 'red green blue'),\n",
        "        (r'\\bfridge\\b', 'refrigerator'),\n",
        "        (r'\\bwashing\\s*machine\\b', 'clothes washer'),\n",
        "        (r'\\bdishwasher\\b', 'dish washing machine'),\n",
        "        (r'\\boven\\b', 'cooking oven'),\n",
        "        (r'\\bmicrowave\\b', 'microwave oven'),\n",
        "        (r'\\bhoover\\b', 'vacuum cleaner'),\n",
        "        (r'\\btumble\\s*dryer\\b', 'clothes dryer'),\n",
        "        (r'\\b(a\\+\\++)\\b', 'energy efficiency class'),\n",
        "        (r'\\b(\\d+)\\s*btu\\b', 'british thermal unit'),\n",
        "        (r'\\bpoly\\b', 'polyester'),\n",
        "        (r'\\bacrylic\\b', 'acrylic fiber'),\n",
        "        (r'\\bnylon\\b', 'nylon fiber'),\n",
        "        (r'\\bspandex\\b', 'spandex fiber'),\n",
        "        (r'\\blycra\\b', 'lycra fiber'),\n",
        "        (r'\\bpvc\\b', 'polyvinyl chloride'),\n",
        "        (r'\\bvinyl\\b', 'vinyl material'),\n",
        "        (r'\\bstainless\\s*steel\\b', 'stainless steel'),\n",
        "        (r'\\baluminum\\b', 'aluminum metal'),\n",
        "        (r'\\bplexiglass\\b', 'acrylic glass'),\n",
        "        (r'\\bpu\\s*leather\\b', 'polyurethane leather'),\n",
        "        (r'\\bsynthetic\\s*leather\\b', 'synthetic leather'),\n",
        "        (r'\\bfaux\\s*leather\\b', 'faux leather'),\n",
        "        (r'\\bwaterproof\\b', 'water resistant'),\n",
        "        (r'\\bbreathable\\b', 'air permeable'),\n",
        "        (r'\\bwrinkle-free\\b', 'wrinkle resistant'),\n",
        "        (r'\\bSPF\\b', 'sun protection factor'),\n",
        "        (r'\\bUV\\b', 'ultraviolet'),\n",
        "        (r'\\bBB\\s*cream\\b', 'blemish balm cream'),\n",
        "        (r'\\bCC\\s*cream\\b', 'color correcting cream'),\n",
        "        (r'\\bHA\\b', 'hyaluronic acid'),\n",
        "        (r'\\bAHA\\b', 'alpha hydroxy acid'),\n",
        "        (r'\\bBHA\\b', 'beta hydroxy acid'),\n",
        "        (r'\\bPHA\\b', 'polyhydroxy acid'),\n",
        "        (r'\\bNMF\\b', 'natural moisturizing factor'),\n",
        "        (r'\\bEGF\\b', 'epidermal growth factor'),\n",
        "        (r'\\bVit\\s*C\\b', 'vitamin c'),\n",
        "        (r'\\bVit\\s*E\\b', 'vitamin e'),\n",
        "        (r'\\bVit\\s*B3\\b', 'niacinamide vitamin b3'),\n",
        "        (r'\\bVit\\s*B5\\b', 'panthenol vitamin b5'),\n",
        "        (r'\\bSOD\\b', 'superoxide dismutase'),\n",
        "        (r'\\bQ10\\b', 'coenzyme q10'),\n",
        "        (r'\\bFoam\\s*cl\\b', 'foam cleanser'),\n",
        "        (r'\\bMic\\s*H2O\\b', 'micellar water'),\n",
        "        (r'\\bToner\\b', 'skin toner'),\n",
        "        (r'\\bEssence\\b', 'skin essence'),\n",
        "        (r'\\bAmpoule\\b', 'concentrated serum'),\n",
        "        (r'\\bCF\\b', 'cruelty free'),\n",
        "        (r'\\bPF\\b', 'paraben free'),\n",
        "        (r'\\bSF\\b', 'sulfate free'),\n",
        "        (r'\\bGF\\b', 'gluten free'),\n",
        "        (r'\\bHF\\b', 'hypoallergenic formula'),\n",
        "        (r'\\bNT\\b', 'non-comedogenic tested'),\n",
        "        (r'\\bAM\\b', 'morning'),\n",
        "        (r'\\bPM\\b', 'night'),\n",
        "        (r'\\bBID\\b', 'twice daily'),\n",
        "        (r'\\bQD\\b', 'once daily'),\n",
        "        (r'\\bAIR\\b', 'airless pump bottle'),\n",
        "        (r'\\bD-C\\b', 'dropper container'),\n",
        "        (r'\\bT-C\\b', 'tube container'),\n",
        "        (r'\\bPDO\\b', 'polydioxanone'),\n",
        "        (r'\\bPCL\\b', 'polycaprolactone'),\n",
        "        (r'\\bPLLA\\b', 'poly-l-lactic acid'),\n",
        "        (r'\\bHIFU\\b', 'high-intensity focused ultrasound'),\n",
        "        (r'\\b(\\d+)\\s*fl\\s*oz\\b', 'fluid ounce'),\n",
        "        (r'\\bpH\\s*bal\\b', 'ph balanced'),\n",
        "        (r'\\b(\\d+)\\s*(gb|tb|mb|go|to|mo)\\b', 'byte'),\n",
        "        (r'\\boctet\\b', 'byte'),\n",
        "        (r'\\b(\\d+)\\s*y\\b', 'year'),\n",
        "        (r'\\b(\\d+)\\s*mth\\b', 'month'),\n",
        "        (r'\\b(\\d+)\\s*d\\b', 'day'),\n",
        "        (r'\\b(\\d+)\\s*h\\b', 'hour'),\n",
        "        (r'\\b(\\d+)\\s*min\\b', 'minute'),\n",
        "        (r'\\b(\\d+)\\s*rpm\\b', 'revolution per minute'),\n",
        "        (r'\\b(\\d+)\\s*(mw|cw|kw)\\b', 'watt'),\n",
        "        (r'\\b(\\d+)\\s*(ma|ca|ka)\\b', 'ampere'),\n",
        "        (r'\\b(\\d+)\\s*(mv|cv|kv)\\b', 'volt'),\n",
        "        (r'\\b(\\d+)\\s*(mm|cm|m|km)\\b', 'meter'),\n",
        "        (r'\\binch\\b', 'meter'),\n",
        "        (r'\\b(\\d+)\\s*(ml|cl|dl|l|oz|gal)\\b', 'liter'),\n",
        "        (r'\\b(gallon|ounce)\\b', 'liter'),\n",
        "        (r'\\b(\\d+)\\s*(mg|cg|dg|g|kg|lb)\\b', 'gram'),\n",
        "        (r'\\bpound\\b', 'gram'),\n",
        "        (r'\\b(\\d+)\\s*(¬∞c|¬∞f)\\b', 'celsius'),\n",
        "        (r'\\bfahrenheit\\b', 'celsius'),\n",
        "        (r'\\bflipkart\\.com\\b', ''),\n",
        "        (r'\\bapprox\\.?\\b', 'approximately'),\n",
        "        (r'\\bw/o\\b', 'without'),\n",
        "        (r'\\bw/\\b', 'with'),\n",
        "        (r'\\bant-\\b', 'anti'),\n",
        "        (r'\\byes\\b', ''),\n",
        "        (r'\\bno\\b', ''),\n",
        "        (r'\\bna\\b', ''),\n",
        "        (r'\\brs\\.?\\b', ''),\n",
        "        # Normaliser les espaces\n",
        "        (r'\\s+', ' '),\n",
        "    ]\n",
        "    # Apply patterns twice to ensure complete replacement\n",
        "    for _ in range(2):\n",
        "        for pattern, replacement in all_patterns:\n",
        "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_keywords(text, nlp, top_n=15):\n",
        "    \"\"\"Extract keywords from text using lemmatization and stopword removal,\n",
        "       filtering out potential product references, specific codes, and short words.\"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    doc = nlp(text)\n",
        "    keywords = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower().strip()\n",
        "        # Skip short words, punctuation, stopwords, empty lemmas, and unwanted patterns\n",
        "        if (len(lemma) < 2 or\n",
        "            token.is_punct or\n",
        "            not lemma or\n",
        "            token.is_stop or\n",
        "            re.match(r'.*[@*/¬±&%#].*', lemma)):  # Exclure les mots avec symboles ind√©sirables\n",
        "            continue\n",
        "        keywords.append(lemma)\n",
        "    keyword_counts = Counter(keywords)\n",
        "    return [word for word, count in keyword_counts.most_common(top_n)]\n",
        "\n",
        "def process_descriptions_to_keywords(df, uniq_id=None):\n",
        "    \"\"\"Convert processed_text to comma-separated keywords and generate keyword frequencies CSV.\n",
        "       If uniq_id is provided, generate CSV for that specific product only.\"\"\"\n",
        "    print(\"‚è≥ Loading spaCy model...\")\n",
        "    try:\n",
        "        nlp = spacy.load(\"en_core_web_trf\")\n",
        "        # Ensure spaCy uses GPU if available\n",
        "        try:\n",
        "            spacy.require_gpu()\n",
        "            print(\"‚úÖ spaCy using GPU\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è spaCy not using GPU (CUDA not found or configured)\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load spaCy model: {str(e)}\")\n",
        "        print(\"‚è≥ Downloading spaCy model...\")\n",
        "        os.system(\"python -m spacy download en_core_web_trf\")\n",
        "        nlp = spacy.load(\"en_core_web_trf\")\n",
        "    print(\"üîç Extracting keywords from descriptions...\")\n",
        "\n",
        "    # Extract keywords for all products or a specific product\n",
        "    if uniq_id is not None:\n",
        "        df_subset = df[df['uniq_id'] == uniq_id].copy()\n",
        "        if df_subset.empty:\n",
        "            print(f\"‚ùå No product found with uniq_id: {uniq_id}\")\n",
        "            return df\n",
        "        df_subset['keywords'] = df_subset['processed_text'].apply(lambda x: \", \".join(extract_keywords(x, nlp)))\n",
        "        df_subset['keywords'] = df_subset['keywords'].replace('', 'no_keywords_found')\n",
        "        all_keywords = []\n",
        "        for kws in df_subset['keywords']:\n",
        "            if kws != 'no_keywords_found':\n",
        "                all_keywords.extend(kws.split(\", \"))\n",
        "        output_csv = f'keyword_frequencies_{uniq_id}.csv'\n",
        "        print(f\"‚úÖ Keywords extracted for product {uniq_id}\")\n",
        "    else:\n",
        "        df['keywords'] = df['processed_text'].apply(lambda x: \", \".join(extract_keywords(x, nlp)))\n",
        "        df['keywords'] = df['keywords'].replace('', 'no_keywords_found')\n",
        "        all_keywords = []\n",
        "        for kws in df['keywords']:\n",
        "            if kws != 'no_keywords_found':\n",
        "                all_keywords.extend(kws.split(\", \"))\n",
        "        output_csv = 'keyword_frequencies.csv'\n",
        "        print(f\"‚úÖ Keywords extracted for {len(df)} products\")\n",
        "\n",
        "    # Generate keyword frequencies\n",
        "    keyword_freq = Counter(all_keywords)\n",
        "    keyword_freq_df = pd.DataFrame(list(keyword_freq.items()), columns=['Mot Cl√©', 'Fr√©quence'])\n",
        "    keyword_freq_df = keyword_freq_df.sort_values(by='Fr√©quence', ascending=False)\n",
        "\n",
        "    # Save to CSV\n",
        "    keyword_freq_df.to_csv(output_csv, index=False, encoding='utf-8')\n",
        "    print(f\"‚úÖ Keyword frequencies saved to {output_csv}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_data(filepath, image_folder, uniq_id=None):\n",
        "    \"\"\"\n",
        "    Load data and prepare image paths with advanced text cleaning and handling of problematic images.\n",
        "    Allow description and product_specifications to be NaN or null. Resize large images to fit pixel limit.\n",
        "    Suppress image size logging. Optionally process a single product by uniq_id.\n",
        "    Save the updated DataFrame with keywords back to produits_original.csv.\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = pd.read_csv(filepath)\n",
        "    original_count = len(df)\n",
        "    print(f\"Initial product count: {original_count}\")\n",
        "\n",
        "    # If uniq_id is provided, filter to that product\n",
        "    if uniq_id is not None:\n",
        "        df = df[df['uniq_id'] == uniq_id]\n",
        "        if df.empty:\n",
        "            raise ValueError(f\"No product found with uniq_id: {uniq_id}\")\n",
        "        print(f\"Processing single product with uniq_id: {uniq_id}\")\n",
        "\n",
        "    # Step 1: Drop rows with NaN in required fields (product_name, product_category_tree, image)\n",
        "    required_columns = ['product_name', 'product_category_tree', 'image']\n",
        "    df = df.dropna(subset=required_columns)\n",
        "    print(f\"After dropping NaN in required columns ({required_columns}): {len(df)} rows remain\")\n",
        "    dropped_nan = df[df[required_columns].isna().any(axis=1)]\n",
        "    if not dropped_nan.empty:\n",
        "        print(\"Dropped due to NaN in required columns:\", dropped_nan['uniq_id'].tolist())\n",
        "\n",
        "    # Step 2: Filter empty strings in required fields\n",
        "    df = df[(df['product_name'] != '') & (df['product_category_tree'] != '') & (df['image'] != '')]\n",
        "    print(f\"After filtering empty strings in required columns: {len(df)} rows remain\")\n",
        "    dropped_empty = df[(df['product_name'] == '') | (df['product_category_tree'] == '') | (df['image'] == '')]\n",
        "    if not dropped_empty.empty:\n",
        "        print(\"Dropped due to empty strings in required columns:\", dropped_empty['uniq_id'].tolist())\n",
        "\n",
        "    # Step 3: Extract and clean main category\n",
        "    df['main_category'] = df['product_category_tree'].str.split(' >> ').str[0]\n",
        "    df['main_category'] = df['main_category'].str.replace(r'[\\[\\]\\\"\\']', '', regex=True)\n",
        "    df = df[df['main_category'] != '']\n",
        "    print(f\"After filtering empty categories: {len(df)} rows remain\")\n",
        "    dropped_category = df[df['main_category'] == '']\n",
        "    if not dropped_category.empty:\n",
        "        print(\"Dropped due to empty categories:\", dropped_category['uniq_id'].tolist())\n",
        "\n",
        "    # Step 4: Check image existence and validity\n",
        "    df['image_path'] = df['uniq_id'].apply(lambda x: os.path.join(image_folder, f\"{x}.jpg\"))\n",
        "    df['image_exists'] = df['image_path'].apply(lambda x: any(\n",
        "        os.path.exists(os.path.join(image_folder, f\"{x}.{ext}\"))\n",
        "        for ext in ['jpg', 'JPG', 'jpeg', 'JPEG']\n",
        "    ))\n",
        "    def is_valid_image(path):\n",
        "        try:\n",
        "            with Image.open(path) as img:\n",
        "                img.verify()  # Verify image integrity\n",
        "                img = Image.open(path)  # Re-open after verify\n",
        "                pixel_count = img.size[0] * img.size[1]\n",
        "                max_pixels = 89478485\n",
        "                if pixel_count > max_pixels:\n",
        "                    # Calculate scaling factor to fit within max_pixels while preserving aspect ratio\n",
        "                    scale = (max_pixels / pixel_count) ** 0.5\n",
        "                    new_size = (int(img.size[0] * scale), int(img.size[1] * scale))\n",
        "                    img = img.resize(new_size, Image.LANCZOS)\n",
        "                    # Save resized image to a temporary path to avoid modifying original\n",
        "                    temp_path = path.replace('.jpg', '_resized.jpg')\n",
        "                    img.save(temp_path, 'JPEG', quality=95)\n",
        "                    return temp_path\n",
        "                return path\n",
        "        except Exception as e:\n",
        "            print(f\"Invalid image {path}: {str(e)}\")\n",
        "            return False\n",
        "    df['image_valid_path'] = df['image_path'].apply(is_valid_image)\n",
        "    dropped_images = df[df['image_valid_path'] == False]\n",
        "    if not dropped_images.empty:\n",
        "        print(\"Dropped due to missing or invalid images:\", dropped_images['uniq_id'].tolist())\n",
        "    df = df[df['image_valid_path'] != False].copy()\n",
        "    df['image_path'] = df['image_valid_path']  # Update image_path with resized path if applicable\n",
        "    df = df.drop(columns=['image_exists', 'image_valid_path'])\n",
        "    print(f\"After filtering invalid images: {len(df)} rows remain\")\n",
        "\n",
        "    # Step 5: Process text, allowing NaN for description and product_specifications\n",
        "    def process_specs(spec_string):\n",
        "        if not isinstance(spec_string, str):\n",
        "            return \"\"\n",
        "        matches = re.findall(r'\\{\"key\"=>\"(.*?)\", \"value\"=>\"(.*?)\"\\}', spec_string)\n",
        "        return \". \".join(f\"{k.strip().lower()} {v.strip().lower()}\" for k, v in matches if k.strip() and v.strip())\n",
        "\n",
        "    # Replace NaN with empty strings for description and product_specifications\n",
        "    df['description'] = df['description'].fillna('')\n",
        "    df['product_specifications'] = df['product_specifications'].fillna('')\n",
        "    df['cleaned_specs'] = df['product_specifications'].apply(process_specs)\n",
        "    df['combined_text'] = (\n",
        "        df['product_name'].str.lower() + '. ' +\n",
        "        df['brand'].fillna('').str.lower() + '. ' +\n",
        "        df['cleaned_specs'].str.lower() + '. ' +\n",
        "        df['description'].str.lower()\n",
        "    )\n",
        "    df['processed_text'] = df['combined_text'].apply(clean_text)\n",
        "    dropped_text = df[(df['processed_text'].str.strip() == '') | (df['processed_text'].str.split().str.len() <= 3)]\n",
        "    if not dropped_text.empty:\n",
        "        print(\"Dropped due to empty or short text:\", dropped_text['uniq_id'].tolist())\n",
        "    df = df[(df['processed_text'].str.strip() != '') & (df['processed_text'].str.split().str.len() > 3)]\n",
        "    print(f\"After filtering short text: {len(df)} rows remain\")\n",
        "\n",
        "    # Step 6: Extract keywords\n",
        "    df = process_descriptions_to_keywords(df, uniq_id=uniq_id)\n",
        "\n",
        "    # Step 7: Save the updated DataFrame to produits_original.csv (only if processing all products)\n",
        "    if uniq_id is None:\n",
        "        # Keep only the original columns plus 'keywords'\n",
        "        original_columns = pd.read_csv(filepath).columns.tolist()\n",
        "        save_columns = original_columns + ['keywords']\n",
        "        df[save_columns].to_csv(filepath, index=False, encoding='utf-8')\n",
        "        print(f\"‚úÖ Updated DataFrame with keywords saved to {filepath}\")\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(\"DataFrame vide apr√®s nettoyage. V√©rifiez les donn√©es sources.\")\n",
        "    return df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "5ekN_03Fs0Ey"
      },
      "id": "5ekN_03Fs0Ey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0370a258"
      },
      "source": [
        "# 3. Fine-Tuning du Mod√®le CLIP\n",
        "Objectif : Cette cellule adapte le mod√®le CLIP √† la t√¢che sp√©cifique de classification des produits en le fine-tunant sur le jeu de donn√©es pr√©par√©.\n",
        "Description : D√©finit une classe personnalis√©e `CLIPForClassification` qui ajoute une couche de classification sur le mod√®le CLIP. Cr√©e un `ProductDataset` personnalis√© pour g√©rer le chargement des images et du texte, y compris le redimensionnement des images et la tokenisation du texte. Configure l'entra√Ænement du mod√®le avec un optimiseur et un scaler pour l'autocasting GPU. Effectue le fine-tuning sur plusieurs √©poques et sauvegarde le mod√®le fine-tun√©."
      ],
      "id": "0370a258"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "class CLIPForClassification(CLIPModel):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__(config)\n",
        "        self.clip = CLIPModel.from_pretrained(MODEL_NAME)\n",
        "        self.classifier = nn.Linear(config.projection_dim * 2, num_labels)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pixel_values, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.clip(pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = torch.cat((outputs.image_embeds, outputs.text_embeds), dim=-1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return type('Output', (), {\n",
        "            'loss': loss,\n",
        "            'logits': logits,\n",
        "            'image_embeds': outputs.image_embeds,\n",
        "            'text_embeds': outputs.text_embeds\n",
        "        })()\n",
        "\n",
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, df, processor, tokenizer, max_size=128, max_length=77):  # Reduced max_size\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_size = max_size\n",
        "        self.max_length = max_length\n",
        "        self.labels = pd.factorize(df['main_category'])[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = row['image_path']\n",
        "        text = row['keywords']\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                if max(img.size) > self.max_size:\n",
        "                    ratio = self.max_size / max(img.size)\n",
        "                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
        "                    img = img.resize(new_size, Image.LANCZOS)\n",
        "                image_inputs = self.processor(images=img, return_tensors=\"pt\", padding=True).pixel_values.squeeze(0)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Skipping image {img_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            text_inputs = self.tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=self.max_length\n",
        "            )\n",
        "            return {\n",
        "                'pixel_values': image_inputs,\n",
        "                'input_ids': text_inputs['input_ids'].squeeze(0),\n",
        "                'attention_mask': text_inputs['attention_mask'].squeeze(0),\n",
        "                'labels': torch.tensor(label, dtype=torch.long)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Skipping text for index {idx}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "def fine_tune_clip(df, processor, tokenizer, epochs=5, batch_size=4, accum_steps=4, save_path=\"finetuned_clip\"):\n",
        "    \"\"\"Fine-tune the CLIP model with a classification head and save it.\"\"\"\n",
        "    num_labels = len(df['main_category'].unique())\n",
        "    try:\n",
        "        config = CLIPModel.from_pretrained(MODEL_NAME).config\n",
        "        model = CLIPForClassification(config, num_labels=num_labels).to(device)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize CLIPForClassification: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-6)\n",
        "    scaler = GradScaler('cuda')\n",
        "    dataset = ProductDataset(df, processor, tokenizer, max_size=128, max_length=77)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        batch = [item for item in batch if item is not None]\n",
        "        if not batch:\n",
        "            return None\n",
        "        return {\n",
        "            'pixel_values': torch.stack([item['pixel_values'] for item in batch]),\n",
        "            'input_ids': torch.stack([item['input_ids'] for item in batch]),\n",
        "            'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n",
        "            'labels': torch.stack([item['labels'] for item in batch])\n",
        "        }\n",
        "\n",
        "    # Split dataset into train and validation\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED)\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "    effective_batch_size = batch_size * accum_steps\n",
        "    print(f\"Using batch_size={batch_size}, accum_steps={accum_steps}, effective_batch_size={effective_batch_size}\")\n",
        "\n",
        "    # Store training history\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_accuracy': [],\n",
        "        'val_accuracy': [],\n",
        "        'train_f1': [],\n",
        "        'val_f1': [],\n",
        "        'train_precision': [],\n",
        "        'val_precision': [],\n",
        "        'train_recall': [],\n",
        "        'val_recall': [],\n",
        "        'train_balanced_accuracy': [],\n",
        "        'val_balanced_accuracy': [],\n",
        "        'train_roc_auc': [],\n",
        "        'val_roc_auc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        train_preds = []\n",
        "        train_labels = []\n",
        "        train_probs = []\n",
        "\n",
        "        step = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            if batch is None:\n",
        "                continue\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            with autocast('cuda'):\n",
        "                outputs = model(**inputs, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            if loss is not None:\n",
        "                loss = loss / accum_steps\n",
        "                scaler.scale(loss).backward()\n",
        "                step += 1\n",
        "\n",
        "                if step % accum_steps == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                total_train_loss += loss.item() * accum_steps\n",
        "\n",
        "            # Store predictions for metrics\n",
        "            with torch.no_grad():\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                train_preds.extend(preds.cpu().numpy())\n",
        "                train_labels.extend(labels.cpu().numpy())\n",
        "                train_probs.extend(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "        # Calculate training metrics\n",
        "        train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "        train_f1 = f1_score(train_labels, train_preds, average='weighted')\n",
        "        train_precision = precision_score(train_labels, train_preds, average='weighted')\n",
        "        train_recall = recall_score(train_labels, train_preds, average='weighted')\n",
        "        train_balanced_accuracy = balanced_accuracy_score(train_labels, train_preds)\n",
        "\n",
        "        # Calculate ROC AUC if possible\n",
        "        try:\n",
        "            train_roc_auc = roc_auc_score(train_labels, train_probs, multi_class='ovr', average='weighted')\n",
        "        except:\n",
        "            train_roc_auc = np.nan\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        val_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                if batch is None:\n",
        "                    continue\n",
        "                inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                with autocast('cuda'):\n",
        "                    outputs = model(**inputs, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "\n",
        "                if loss is not None:\n",
        "                    total_val_loss += loss.item()\n",
        "\n",
        "                logits = outputs.logits\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_probs.extend(torch.softmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "        # Calculate validation metrics\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "        val_precision = precision_score(val_labels, val_preds, average='weighted')\n",
        "        val_recall = recall_score(val_labels, val_preds, average='weighted')\n",
        "        val_balanced_accuracy = balanced_accuracy_score(val_labels, val_preds)\n",
        "\n",
        "        try:\n",
        "            val_roc_auc = roc_auc_score(val_labels, val_probs, multi_class='ovr', average='weighted')\n",
        "        except:\n",
        "            val_roc_auc = np.nan\n",
        "\n",
        "        # Store metrics\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['train_loss'].append(total_train_loss / len(train_dataloader))\n",
        "        history['val_loss'].append(total_val_loss / len(val_dataloader))\n",
        "        history['train_accuracy'].append(train_accuracy)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "        history['train_f1'].append(train_f1)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        history['train_precision'].append(train_precision)\n",
        "        history['val_precision'].append(val_precision)\n",
        "        history['train_recall'].append(train_recall)\n",
        "        history['val_recall'].append(val_recall)\n",
        "        history['train_balanced_accuracy'].append(train_balanced_accuracy)\n",
        "        history['val_balanced_accuracy'].append(val_balanced_accuracy)\n",
        "        history['train_roc_auc'].append(train_roc_auc)\n",
        "        history['val_roc_auc'].append(val_roc_auc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"  Train Loss: {history['train_loss'][-1]:.4f}, Val Loss: {history['val_loss'][-1]:.4f}\")\n",
        "        print(f\"  Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "        print(f\"  Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}\")\n",
        "        print(f\"  Train-Validation Gap: {train_accuracy - val_accuracy:.4f}\")\n",
        "\n",
        "    # Save model in the Hugging Face format\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    model.save_pretrained(save_path)\n",
        "    processor.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "    print(f\"‚úÖ Fine-tuned model saved to {save_path}\")\n",
        "\n",
        "    # Save model state_dict as a single .pth file\n",
        "    pth_save_path = \"new_clip_product_classifier.pth\"\n",
        "    torch.save(model.state_dict(), pth_save_path)\n",
        "    print(f\"‚úÖ Model state_dict saved to {pth_save_path}\")\n",
        "\n",
        "    # Save training history\n",
        "    history_df = pd.DataFrame(history)\n",
        "    history_df.to_csv(os.path.join(save_path, 'training_history.csv'), index=False)\n",
        "\n",
        "    print(f\"‚úÖ Training history saved to {os.path.join(save_path, 'training_history.csv')}\")\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "RAtrAqF6s0H2"
      },
      "id": "RAtrAqF6s0H2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(history, save_path):\n",
        "    \"\"\"Plot training and validation curves to detect overfitting.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    # Loss curve\n",
        "    axes[0, 0].plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
        "    axes[0, 0].plot(history['epoch'], history['val_loss'], label='Validation Loss', marker='o')\n",
        "    axes[0, 0].set_title('Training and Validation Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy curve\n",
        "    axes[0, 1].plot(history['epoch'], history['train_accuracy'], label='Train Accuracy', marker='o')\n",
        "    axes[0, 1].plot(history['epoch'], history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
        "    axes[0, 1].set_title('Training and Validation Accuracy')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # F1 score curve\n",
        "    axes[0, 2].plot(history['epoch'], history['train_f1'], label='Train F1', marker='o')\n",
        "    axes[0, 2].plot(history['epoch'], history['val_f1'], label='Validation F1 Score', marker='o')\n",
        "    axes[0, 2].set_title('Training and Validation F1 Score')\n",
        "    axes[0, 2].set_xlabel('Epoch')\n",
        "    axes[0, 2].set_ylabel('F1 Score')\n",
        "    axes[0, 2].legend()\n",
        "    axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision curve\n",
        "    axes[1, 0].plot(history['epoch'], history['train_precision'], label='Train Precision', marker='o')\n",
        "    axes[1, 0].plot(history['epoch'], history['val_precision'], label='Validation Precision', marker='o')\n",
        "    axes[1, 0].set_title('Training and Validation Precision')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Precision')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Recall curve\n",
        "    axes[1, 1].plot(history['epoch'], history['train_recall'], label='Train Recall', marker='o')\n",
        "    axes[1, 1].plot(history['epoch'], history['val_recall'], label='Validation Recall', marker='o')\n",
        "    axes[1, 1].set_title('Training and Validation Recall')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Recall')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy gap (overfitting indicator)\n",
        "    accuracy_gap = [train - val for train, val in zip(history['train_accuracy'], history['val_accuracy'])]\n",
        "    axes[1, 2].plot(history['epoch'], accuracy_gap, label='Accuracy Gap (Train - Val)', marker='o', color='red')\n",
        "    axes[1, 2].axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
        "    axes[1, 2].set_title('Accuracy Gap (Indicator of Overfitting)')\n",
        "    axes[1, 2].set_xlabel('Epoch')\n",
        "    axes[1, 2].set_ylabel('Accuracy Gap')\n",
        "    axes[1, 2].legend()\n",
        "    axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Create summary table\n",
        "    final_metrics = {\n",
        "        'Metric': ['Loss', 'Accuracy', 'F1 Score', 'Precision', 'Recall', 'Balanced Accuracy', 'ROC AUC'],\n",
        "        'Train_Final': [\n",
        "            history['train_loss'][-1],\n",
        "            history['train_accuracy'][-1],\n",
        "            history['train_f1'][-1],\n",
        "            history['train_precision'][-1],\n",
        "            history['train_recall'][-1],\n",
        "            history['train_balanced_accuracy'][-1],\n",
        "            history['train_roc_auc'][-1] if not np.isnan(history['train_roc_auc'][-1]) else None\n",
        "        ],\n",
        "        'Validation_Final': [\n",
        "            history['val_loss'][-1],\n",
        "            history['val_accuracy'][-1],\n",
        "            history['val_f1'][-1],\n",
        "            history['val_precision'][-1],\n",
        "            history['val_recall'][-1],\n",
        "            history['val_balanced_accuracy'][-1],\n",
        "            history['val_roc_auc'][-1] if not np.isnan(history['val_roc_auc'][-1]) else None\n",
        "        ],\n",
        "        'Gap': [\n",
        "            history['train_loss'][-1] - history['val_loss'][-1],\n",
        "            history['train_accuracy'][-1] - history['val_accuracy'][-1],\n",
        "            history['train_f1'][-1] - history['val_f1'][-1],\n",
        "            history['train_precision'][-1] - history['val_precision'][-1],\n",
        "            history['train_recall'][-1] - history['val_recall'][-1],\n",
        "            history['train_balanced_accuracy'][-1] - history['val_balanced_accuracy'][-1],\n",
        "            (history['train_roc_auc'][-1] - history['val_roc_auc'][-1]) if not np.isnan(history['train_roc_auc'][-1]) and not np.isnan(history['val_roc_auc'][-1]) else None\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    summary_df = pd.DataFrame(final_metrics)\n",
        "    summary_df.to_csv(os.path.join(save_path, 'final_metrics_summary.csv'), index=False)\n",
        "\n",
        "    print(f\"‚úÖ Training curves saved to {os.path.join(save_path, 'training_curves.png')}\")\n",
        "    print(f\"‚úÖ Final metrics summary saved to {os.path.join(save_path, 'final_metrics_summary.csv')}\")\n",
        "\n",
        "    return summary_df"
      ],
      "metadata": {
        "id": "r8eSmdtXfh16"
      },
      "id": "r8eSmdtXfh16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baf0647d"
      },
      "source": [
        "# 4. Extraction des Caract√©ristiques Textuelles et Visuelles\n",
        "Objectif : Cette cellule utilise le mod√®le CLIP fine-tun√© pour extraire des repr√©sentations num√©riques (caract√©ristiques) distinctes pour les modalit√©s textuelle et visuelle de chaque produit, puis les combine.\n",
        "Description : D√©finit des fonctions pour extraire les caract√©ristiques textuelles √† partir des mots-cl√©s en utilisant l'encodeur de texte de CLIP, et les caract√©ristiques visuelles √† partir des images en utilisant l'encodeur d'image de CLIP. Normalise ces caract√©ristiques. Propose une m√©thode pour combiner ces deux types de caract√©ristiques en utilisant une pond√©ration alpha, cr√©ant ainsi une repr√©sentation multimodale."
      ],
      "id": "baf0647d"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_features(df, model, tokenizer):\n",
        "    \"\"\"Extract text features using the fine-tuned CLIP model.\"\"\"\n",
        "    texts = df['keywords'].tolist()\n",
        "    if not texts:\n",
        "        return np.array([])\n",
        "    with torch.no_grad():\n",
        "        inputs = tokenizer(texts, padding=True, truncation=True, max_length=77, return_tensors=\"pt\").to(device)\n",
        "        text_features = model.clip.get_text_features(**inputs)\n",
        "    return text_features.cpu().numpy()\n",
        "\n",
        "def extract_image_features(df, model, processor, max_size=128):  # Reduced max_size\n",
        "    \"\"\"Extract image features using the fine-tuned CLIP model.\"\"\"\n",
        "    features = []\n",
        "    valid_indices = []\n",
        "    for idx, img_path in enumerate(df['image_path']):\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "                if max(img.size) > max_size:\n",
        "                    ratio = max_size / max(img.size)\n",
        "                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
        "                    img = img.resize(new_size, Image.LANCZOS)\n",
        "                with torch.no_grad():\n",
        "                    inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "                    features.append(model.clip.get_image_features(**inputs).cpu().numpy())\n",
        "                    valid_indices.append(idx)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Skipping image {img_path}: {str(e)}\")\n",
        "            continue\n",
        "    if not features:\n",
        "        raise ValueError(\"No valid images processed.\")\n",
        "    return np.vstack(features), df.iloc[valid_indices].copy()\n",
        "\n",
        "def combine_features(text_features, image_features, alpha=0.6):\n",
        "    \"\"\"Combine text and image features with a weighting factor.\"\"\"\n",
        "    text_features = normalize(text_features, norm='l2')\n",
        "    image_features = normalize(image_features, norm='l2')\n",
        "    min_samples = min(text_features.shape[0], image_features.shape[0])\n",
        "    return normalize(alpha * text_features[:min_samples] + (1 - alpha) * image_features[:min_samples])"
      ],
      "metadata": {
        "id": "JQYIR9ins0Kw"
      },
      "id": "JQYIR9ins0Kw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68c0fd1b"
      },
      "source": [
        "# 5. √âvaluation et Comparaison des Modalit√©s\n",
        "Objectif : Cette cellule √©value les performances de classification en utilisant les caract√©ristiques textuelles, visuelles et combin√©es pour d√©terminer l'efficacit√© de chaque modalit√© et de leur combinaison.\n",
        "Description : Impl√©mente une fonction `evaluate_classification` qui utilise la validation crois√©e Stratified K-Fold avec un pipeline comprenant une PCA pour la r√©duction de dimensionnalit√© et un classificateur RandomForest. Calcule et affiche plusieurs m√©triques de performance courantes (Accuracy, F1-score, Precision, Recall, Balanced Accuracy, ARI, ROC AUC). La fonction `compare_modalities` appelle l'√©valuation pour chaque ensemble de caract√©ristiques et sauvegarde les r√©sultats dans un fichier CSV et g√©n√®re une visualisation comparative des m√©triques."
      ],
      "id": "68c0fd1b"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(features, true_labels, method_name, n_splits=5):\n",
        "    \"\"\"Evaluate classification performance with cross-validation, including additional metrics.\"\"\"\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "\n",
        "    # Define scoring metrics\n",
        "    scoring = {\n",
        "        'accuracy': 'accuracy',\n",
        "        'f1_weighted': 'f1_weighted',\n",
        "        'precision_weighted': 'precision_weighted',\n",
        "        'recall_weighted': 'recall_weighted',\n",
        "        'balanced_accuracy': 'balanced_accuracy'\n",
        "    }\n",
        "\n",
        "    # Perform cross-validation\n",
        "    scores = cross_validate(\n",
        "        pipeline, features, true_labels, cv=cv, scoring=scoring, n_jobs=1, return_train_score=False\n",
        "    )\n",
        "\n",
        "    # Compute ARI and get predictions using cross_val_predict\n",
        "    y_pred = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "    ari_score = adjusted_rand_score(true_labels, y_pred)\n",
        "\n",
        "    # Compute ROC AUC (One-vs-Rest) if multi-class\n",
        "    try:\n",
        "        le = LabelEncoder()\n",
        "        y_true_encoded = le.fit_transform(true_labels)\n",
        "        y_score = cross_val_predict(\n",
        "            pipeline, features, true_labels, cv=cv, method='predict_proba', n_jobs=1\n",
        "        )\n",
        "        roc_auc = roc_auc_score(y_true_encoded, y_score, multi_class='ovr', average='weighted')\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è ROC AUC calculation failed for {method_name}: {str(e)}\")\n",
        "        roc_auc = np.nan\n",
        "\n",
        "    # Aggregate results\n",
        "    avg_accuracy = np.mean(scores['test_accuracy'])\n",
        "    avg_f1 = np.mean(scores['test_f1_weighted'])\n",
        "    avg_precision = np.mean(scores['test_precision_weighted'])\n",
        "    avg_recall = np.mean(scores['test_recall_weighted'])\n",
        "    avg_balanced_accuracy = np.mean(scores['test_balanced_accuracy'])\n",
        "\n",
        "    print(f\"\\nM√©thode: {method_name}\")\n",
        "    print(f\"Accuracy (CV): {avg_accuracy:.3f}\")\n",
        "    print(f\"F1-score (weighted): {avg_f1:.3f}\")\n",
        "    print(f\"Precision (weighted): {avg_precision:.3f}\")\n",
        "    print(f\"Recall (weighted): {avg_recall:.3f}\")\n",
        "    print(f\"Balanced Accuracy: {avg_balanced_accuracy:.3f}\")\n",
        "    print(f\"Adjusted Rand Index: {ari_score:.3f}\")\n",
        "    print(f\"ROC AUC (OvR, weighted): {roc_auc:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'method': method_name,\n",
        "        'accuracy': avg_accuracy,\n",
        "        'f1_weighted': avg_f1,\n",
        "        'precision_weighted': avg_precision,\n",
        "        'recall_weighted': avg_recall,\n",
        "        'balanced_accuracy': avg_balanced_accuracy,\n",
        "        'ari': ari_score,\n",
        "        'roc_auc': roc_auc\n",
        "    }, true_labels, y_pred # Return true and predicted labels from CV\n",
        "\n",
        "def compare_modalities(df, text_features, image_features, combined_features, true_labels, valid_df, valid_categories, save_folder=\"result\"):\n",
        "    \"\"\"Compare text, image, and combined modalities with extended metrics and save to CSV.\"\"\"\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    results = []\n",
        "    # Capture true and predicted labels from CV for each modality\n",
        "    text_results, text_true_labels_cv, text_pred_labels_cv = evaluate_classification(text_features, true_labels, \"Texte seul\")\n",
        "    results.append(text_results)\n",
        "\n",
        "    img_results, img_true_labels_cv, img_pred_labels_cv = evaluate_classification(image_features, valid_categories, \"Image seule\")\n",
        "    results.append(img_results)\n",
        "\n",
        "    comb_results, comb_true_labels_cv, comb_pred_labels_cv = evaluate_classification(combined_features, valid_categories, \"Texte+Image\")\n",
        "    results.append(comb_results)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df.to_csv(os.path.join(save_folder, 'comparison_results.csv'), index=False)\n",
        "    print(f\"‚úÖ Results saved to '{save_folder}/comparison_results.csv'\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(2, 3, 1)\n",
        "    sns.barplot(x='method', y='accuracy', hue='method', data=results_df, palette=\"Blues_d\", legend=False)\n",
        "    plt.title(\"Accuracy moyenne (validation crois√©e)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "\n",
        "    # F1-score\n",
        "    plt.subplot(2, 3, 2)\n",
        "    sns.barplot(x='method', y='f1_weighted', hue='method', data=results_df, palette=\"Greens_d\", legend=False)\n",
        "    plt.title(\"F1-score moyen (pond√©r√©)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"F1-score\")\n",
        "\n",
        "    # Precision\n",
        "    plt.subplot(2, 3, 3)\n",
        "    sns.barplot(x='method', y='precision_weighted', hue='method', data=results_df, palette=\"Oranges_d\", legend=False)\n",
        "    plt.title(\"Precision moyenne (pond√©r√©e)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Precision\")\n",
        "\n",
        "    # Recall\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.barplot(x='method', y='recall_weighted', hue='method', data=results_df, palette=\"Purples_d\", legend=False)\n",
        "    plt.title(\"Recall moyen (pond√©r√©)\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Recall\")\n",
        "\n",
        "    # Balanced Accuracy\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.barplot(x='method', y='balanced_accuracy', hue='method', data=results_df, palette=\"Reds_d\", legend=False)\n",
        "    plt.title(\"Balanced Accuracy moyenne\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Balanced Accuracy\")\n",
        "\n",
        "    # ARI\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.barplot(x='method', y='ari', hue='method', data=results_df, palette=\"YlOrBr_d\", legend=False)\n",
        "    plt.title(\"Adjusted Rand Index\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"ARI\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_folder, 'comparison_supervised_finetuned_extended.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Visualization saved to '{save_folder}/comparison_supervised_finetuned_extended.png'\")\n",
        "\n",
        "    return results_df, comb_true_labels_cv, comb_pred_labels_cv # Return results and CV labels for combined features"
      ],
      "metadata": {
        "id": "gAUz5ylss0Nm"
      },
      "id": "gAUz5ylss0Nm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "571e9c80"
      },
      "source": [
        "# 6. G√©n√©ration de la Matrice de Confusion\n",
        "Objectif : Cette cellule visualise la matrice de confusion pour comprendre o√π le mod√®le fine-tun√© fait des erreurs de classification entre les diff√©rentes cat√©gories de produits.\n",
        "Description : Divise les donn√©es (caract√©ristiques combin√©es et √©tiquettes) en ensembles d'entra√Ænement et de test. Entra√Æne un pipeline PCA + RandomForest sur l'ensemble d'entra√Ænement et pr√©dit les √©tiquettes sur l'ensemble de test. Calcule la matrice de confusion normalis√©e. Utilise Seaborn pour visualiser la matrice de confusion sous forme de heatmap, affichant les proportions de vrais positifs, faux positifs et faux n√©gatifs pour chaque paire de cat√©gories. Sauvegarde l'image de la matrice de confusion."
      ],
      "id": "571e9c80"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(features, labels, category_names, save_path=\"result\"):\n",
        "    \"\"\"Generate and plot a normalized confusion matrix.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, labels, test_size=0.2, random_state=SEED, stratify=labels)\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True))\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "    cleaned_category_names = [re.sub(r'^[\\[\\\"\\]]|[\\]\\\"]$', '', name) for name in category_names]\n",
        "\n",
        "    plt.figure(figsize=(15, 12))\n",
        "    sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=sns.light_palette(\"#3498db\", as_cmap=True),\n",
        "                xticklabels=cleaned_category_names, yticklabels=cleaned_category_names,\n",
        "                linewidths=0.5, linecolor='lightgray')\n",
        "    plt.title(\"Matrice de confusion normalis√©e (Fine-Tuned CLIP)\", fontsize=14, pad=20)\n",
        "    plt.xlabel('Pr√©dictions', fontsize=12)\n",
        "    plt.ylabel('Vraies classes', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "    plt.yticks(rotation=0, fontsize=10)\n",
        "    for _, spine in plt.gca().spines.items():\n",
        "        spine.set_visible(True)\n",
        "        spine.set_color('lightgray')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, 'confusion_matrix_finetuned.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Confusion matrix saved to '{save_path}/confusion_matrix_finetuned.png'\")"
      ],
      "metadata": {
        "id": "7_Q6oi54s0Qj"
      },
      "id": "7_Q6oi54s0Qj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "790f6e1d"
      },
      "source": [
        "# 7. Visualisation t-SNE\n",
        "Objectif : Cette cellule r√©duit la dimensionnalit√© des caract√©ristiques combin√©es pour visualiser leur distribution dans un espace 2D et observer la s√©paration des clusters par cat√©gorie.\n",
        "Description : Applique une PCA pour r√©duire initialement les caract√©ristiques combin√©es, puis utilise t-SNE pour projeter les caract√©ristiques dans un espace bidimensionnel. Cr√©e un DataFrame avec les coordonn√©es t-SNE et les √©tiquettes de cat√©gorie. Utilise Seaborn pour g√©n√©rer un nuage de points (scatterplot) color√© par cat√©gorie, permettant d'√©valuer visuellement la qualit√© du clustering et la distinction entre les diff√©rentes classes de produits dans l'espace des caract√©ristiques apprises par le mod√®le fine-tun√©. Sauvegarde la visualisation t-SNE."
      ],
      "id": "790f6e1d"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tsne(features, labels, category_names, save_path=\"result\"):\n",
        "    \"\"\"Generate t-SNE visualization of features.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    print(\"‚è≥ Computing t-SNE...\")\n",
        "    pca = PCA(n_components=min(50, features.shape[1]), random_state=SEED)\n",
        "    features_pca = pca.fit_transform(features)\n",
        "    tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=SEED, init='pca')\n",
        "    tsne_features = tsne.fit_transform(features_pca)\n",
        "    cleaned_category_names = [re.sub(r'^[\\[\\\"\\]]|[\\]\\\"]$', '', name) for name in category_names]\n",
        "    tsne_df = pd.DataFrame({\n",
        "        'x': tsne_features[:, 0],\n",
        "        'y': tsne_features[:, 1],\n",
        "        'category': [cleaned_category_names[i] for i in labels]\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    sns.scatterplot(data=tsne_df, x='x', y='y', hue='category',\n",
        "                    palette=sns.color_palette(\"husl\", len(cleaned_category_names)),\n",
        "                    s=70, alpha=0.8, legend='full')\n",
        "    plt.title(\"Visualisation t-SNE (Fine-Tuned CLIP)\", fontsize=16)\n",
        "    plt.xlabel(\"t-SNE 1\", fontsize=14)\n",
        "    plt.ylabel(\"t-SNE 2\", fontsize=14)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, fontsize=10, title='Cat√©gories', title_fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.2)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_path, 'tsne_finetuned.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ t-SNE visualization saved ('{save_path}/tsne_finetuned.png')\")"
      ],
      "metadata": {
        "id": "ecvZQJ_Ts0Tk"
      },
      "id": "ecvZQJ_Ts0Tk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80e292d9"
      },
      "source": [
        "# 8. Analyse d'Attention CLIP\n",
        "Objectif : Cette cellule explore les m√©canismes d'attention du mod√®le CLIP fine-tun√© pour comprendre quelles parties de l'image et quels mots-cl√©s sont les plus influents dans la repr√©sentation apprise pour un produit donn√©.\n",
        "Description : D√©finit une fonction `clip_attention_analysis` qui prend l'ID d'un produit, le DataFrame, le mod√®le, le processeur et le tokenizer. Effectue une d√©composition de l'image en patches et calcule la similarit√© des caract√©ristiques de chaque patch avec les caract√©ristiques des mots-cl√©s associ√©s au produit. Visualise ces similarit√©s sur une grille d'images. Calcule √©galement une heatmap d'attention en utilisant des patchs glissants sur l'image enti√®re et la moyenne des scores de similarit√© avec tous les mots-cl√©s, superposant cette heatmap sur l'image originale pour montrer les r√©gions les plus \"attendues\". Affiche et sauvegarde les visualisations ainsi que les scores de similarit√© des mots-cl√©s."
      ],
      "id": "80e292d9"
    },
    {
      "cell_type": "code",
      "source": [
        "def clip_attention_analysis(uniq_id, df, model, processor, tokenizer, patch_size=128, resolution=50, category_folder=\"Home Furnishing\"):\n",
        "    \"\"\"Generate CLIP attention interpretability visualizations.\"\"\"\n",
        "    try:\n",
        "        product = df[df['uniq_id'] == uniq_id].iloc[0]\n",
        "        img = Image.open(product['image_path'])\n",
        "        img = img.convert('RGB')  # Ensure RGB format\n",
        "        img_width, img_height = img.size\n",
        "        img_bw = img.convert('L')\n",
        "        enhancer = ImageEnhance.Contrast(img_bw)\n",
        "        img_bw = enhancer.enhance(1.5)\n",
        "        img_bw = np.array(img_bw)\n",
        "        keywords = list(set(kw.strip() for kw in product['keywords'].split(',') if kw.strip()))\n",
        "        print(f\"üîç Analyse du produit: {product['product_name'][:50]}...\")\n",
        "        print(\"üî† Mots-cl√©s uniques:\", \", \".join(keywords))\n",
        "\n",
        "        # Create the category folder\n",
        "        os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "        # Decomposition\n",
        "        patches = []\n",
        "        positions = []\n",
        "        step = patch_size\n",
        "        for y in range(0, img_height, step):\n",
        "            for x in range(0, img_width, step):\n",
        "                patch = img.crop((x, y, min(x+patch_size, img_width), min(y+patch_size, img_height)))\n",
        "                if patch.size[0] > 0 and patch.size[1] > 0:\n",
        "                    patch = patch.convert('RGB')  # Ensure patch is RGB\n",
        "                    patch = patch.resize((224, 224), Image.LANCZOS)\n",
        "                    patches.append(patch)\n",
        "                    positions.append((x, y, min(x+patch_size, img_width), min(y+patch_size, img_height)))\n",
        "\n",
        "        if not patches:\n",
        "            raise ValueError(\"No valid patches extracted for decomposition.\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_inputs = tokenizer(keywords[:5], return_tensors=\"pt\", padding=True, truncation=True, max_length=77).to(device)\n",
        "            # Access text features directly from the model instance\n",
        "            text_features = model.get_text_features(**text_inputs)\n",
        "            patch_features = []\n",
        "            for p in patches:\n",
        "                inputs = processor(images=p, return_tensors=\"pt\", padding=True).pixel_values.to(device).float()\n",
        "                if inputs.shape[1] != 3:  # Check for 3 channels (RGB)\n",
        "                    print(f\"‚ö†Ô∏è Patch non-RGB d√©tect√©, saut du patch\")\n",
        "                    continue\n",
        "                # Access image features directly from the model instance\n",
        "                features = model.get_image_features(pixel_values=inputs)\n",
        "                patch_features.append(features)\n",
        "                torch.cuda.empty_cache()\n",
        "            if not patch_features:\n",
        "                raise ValueError(\"No valid patch features extracted.\")\n",
        "            patch_features = torch.cat(patch_features)\n",
        "            similarities = (patch_features @ text_features.T).softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "        n = int(np.ceil(len(patches)**0.5))\n",
        "        fig, axes = plt.subplots(n, n, figsize=(15, 15))\n",
        "        axes = axes.flatten()\n",
        "        for idx, (patch, ax) in enumerate(zip(patches, axes)):\n",
        "            ax.imshow(patch)\n",
        "            ax.axis('off')\n",
        "            if idx < len(similarities):\n",
        "                top_concept = keywords[similarities[idx].argmax()]\n",
        "                ax.set_title(f\"{top_concept}\\n{similarities[idx].max():.2f}\", fontsize=8)\n",
        "        for ax in axes[len(patches):]:\n",
        "            ax.axis('off')\n",
        "        plt.suptitle(f\"CLIP Decomposition (Fine-Tuned) - {product['product_name'][:50]}...\", y=0.92)\n",
        "        plt.tight_layout()\n",
        "        decomposition_path = os.path.join(category_folder, f'clip_decomposition_finetuned_{uniq_id}.png')\n",
        "        plt.savefig(decomposition_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        # Keyword Similarity\n",
        "        with torch.no_grad():\n",
        "            text_inputs = tokenizer(keywords, return_tensors=\"pt\", padding=True, truncation=True, max_length=77).to(device)\n",
        "            image_inputs = processor(images=img, return_tensors=\"pt\").pixel_values.to(device).float()\n",
        "            # Access text features directly from the model instance\n",
        "            text_features = model.get_text_features(**text_inputs)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "            # Access image features directly from the model instance\n",
        "            image_features = model.get_image_features(pixel_values=image_inputs)\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "            logits_per_image = (image_features @ text_features.T) / 0.07\n",
        "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()[0]\n",
        "        results = dict(zip(keywords, probs))\n",
        "        sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        print(\"\\nüìä Scores de similarit√©:\")\n",
        "        for kw, prob in sorted_results:\n",
        "            print(f\"- {kw}: {prob:.4f}\")\n",
        "\n",
        "        # Smooth Heatmap with batched processing\n",
        "        torch.cuda.empty_cache()\n",
        "        x = np.linspace(0, img_width, resolution, dtype=int)\n",
        "        y = np.linspace(0, img_height, resolution, dtype=int)\n",
        "        xx, yy = np.meshgrid(x, y)\n",
        "        positions = []\n",
        "        batch_size = 10\n",
        "        patch_features = []\n",
        "        size = min(img_width, img_height) // 10\n",
        "        for i in range(0, resolution * resolution, batch_size):\n",
        "            batch_patches = []\n",
        "            batch_positions = []\n",
        "            for j in range(i, min(i + batch_size, resolution * resolution)):\n",
        "                x_idx = j // resolution\n",
        "                y_idx = j % resolution\n",
        "                x_pos = xx[x_idx, y_idx]\n",
        "                y_pos = yy[x_idx, y_idx]\n",
        "                patch = img.crop((max(0, x_pos - size//2), max(0, y_pos - size//2),\n",
        "                                  min(img_width, x_pos + size//2), min(img_height, y_pos + size//2)))\n",
        "                if patch.size[0] > 0 and patch.size[1] > 0:\n",
        "                    patch = patch.convert('RGB')  # Ensure patch is RGB\n",
        "                    patch = patch.resize((224, 224), Image.LANCZOS)\n",
        "                    batch_patches.append(patch)\n",
        "                    batch_positions.append((x_pos, y_pos))\n",
        "            if batch_patches:\n",
        "                with torch.no_grad():\n",
        "                    inputs = processor(images=batch_patches, return_tensors=\"pt\").pixel_values.to(device).float()\n",
        "                    if inputs.shape[1] != 3:  # Check for 3 channels (RGB)\n",
        "                        print(f\"‚ö†Ô∏è Batch non-RGB d√©tect√©, saut du batch\")\n",
        "                        continue\n",
        "                    # Access image features directly from the model instance\n",
        "                    features = model.get_image_features(pixel_values=inputs)\n",
        "                    patch_features.append(features)\n",
        "                positions.extend(batch_positions)\n",
        "                torch.cuda.empty_cache()\n",
        "        if not patch_features:\n",
        "            raise ValueError(\"No valid patches extracted for heatmap.\")\n",
        "        patch_features = torch.cat(patch_features)\n",
        "        patch_features = patch_features / patch_features.norm(dim=-1, keepdim=True)\n",
        "        with torch.no_grad():\n",
        "            # Access text features directly from the model instance\n",
        "            text_features = model.get_text_features(**text_inputs)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "            attention_scores = (patch_features @ text_features.T).cpu().numpy()\n",
        "        points = np.array(positions)\n",
        "        grid_x, grid_y = np.mgrid[0:img_width:complex(0, img_width), 0:img_height:complex(0, img_height)]\n",
        "        smooth_heatmap = griddata(points, attention_scores.mean(axis=1), (grid_x, grid_y), method='cubic', fill_value=0)\n",
        "        smooth_heatmap = (smooth_heatmap - smooth_heatmap.min()) / (smooth_heatmap.max() - smooth_heatmap.min())\n",
        "\n",
        "        plt.figure(figsize=(16, 10))\n",
        "        plt.imshow(img_bw, cmap='gray', vmin=0, vmax=255)\n",
        "        heatmap_layer = plt.imshow(smooth_heatmap.T, cmap='inferno', alpha=0.55, # Transpose heatmap\n",
        "                                  extent=[0, img_width, img_height, 0], interpolation='bicubic')\n",
        "        top_keywords = sorted(zip(keywords, attention_scores.mean(axis=0)), key=lambda x: x[1], reverse=True)[:3]\n",
        "        for kw, score in top_keywords:\n",
        "            kw_idx = keywords.index(kw)\n",
        "            max_pos_idx = np.argmax(attention_scores[:, kw_idx])\n",
        "            max_pos = positions[max_pos_idx]\n",
        "            plt.scatter(max_pos[0], max_pos[1], s=300, edgecolors='white', linewidths=2, facecolors='none')\n",
        "            plt.text(max_pos[0], max_pos[1]+img_height*0.03, f\"{kw}\\n({score:.2f})\",\n",
        "                     color='white', ha='center', va='top', fontsize=11,\n",
        "                     bbox=dict(facecolor='black', alpha=0.7, boxstyle='round,pad=0.5', edgecolor='white', linewidth=1))\n",
        "        cbar = plt.colorbar(heatmap_layer, fraction=0.03, pad=0.01)\n",
        "        cbar.set_label('Intensit√© d\\'attention', rotation=270, labelpad=15)\n",
        "        plt.title(f\"Heatmap d'attention CLIP (Fine-Tun√©) - {product['product_name'][:50]}...\\nProduit: {uniq_id}\", pad=20, fontsize=12)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        heatmap_path = os.path.join(category_folder, f'smooth_attention_finetuned_{uniq_id}.png')\n",
        "        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight', facecolor='black')\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Heatmap saved as {heatmap_path}\")\n",
        "\n",
        "        return {\n",
        "            'decomposition': similarities,\n",
        "            'keyword_similarities': dict(sorted_results),\n",
        "            'heatmap': smooth_heatmap,\n",
        "            'top_keywords': top_keywords\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ekRUFcPos0Wk"
      },
      "id": "ekRUFcPos0Wk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5821cf1"
      },
      "source": [
        "# 9. Analyse des Produits Repr√©sentatifs et des Erreurs de Pr√©diction par Cat√©gorie\n",
        "Objectif : Cette cellule analyse en d√©tail les produits qui sont les plus \"typiques\" de chaque cat√©gorie (repr√©sentatifs) et ceux qui sont le plus souvent mal class√©s, en utilisant l'analyse d'attention pour comprendre les raisons.\n",
        "Description : D√©finit la fonction `find_closest_to_centers` pour identifier les produits dont les caract√©ristiques combin√©es sont les plus proches du centre (moyenne) de leur cluster (cat√©gorie), les consid√©rant comme des repr√©sentants typiques. La fonction `analyze_classification_errors` utilise la validation crois√©e pour identifier les paires de cat√©gories o√π les erreurs de classification sont les plus fr√©quentes, en se basant sur la matrice de confusion. Pour les erreurs les plus courantes, elle s√©lectionne les produits mal class√©s et applique l'analyse d'attention CLIP (d√©finie dans la cellule pr√©c√©dente) pour visualiser ce qui a pu conduire √† la mauvaise pr√©diction. Sauvegarde les visualisations et g√©n√®re un rapport CSV des erreurs."
      ],
      "id": "c5821cf1"
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        original_indices = np.where(labels == label)[0][closest_idx]\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "    results = df.iloc[closest_indices].copy()\n",
        "    results['cluster'] = labels[closest_indices]\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[closest_indices],\n",
        "        [np.mean(features[labels == l], axis=0) for l in labels[closest_indices]]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs('error', exist_ok=True)\n",
        "    print(\"\\n‚è≥ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\nüî¥ Erreur fr√©quente: '{true_cat}' class√© comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"‚ö†Ô∏è Aucun produit trouv√© pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = valid_df.iloc[misclassified_indices]\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join('error',\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   üîç Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=valid_df,\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ‚úÖ M√äME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarit√© des mots-cl√©s - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarit√©\")\n",
        "                    plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ‚úÖ Diagramme en barres sauvegard√©: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv('error/classification_errors_report.csv', index=False)\n",
        "        print(\"\\n‚úÖ Rapport d'erreurs sauvegard√©: 'error/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un r√©sum√©\n",
        "        print(\"\\nüìä R√âSUM√â DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} ‚Üí {row['predicted_category']}: {row['product_name'][:30]}...\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Aucune erreur de classification trouv√©e\")\n",
        "\n",
        "    return error_df"
      ],
      "metadata": {
        "id": "-GEG7YK_s0Zq"
      },
      "id": "-GEG7YK_s0Zq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "\n",
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        if cluster_points.shape[0] == 0:\n",
        "            print(f\"‚ö†Ô∏è No points found for label {label}\")\n",
        "            continue\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        # Ensure original_indices correspond to the original dataframe df\n",
        "        original_indices = df[labels == label].iloc[closest_idx].index.tolist()\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "\n",
        "    results = df.loc[closest_indices].copy()\n",
        "    # Map original indices back to labels\n",
        "    results['cluster'] = labels[results.index]\n",
        "    # Recalculate distance to center using the features of the selected products\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[results.index],\n",
        "        [np.mean(features[labels == l], axis=0) for l in results['cluster']]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs('error', exist_ok=True)\n",
        "    print(\"\\n‚è≥ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\nüî¥ Erreur fr√©quente: '{true_cat}' class√© comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"‚ö†Ô∏è Aucun produit trouv√© pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = df.iloc[misclassified_indices] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join('error',\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   üîç Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=df, # Pass the input df which should be the valid_df\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ‚úÖ M√äME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarit√© des mots-cl√©s - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarit√©\")\n",
        "                    plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ‚úÖ Diagramme en barres sauvegard√©: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv('error/classification_errors_report.csv', index=False)\n",
        "        print(\"\\n‚úÖ Rapport d'erreurs sauvegard√©: 'error/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un r√©sum√©\n",
        "        print(\"\\nüìä R√âSUM√â DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} ‚Üí {row['predicted_category']}: {row['product_name'][:30]}...\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Aucune erreur de classification trouv√©e\")\n",
        "\n",
        "    return error_df"
      ],
      "metadata": {
        "id": "8yzEznG_YUyA"
      },
      "id": "8yzEznG_YUyA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0436cf4c"
      },
      "source": [
        "# 10. Ex√©cution du Pipeline Complet\n",
        "Objectif : Cette cellule ex√©cute l'ensemble du pipeline d'analyse multimodale, du chargement des donn√©es √† l'analyse d√©taill√©e des r√©sultats, y compris l'√©valuation, la visualisation et l'interpr√©tabilit√© des erreurs.\n",
        "Description : Appelle s√©quentiellement les fonctions d√©finies dans les cellules pr√©c√©dentes : chargement et nettoyage des donn√©es (`load_data`, `process_descriptions_to_keywords`), fine-tuning du mod√®le CLIP (`fine_tune_clip`), extraction des caract√©ristiques (`extract_text_features`, `extract_image_features`, `combine_features`), √©valuation comparative (`compare_modalities`), g√©n√©ration des visualisations (matrice de confusion et t-SNE), et analyse unifi√©e des produits repr√©sentatifs et des erreurs (`unified_analysis_pipeline`). La fonction `unified_analysis_pipeline` est red√©finie ici pour s'assurer qu'elle est disponible dans ce bloc d'ex√©cution, int√©grant les appels aux fonctions d'analyse d'attention et de recherche des repr√©sentants. G√®re √©galement la gestion de la m√©moire GPU et les erreurs potentielles."
      ],
      "id": "0436cf4c"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "\n",
        "# Definition de la fonction unified_analysis_pipeline included here for assurance\n",
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        if cluster_points.shape[0] == 0:\n",
        "            print(f\"‚ö†Ô∏è No points found for label {label}\")\n",
        "            continue\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        # Ensure original_indices correspond to the original dataframe df\n",
        "        original_indices = df[labels == label].iloc[closest_idx].index.tolist()\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "\n",
        "    results = df.loc[closest_indices].copy()\n",
        "    # Map original indices back to labels\n",
        "    results['cluster'] = labels[results.index]\n",
        "    # Recalculate distance to center using the features of the selected products\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[results.index],\n",
        "        [np.mean(features[labels == l], axis=0) for l in results['cluster']]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5, save_folder=\"error\"):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    print(\"\\n‚è≥ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\nüî¥ Erreur fr√©quente: '{true_cat}' class√© comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"‚ö†Ô∏è Aucun produit trouv√© pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = df.iloc[misclassified_indices] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join(save_folder,\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   üîç Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=df, # Pass the input df which should be the valid_df\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ‚úÖ M√äME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values()) # Corrected access\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarit√© des mots-cl√©s - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarit√©\")\n",
        "                    plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ‚úÖ Diagramme en barres sauvegard√©: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv(os.path.join(save_folder, 'classification_errors_report.csv'), index=False)\n",
        "        print(f\"\\n‚úÖ Rapport d'erreurs sauvegard√©: '{save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un r√©sum√©\n",
        "        print(\"\\nüìä R√âSUM√â DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} ‚Üí {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n‚úÖ Aucune erreur de classification trouv√©e\")\n",
        "\n",
        "    return error_df\n",
        "\n",
        "def unified_analysis_pipeline(features, true_labels, df, category_names, model, processor, tokenizer,\n",
        "                             analysis_type=\"both\", n_representatives=3, top_n_errors=5):\n",
        "    \"\"\"\n",
        "    Pipeline unifi√© pour l'analyse des produits repr√©sentatifs et des erreurs de classification.\n",
        "\n",
        "    Args:\n",
        "        features: Caract√©ristiques combin√©es\n",
        "        true_labels: √âtiquettes vraies\n",
        "        df: DataFrame original (should be the valid_df from the main pipeline)\n",
        "        category_names: Noms des cat√©gories\n",
        "        model: Mod√®le CLIP fine-tun√©\n",
        "        processor: Processeur CLIP\n",
        "        tokenizer: Tokenizer CLIP\n",
        "        analysis_type: Type d'analyse (\"representatives\", \"errors\", ou \"both\")\n",
        "        n_representatives: Nombre de produits repr√©sentatifs par cat√©gorie\n",
        "        top_n_errors: Nombre d'erreurs principales √† analyser\n",
        "    \"\"\"\n",
        "\n",
        "    # Cr√©er les dossiers n√©cessaires\n",
        "    category_save_folder = 'category'\n",
        "    error_save_folder = 'error'\n",
        "    os.makedirs(category_save_folder, exist_ok=True)\n",
        "    os.makedirs(error_save_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "    if analysis_type in [\"representatives\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES PRODUITS REPR√âSENTATIFS PAR CAT√âGORIE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Trouver les produits les plus proches des centres de clusters\n",
        "        print(\"\\n‚è≥ Recherche des produits les plus proches des centres de clusters...\")\n",
        "        closest_products = find_closest_to_centers(features, true_labels, df, n_examples=n_representatives)\n",
        "\n",
        "\n",
        "        # Traiter chaque cat√©gorie\n",
        "        unique_labels = np.unique(true_labels)\n",
        "        for cluster_id in unique_labels:\n",
        "            category_name = category_names[cluster_id]\n",
        "            print(f\"\\nüè† Top {n_representatives} produits pour la cat√©gorie '{category_name}':\")\n",
        "\n",
        "            # Cr√©er un dossier pour la cat√©gorie\n",
        "            category_folder = os.path.join(category_save_folder, category_name.replace('/', '_').replace(' ', '_'))\n",
        "            os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "            # S√©lectionner les produits pour cette cat√©gorie\n",
        "            category_products = closest_products[closest_products['cluster'] == cluster_id].head(n_representatives)\n",
        "\n",
        "            if category_products.empty:\n",
        "                print(f\"‚ö†Ô∏è Aucun produit trouv√© pour la cat√©gorie '{category_name}'\")\n",
        "                continue\n",
        "\n",
        "            # Traiter chaque produit repr√©sentatif\n",
        "            for idx, row in category_products.iterrows():\n",
        "                print(f\"\\nüîπ Produit: {row['product_name'][:50]}...\")\n",
        "                print(f\"   üìè Distance au centre: {row['distance_to_center']:.4f}\")\n",
        "\n",
        "                try:\n",
        "                    # G√©n√©rer l'analyse d'attention CLIP\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=category_folder # Pass the category-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # G√©n√©rer le diagramme en barres des similarit√©s\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Blues_d\", legend=False)\n",
        "                        plt.title(f\"Scores de similarit√© - {row['product_name'][:50]}...\")\n",
        "                        plt.xlabel(\"Score de similarit√©\")\n",
        "                        plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                        # Ajouter les valeurs aux barres\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(category_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        print(f\"‚úÖ Visualisations sauvegard√©es dans: {category_folder}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erreur lors de l'analyse du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    if analysis_type in [\"errors\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES ERREURS DE CLASSIFICATION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # G√©n√©rer les pr√©dictions par validation crois√©e\n",
        "        pipeline = make_pipeline(\n",
        "            PCA(n_components=0.95, random_state=SEED),\n",
        "            RandomForestClassifier(n_estimators=100, random_state=SEED,\n",
        "                                 max_features='sqrt', bootstrap=True)\n",
        "        )\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "        pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "        # Obtenir la matrice de confusion\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "        # Trouver les paires d'erreurs les plus fr√©quentes\n",
        "        error_pairs = []\n",
        "        for i in range(len(category_names)):\n",
        "            for j in range(len(category_names)):\n",
        "                if i != j and cm[i, j] > 0:\n",
        "                    error_pairs.append((i, j, cm[i, j]))\n",
        "\n",
        "        # Trier par nombre d'erreurs\n",
        "        error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Cr√©er le dataframe d'analyse d'erreurs\n",
        "        error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                       'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "        # Traiter les principales erreurs\n",
        "        for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "            true_cat = category_names[true_idx]\n",
        "            pred_cat = category_names[pred_idx]\n",
        "\n",
        "            print(f\"\\nüî¥ Erreur: '{true_cat}' ‚Üí '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "            # Obtenir les indices des produits mal class√©s\n",
        "            misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "            if len(misclassified_indices) == 0:\n",
        "                print(\"‚ö†Ô∏è Aucun produit trouv√© pour cette paire d'erreur\")\n",
        "                continue\n",
        "\n",
        "            # Cr√©er un sous-dossier pour ce type d'erreur\n",
        "            error_folder = os.path.join(error_save_folder,\n",
        "                                      f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "            os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "            # Traiter chaque produit mal class√©\n",
        "            for idx in misclassified_indices:\n",
        "                row = df.iloc[idx] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "                try:\n",
        "                    print(f\"   üîç Traitement: {row['product_name'][:50]}...\")\n",
        "\n",
        "                    # G√©n√©rer l'analyse d'attention\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=error_folder # Pass the error-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # G√©n√©rer le diagramme en barres\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        # CORRECTED: Use 'keyword_similarities' (plural)\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Reds_d\", legend=False)\n",
        "                        plt.title(f\"Erreur: {true_cat} ‚Üí {pred_cat} - {row['product_name'][:30]}...\")\n",
        "                        plt.xlabel(\"Score de similarit√©\")\n",
        "                        plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(error_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        # Ajouter au rapport d'erreurs\n",
        "                        error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                            'true_category': true_cat,\n",
        "                            'predicted_category': pred_cat,\n",
        "                            'uniq_id': row['uniq_id'],\n",
        "                            'product_name': row['product_name'],\n",
        "                            'keywords': row['keywords'],\n",
        "                            'error_count': error_count\n",
        "                        }])], ignore_index=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "        # Sauvegarder le rapport d'erreurs\n",
        "        if not error_df.empty:\n",
        "            error_df.to_csv(os.path.join(error_save_folder, 'classification_errors_report.csv'), index=False)\n",
        "            print(f\"\\n‚úÖ Rapport d'erreurs sauvegard√©: '{error_save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "            # Afficher le r√©sum√©\n",
        "            print(\"\\nüìä R√âSUM√â DES ERREURS:\")\n",
        "            for _, row in error_df.iterrows():\n",
        "                print(f\"   - {row['true_category']} ‚Üí {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n‚úÖ Aucune erreur de classification trouv√©e\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ANALYSE TERMIN√âE AVEC SUCC√àS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "# Cr√©er les dossier au d√©but de l'ex√©cution du pipeline\n",
        "os.makedirs('result', exist_ok=True)\n",
        "print(\"‚úÖ Created 'result' folder.\")\n",
        "os.makedirs('category', exist_ok=True)\n",
        "print(\"‚úÖ Created 'category' folder.\")\n",
        "os.makedirs('error', exist_ok=True)\n",
        "print(\"‚úÖ Created 'error' folder.\")\n",
        "os.makedirs('training_analysis', exist_ok=True)\n",
        "print(\"‚úÖ Created 'training_analysis' folder.\")\n",
        "\n",
        "\n",
        "try:\n",
        "    print(\"\\n‚è≥ Loading data...\")\n",
        "    df = load_data('produits_original.csv', 'images_original')\n",
        "    df = process_descriptions_to_keywords(df)\n",
        "    print(f\"‚úÖ {len(df)} products loaded\")\n",
        "\n",
        "    print(\"\\n‚è≥ Clearing GPU memory...\")\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    print(\"‚úÖ GPU memory cleared\")\n",
        "\n",
        "    print(\"\\n‚è≥ Fine-tuning CLIP model...\")\n",
        "    # Modifier l'appel pour r√©cup√©rer l'historique\n",
        "    model, training_history = fine_tune_clip(df, processor, tokenizer, epochs=5, batch_size=4, accum_steps=4, save_path=\"finetuned_clip\")\n",
        "    model.eval()\n",
        "    print(\"‚úÖ Loaded fine-tuned CLIP model\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "z9ho69Kys0c4"
      },
      "id": "z9ho69Kys0c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "\n",
        "\n",
        "# Definition de la fonction unified_analysis_pipeline included here for assurance\n",
        "def find_closest_to_centers(features, labels, df, n_examples=3):\n",
        "    \"\"\"Find n products closest to each cluster center.\"\"\"\n",
        "    from sklearn.metrics.pairwise import euclidean_distances\n",
        "    unique_labels = np.unique(labels)\n",
        "    closest_indices = []\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = features[labels == label]\n",
        "        if cluster_points.shape[0] == 0:\n",
        "            print(f\"‚ö†Ô∏è No points found for label {label}\")\n",
        "            continue\n",
        "        center = np.mean(cluster_points, axis=0)\n",
        "        distances = euclidean_distances(cluster_points, [center])\n",
        "        closest_idx = np.argsort(distances.flatten())[:n_examples]\n",
        "        # Ensure original_indices correspond to the original dataframe df\n",
        "        original_indices = df[labels == label].iloc[closest_idx].index.tolist()\n",
        "        closest_indices.extend(original_indices)\n",
        "\n",
        "\n",
        "    results = df.loc[closest_indices].copy()\n",
        "    # Map original indices back to labels\n",
        "    results['cluster'] = labels[results.index]\n",
        "    # Recalculate distance to center using the features of the selected products\n",
        "    results['distance_to_center'] = euclidean_distances(\n",
        "        features[results.index],\n",
        "        [np.mean(features[labels == l], axis=0) for l in results['cluster']]\n",
        "    ).diagonal()\n",
        "    return results.sort_values(['cluster', 'distance_to_center'])\n",
        "\n",
        "def analyze_classification_errors(features, true_labels, df, category_names, model, processor, tokenizer, top_n_errors=5, n_splits=5, save_folder=\"error\"):\n",
        "    \"\"\"Analyze and visualize classification errors from confusion matrix.\"\"\"\n",
        "    # Create error directory\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    print(\"\\n‚è≥ Analyzing classification errors...\")\n",
        "\n",
        "    # Generate predictions using cross-validation\n",
        "    pipeline = make_pipeline(\n",
        "        PCA(n_components=0.95, random_state=SEED),\n",
        "        RandomForestClassifier(n_estimators=100, random_state=SEED, max_features='sqrt', bootstrap=True)\n",
        "    )\n",
        "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "    # Get confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Find most common error pairs\n",
        "    error_pairs = []\n",
        "    for i in range(len(category_names)):\n",
        "        for j in range(len(category_names)):\n",
        "            if i != j and cm[i,j] > 0:\n",
        "                error_pairs.append((i, j, cm[i,j]))\n",
        "\n",
        "    # Sort by error count\n",
        "    error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Create error analysis dataframe\n",
        "    error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                   'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "    # Process top error pairs\n",
        "    for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "        true_cat = category_names[true_idx]\n",
        "        pred_cat = category_names[pred_idx]\n",
        "\n",
        "        print(f\"\\nüî¥ Erreur fr√©quente: '{true_cat}' class√© comme '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "        # Get misclassified products\n",
        "        misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"‚ö†Ô∏è Aucun produit trouv√© pour cette paire d'erreur\")\n",
        "            continue\n",
        "\n",
        "        # Get the actual products from valid_df\n",
        "        misclassified_products = df.iloc[misclassified_indices] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "        # Process each misclassified product\n",
        "        for _, row in misclassified_products.iterrows():\n",
        "            try:\n",
        "                # Create subfolder for this error type\n",
        "                error_folder = os.path.join(save_folder,\n",
        "                                          f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "                os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "                print(f\"   üîç Traitement du produit: {row['product_name'][:50]}...\")\n",
        "\n",
        "                # Generate CLIP attention analysis\n",
        "                analysis_results = clip_attention_analysis(\n",
        "                    uniq_id=row['uniq_id'],\n",
        "                    df=df, # Pass the input df which should be the valid_df\n",
        "                    model=model,\n",
        "                    processor=processor,\n",
        "                    tokenizer=tokenizer,\n",
        "                    category_folder=error_folder\n",
        "                )\n",
        "\n",
        "                if analysis_results:\n",
        "                    # ‚úÖ M√äME CODE QUE POUR LE DOSSIER 'CATEGORY'\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                    scores_list = list(analysis_results['keyword_similarities'].values()) # Corrected access\n",
        "\n",
        "                    ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "                    plt.title(f\"Scores de similarit√© des mots-cl√©s - {row['product_name'][:50]}...\")\n",
        "                    plt.xlabel(\"Score de similarit√©\")\n",
        "                    plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                    # Ajouter les valeurs au bout des barres\n",
        "                    for i, score in enumerate(scores_list):\n",
        "                        ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "                    plt.tight_layout()\n",
        "                    barchart_path = os.path.join(error_folder, f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                    plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                    plt.close()\n",
        "                    print(f\"   ‚úÖ Diagramme en barres sauvegard√©: {barchart_path}\")\n",
        "\n",
        "                    # Add to error dataframe\n",
        "                    error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                        'true_category': true_cat,\n",
        "                        'predicted_category': pred_cat,\n",
        "                        'uniq_id': row['uniq_id'],\n",
        "                        'product_name': row['product_name'],\n",
        "                        'keywords': row['keywords'],\n",
        "                        'error_count': error_count\n",
        "                    }])], ignore_index=True)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    # Save error analysis report\n",
        "    if not error_df.empty:\n",
        "        error_df.to_csv(os.path.join(save_folder, 'classification_errors_report.csv'), index=False)\n",
        "        print(f\"\\n‚úÖ Rapport d'erreurs sauvegard√©: '{save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "        # Afficher un r√©sum√©\n",
        "        print(\"\\nüìä R√âSUM√â DES ERREURS:\")\n",
        "        for _, row in error_df.iterrows():\n",
        "            print(f\"   - {row['true_category']} ‚Üí {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n‚úÖ Aucune erreur de classification trouv√©e\")\n",
        "\n",
        "    return error_df\n",
        "\n",
        "def unified_analysis_pipeline(features, true_labels, df, category_names, model, processor, tokenizer,\n",
        "                             analysis_type=\"both\", n_representatives=3, top_n_errors=5):\n",
        "    \"\"\"\n",
        "    Pipeline unifi√© pour l'analyse des produits repr√©sentatifs et des erreurs de classification.\n",
        "\n",
        "    Args:\n",
        "        features: Caract√©ristiques combin√©es\n",
        "        true_labels: √âtiquettes vraies\n",
        "        df: DataFrame original (should be the valid_df from the main pipeline)\n",
        "        category_names: Noms des cat√©gories\n",
        "        model: Mod√®le CLIP fine-tun√©\n",
        "        processor: Processeur CLIP\n",
        "        tokenizer: Tokenizer CLIP\n",
        "        analysis_type: Type d'analyse (\"representatives\", \"errors\", ou \"both\")\n",
        "        n_representatives: Nombre de produits repr√©sentatifs par cat√©gorie\n",
        "        top_n_errors: Nombre d'erreurs principales √† analyser\n",
        "    \"\"\"\n",
        "\n",
        "    # Cr√©er les dossiers n√©cessaires\n",
        "    category_save_folder = 'category'\n",
        "    error_save_folder = 'error'\n",
        "    os.makedirs(category_save_folder, exist_ok=True)\n",
        "    os.makedirs(error_save_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "    if analysis_type in [\"representatives\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES PRODUITS REPR√âSENTATIFS PAR CAT√âGORIE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Trouver les produits les plus proches des centres de clusters\n",
        "        print(\"\\n‚è≥ Recherche des produits les plus proches des centres de clusters...\")\n",
        "        closest_products = find_closest_to_centers(features, true_labels, df, n_examples=n_representatives)\n",
        "\n",
        "\n",
        "        # Traiter chaque cat√©gorie\n",
        "        unique_labels = np.unique(true_labels)\n",
        "        for cluster_id in unique_labels:\n",
        "            category_name = category_names[cluster_id]\n",
        "            print(f\"\\nüè† Top {n_representatives} produits pour la cat√©gorie '{category_name}':\")\n",
        "\n",
        "            # Cr√©er un dossier pour la cat√©gorie\n",
        "            category_folder = os.path.join(category_save_folder, category_name.replace('/', '_').replace(' ', '_'))\n",
        "            os.makedirs(category_folder, exist_ok=True)\n",
        "\n",
        "            # S√©lectionner les produits pour cette cat√©gorie\n",
        "            category_products = closest_products[closest_products['cluster'] == cluster_id].head(n_representatives)\n",
        "\n",
        "            if category_products.empty:\n",
        "                print(f\"‚ö†Ô∏è Aucun produit trouv√© pour la cat√©gorie '{category_name}'\")\n",
        "                continue\n",
        "\n",
        "            # Traiter chaque produit repr√©sentatif\n",
        "            for idx, row in category_products.iterrows():\n",
        "                print(f\"\\nüîπ Produit: {row['product_name'][:50]}...\")\n",
        "                print(f\"   üìè Distance au centre: {row['distance_to_center']:.4f}\")\n",
        "\n",
        "                try:\n",
        "                    # G√©n√©rer l'analyse d'attention CLIP\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=category_folder # Pass the category-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # G√©n√©rer le diagramme en barres des similarit√©s\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Blues_d\", legend=False)\n",
        "                        plt.title(f\"Scores de similarit√© - {row['product_name'][:50]}...\")\n",
        "                        plt.xlabel(\"Score de similarit√©\")\n",
        "                        plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                        # Ajouter les valeurs aux barres\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(category_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        print(f\"‚úÖ Visualisations sauvegard√©es dans: {category_folder}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erreur lors de l'analyse du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "    if analysis_type in [\"errors\", \"both\"]:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"ANALYSE DES ERREURS DE CLASSIFICATION\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # G√©n√©rer les pr√©dictions par validation crois√©e\n",
        "        pipeline = make_pipeline(\n",
        "            PCA(n_components=0.95, random_state=SEED),\n",
        "            RandomForestClassifier(n_estimators=100, random_state=SEED,\n",
        "                                 max_features='sqrt', bootstrap=True)\n",
        "        )\n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "        pred_labels = cross_val_predict(pipeline, features, true_labels, cv=cv, n_jobs=1)\n",
        "\n",
        "        # Obtenir la matrice de confusion\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "        # Trouver les paires d'erreurs les plus fr√©quentes\n",
        "        error_pairs = []\n",
        "        for i in range(len(category_names)):\n",
        "            for j in range(len(category_names)):\n",
        "                if i != j and cm[i, j] > 0:\n",
        "                    error_pairs.append((i, j, cm[i, j]))\n",
        "\n",
        "        # Trier par nombre d'erreurs\n",
        "        error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "        # Cr√©er le dataframe d'analyse d'erreurs\n",
        "        error_df = pd.DataFrame(columns=['true_category', 'predicted_category', 'uniq_id',\n",
        "                                       'product_name', 'keywords', 'error_count'])\n",
        "\n",
        "        # Traiter les principales erreurs\n",
        "        for true_idx, pred_idx, error_count in error_pairs[:top_n_errors]:\n",
        "            true_cat = category_names[true_idx]\n",
        "            pred_cat = category_names[pred_idx]\n",
        "\n",
        "            print(f\"\\nüî¥ Erreur: '{true_cat}' ‚Üí '{pred_cat}' ({error_count} erreurs)\")\n",
        "\n",
        "            # Obtenir les indices des produits mal class√©s\n",
        "            misclassified_indices = np.where((true_labels == true_idx) & (pred_labels == pred_idx))[0]\n",
        "\n",
        "            if len(misclassified_indices) == 0:\n",
        "                print(\"‚ö†Ô∏è Aucun produit trouv√© pour cette paire d'erreur\")\n",
        "                continue\n",
        "\n",
        "            # Cr√©er un sous-dossier pour ce type d'erreur\n",
        "            error_folder = os.path.join(error_save_folder,\n",
        "                                      f\"{true_cat.replace('/', '_')}_as_{pred_cat.replace('/', '_')}\")\n",
        "            os.makedirs(error_folder, exist_ok=True)\n",
        "\n",
        "            # Traiter chaque produit mal class√©\n",
        "            for idx in misclassified_indices:\n",
        "                row = df.iloc[idx] # Use the input df which should be the valid_df from the main pipeline\n",
        "\n",
        "                try:\n",
        "                    print(f\"   üîç Traitement: {row['product_name'][:50]}...\")\n",
        "\n",
        "                    # G√©n√©rer l'analyse d'attention\n",
        "                    analysis_results = clip_attention_analysis(\n",
        "                        uniq_id=row['uniq_id'],\n",
        "                        df=df, # Pass the input df which should be the valid_df\n",
        "                        model=model,\n",
        "                        processor=processor,\n",
        "                        tokenizer=tokenizer,\n",
        "                        category_folder=error_folder # Pass the error-specific folder\n",
        "                    )\n",
        "\n",
        "                    if analysis_results:\n",
        "                        # G√©n√©rer le diagramme en barres\n",
        "                        plt.figure(figsize=(10, 6))\n",
        "                        keywords_list = list(analysis_results['keyword_similarities'].keys())\n",
        "                        # CORRECTED: Use 'keyword_similarities' (plural)\n",
        "                        scores_list = list(analysis_results['keyword_similarities'].values())\n",
        "\n",
        "                        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list,\n",
        "                                        palette=\"Reds_d\", legend=False)\n",
        "                        plt.title(f\"Erreur: {true_cat} ‚Üí {pred_cat} - {row['product_name'][:30]}...\")\n",
        "                        plt.xlabel(\"Score de similarit√©\")\n",
        "                        plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "                        for i, score in enumerate(scores_list):\n",
        "                            ax.text(score + 0.002, i, f'{score:.4f}', va='center',\n",
        "                                   ha='left', fontsize=10, color='black')\n",
        "\n",
        "                        plt.tight_layout()\n",
        "                        barchart_path = os.path.join(error_folder,\n",
        "                                                   f'keyword_similarity_barchart_{row[\"uniq_id\"]}.png')\n",
        "                        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "\n",
        "                        # Ajouter au rapport d'erreurs\n",
        "                        error_df = pd.concat([error_df, pd.DataFrame([{\n",
        "                            'true_category': true_cat,\n",
        "                            'predicted_category': pred_cat,\n",
        "                            'uniq_id': row['uniq_id'],\n",
        "                            'product_name': row['product_name'],\n",
        "                            'keywords': row['keywords'],\n",
        "                            'error_count': error_count\n",
        "                        }])], ignore_index=True)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erreur lors du traitement du produit {row['uniq_id']}: {str(e)}\")\n",
        "\n",
        "        # Sauvegarder le rapport d'erreurs\n",
        "        if not error_df.empty:\n",
        "            error_df.to_csv(os.path.join(error_save_folder, 'classification_errors_report.csv'), index=False)\n",
        "            print(f\"\\n‚úÖ Rapport d'erreurs sauvegard√©: '{error_save_folder}/classification_errors_report.csv'\")\n",
        "\n",
        "            # Afficher le r√©sum√©\n",
        "            print(\"\\nüìä R√âSUM√â DES ERREURS:\")\n",
        "            for _, row in error_df.iterrows():\n",
        "                print(f\"   - {row['true_category']} ‚Üí {row['predicted_category']}: \"\n",
        "                      f\"{row['product_name'][:30]}...\")\n",
        "        else:\n",
        "            print(\"\\n‚úÖ Aucune erreur de classification trouv√©e\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ANALYSE TERMIN√âE AVEC SUCC√àS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "# Cr√©er les dossier au d√©but de l'ex√©cution du pipeline\n",
        "os.makedirs('result', exist_ok=True)\n",
        "print(\"‚úÖ Created 'result' folder.\")\n",
        "os.makedirs('category', exist_ok=True)\n",
        "print(\"‚úÖ Created 'category' folder.\")\n",
        "os.makedirs('error', exist_ok=True)\n",
        "print(\"‚úÖ Created 'error' folder.\")\n",
        "os.makedirs('training_analysis', exist_ok=True)\n",
        "print(\"‚úÖ Created 'training_analysis' folder.\")\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    # Tracer les courbes d'apprentissage\n",
        "    print(\"\\nüìä Plotting training curves...\")\n",
        "    # Correct the parameter name to save_path\n",
        "    summary_df = plot_training_curves(training_history, save_path=\"result/training_analysis\")\n",
        "\n",
        "    # Afficher le r√©sum√© des m√©triques finales\n",
        "    print(\"\\nüìä FINAL METRICS SUMMARY:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Analyser l'overfitting\n",
        "    accuracy_gap = summary_df[summary_df['Metric'] == 'Accuracy']['Gap'].values[0]\n",
        "    if accuracy_gap > 0.1:\n",
        "        print(f\"\\n‚ö†Ô∏è  WARNING: Potential overfitting detected! Accuracy gap: {accuracy_gap:.4f}\")\n",
        "    elif accuracy_gap > 0.05:\n",
        "        print(f\"\\n‚ÑπÔ∏è  Moderate overfitting detected. Accuracy gap: {accuracy_gap:.4f}\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ Good generalization. Accuracy gap: {accuracy_gap:.4f}\")\n",
        "\n",
        "    # Le reste du code reste inchang√©...\n",
        "    categories_encoded, category_names = pd.factorize(df['main_category'])\n",
        "    print(\"\\nüîç Extracting features...\")\n",
        "    text_features = extract_text_features(df, model, tokenizer)\n",
        "    image_features, valid_df = extract_image_features(df, model, processor, max_size=128)\n",
        "    valid_categories = categories_encoded[valid_df.index]\n",
        "    combined_features = combine_features(text_features[valid_df.index], image_features, alpha=0.6)\n",
        "\n",
        "    print(\"\\nüìä Evaluating modalities...\")\n",
        "    results_df, true_labels_cv, pred_labels_cv = compare_modalities(df, text_features, image_features, combined_features, categories_encoded, valid_df, valid_categories, save_folder=\"result\")\n",
        "\n",
        "    print(\"\\nüìä Generating visualizations...\")\n",
        "    # Explicitly call with correct parameter name\n",
        "    print(\"Calling plot_confusion_matrix with save_path='result'\")\n",
        "    plot_confusion_matrix(combined_features, valid_categories, category_names, save_path=\"result\")\n",
        "\n",
        "    print(\"Calling plot_tsne with save_path='result'\")\n",
        "    plot_tsne(combined_features, valid_categories, category_names, save_path=\"result\")\n",
        "\n",
        "    print(\"\\nüìä Analyzing classification errors...\")\n",
        "    # Pass the true and predicted labels from cross-validation to the error analysis function\n",
        "    # The error was likely here, passing the wrong arguments.\n",
        "    # We need to pass the valid_categories (true labels for the processed data)\n",
        "    # and the predicted labels from the cross-validation on the combined features.\n",
        "    error_report = analyze_classification_errors(\n",
        "        combined_features,   # Features used for classification (for indexing)\n",
        "        valid_categories,    # True labels for the processed data\n",
        "        valid_df,            # Original DataFrame (for product info)\n",
        "        category_names,      # List of category names\n",
        "        model,               # Fine-tuned CLIP model\n",
        "        processor,           # CLIP processor\n",
        "        tokenizer,           # CLIP tokenizer\n",
        "        top_n_errors=5,\n",
        "        n_splits=5,\n",
        "        save_folder=\"error\"\n",
        "    )\n",
        "    print(\"\\n‚úÖ Error analysis completed\")\n",
        "\n",
        "    print(\"\\nüìä Analyzing representatives and errors...\")\n",
        "    # Utilisation de la fonction unifi√©e\n",
        "    # The unified_analysis_pipeline also needs the correct true labels (valid_categories)\n",
        "    # and the valid_df (processed dataframe)\n",
        "    unified_analysis_pipeline(\n",
        "        features=combined_features,\n",
        "        true_labels=valid_categories,\n",
        "        df=valid_df,\n",
        "        category_names=category_names,\n",
        "        model=model,\n",
        "        processor=processor,\n",
        "        tokenizer=tokenizer,\n",
        "        analysis_type=\"both\",  # \"representatives\", \"errors\", ou \"both\"\n",
        "        n_representatives=3,\n",
        "        top_n_errors=5\n",
        "    )\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    torch.cuda.empty_cache()\n",
        "    import gc\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "cycvUxg049om"
      },
      "id": "cycvUxg049om",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06335939"
      },
      "source": [
        "# Specify the product unique ID for attention analysis\n",
        "product_uniq_id_to_analyze = '1120bc768623572513df956172ffefeb'\n",
        "\n",
        "# Find the product in the DataFrame\n",
        "product_row = df[df['uniq_id'] == product_uniq_id_to_analyze]\n",
        "\n",
        "if not product_row.empty:\n",
        "    print(f\"‚úÖ Found product with uniq_id: {product_uniq_id_to_analyze}\")\n",
        "    # Specify a folder for this specific analysis\n",
        "    analysis_folder = \"attention_analysis\"\n",
        "    os.makedirs(analysis_folder, exist_ok=True)\n",
        "\n",
        "    # Call the attention analysis function\n",
        "    attention_results = clip_attention_analysis(\n",
        "        uniq_id=product_uniq_id_to_analyze,\n",
        "        df=df,\n",
        "        model=model,\n",
        "        processor=processor,\n",
        "        tokenizer=tokenizer,\n",
        "        category_folder=analysis_folder # Pass the analysis folder\n",
        "    )\n",
        "\n",
        "    if attention_results:\n",
        "        print(f\"\\n‚úÖ Attention analysis completed for {product_uniq_id_to_analyze}. Results saved in '{analysis_folder}' folder.\")\n",
        "\n",
        "        # Generate and save the keyword similarity bar chart\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        keywords_list = list(attention_results['keyword_similarities'].keys())\n",
        "        scores_list = list(attention_results['keyword_similarities'].values())\n",
        "\n",
        "        ax = sns.barplot(x=scores_list, y=keywords_list, hue=keywords_list, palette=\"Blues_d\", legend=False)\n",
        "        plt.title(f\"Scores de similarit√© des mots-cl√©s - {product_row['product_name'].iloc[0][:50]}...\")\n",
        "        plt.xlabel(\"Score de similarit√©\")\n",
        "        plt.ylabel(\"Mots-cl√©s\")\n",
        "\n",
        "        # Ajouter les valeurs au bout des barres\n",
        "        for i, score in enumerate(scores_list):\n",
        "            ax.text(score + 0.002, i, f'{score:.4f}', va='center', ha='left', fontsize=10, color='black')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        barchart_path = os.path.join(analysis_folder, f'keyword_similarity_barchart_{product_uniq_id_to_analyze}.png')\n",
        "        plt.savefig(barchart_path, dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(f\"   ‚úÖ Diagramme en barres sauvegard√©: {barchart_path}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"‚ùå Attention analysis failed for {product_uniq_id_to_analyze}.\")\n",
        "else:\n",
        "    print(f\"‚ùå Product with uniq_id '{product_uniq_id_to_analyze}' not found in the DataFrame.\")"
      ],
      "id": "06335939",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dccf28c"
      },
      "source": [
        "import torch\n",
        "from transformers import CLIPModel, CLIPTokenizer, CLIPProcessor\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "# Ensure the CLIPForClassification class is defined (copying from a previous cell for clarity)\n",
        "# In a real notebook, you would just need to ensure the cell defining this class has been run.\n",
        "class CLIPForClassification(CLIPModel):\n",
        "    def __init__(self, config, num_labels):\n",
        "        super().__init__(config)\n",
        "        self.clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\") # Use the same base model name\n",
        "        self.classifier = nn.Linear(config.projection_dim * 2, num_labels)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, pixel_values, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.clip(pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = torch.cat((outputs.image_embeds, outputs.text_embeds), dim=-1)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return type('Output', (), {\n",
        "            'loss': loss,\n",
        "            'logits': logits,\n",
        "            'image_embeds': outputs.image_embeds,\n",
        "            'text_embeds': outputs.text_embeds\n",
        "        })()\n",
        "\n",
        "def load_finetuned_clip_model(pth_path, num_labels, device):\n",
        "    \"\"\"\n",
        "    Loads the fine-tuned CLIPForClassification model from a .pth state_dict file.\n",
        "    Handles the mismatched keys by loading relevant parts into the model's components.\n",
        "    \"\"\"\n",
        "    # Initialize the model architecture\n",
        "    # Ensure you use the same config and num_labels as during training\n",
        "    config = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").config # Use the same base model name\n",
        "    model = CLIPForClassification(config, num_labels=num_labels).to(device)\n",
        "\n",
        "    # Load the state dictionary\n",
        "    state_dict = torch.load(pth_path, map_location=device)\n",
        "\n",
        "    # Create a new state_dict that matches the CLIPForClassification structure\n",
        "    # This requires knowing the keys saved in the .pth file.\n",
        "    # Based on the error message, the .pth contains the full CLIPModel state_dict.\n",
        "    # We need to load the 'clip' and 'classifier' parts.\n",
        "    model_state_dict = model.state_dict()\n",
        "    new_state_dict = {}\n",
        "\n",
        "    # Manually copy keys for the 'clip' part\n",
        "    # The keys in the loaded state_dict for the base CLIP model don't have the 'clip.' prefix.\n",
        "    # We need to add it to match the keys in model.state_dict()\n",
        "    for k, v in state_dict.items():\n",
        "        if k in model_state_dict:\n",
        "             new_state_dict[k] = v # This handles the classifier keys\n",
        "        elif 'clip.' + k in model_state_dict:\n",
        "             new_state_dict['clip.' + k] = v # This handles the base CLIP model keys\n",
        "\n",
        "    # Load the modified state dictionary into the model\n",
        "    # Use strict=False to ignore keys in model_state_dict that are not in new_state_dict (e.g., logit_scale)\n",
        "    # and keys in new_state_dict that are not in model_state_dict (shouldn't happen if we copied correctly).\n",
        "    # Report missing and unexpected keys for debugging if needed.\n",
        "    load_result = model.load_state_dict(new_state_dict, strict=False)\n",
        "\n",
        "    print(f\"‚úÖ Model loaded successfully from {pth_path}\")\n",
        "    print(f\"Missing keys: {load_result.missing_keys}\")\n",
        "    print(f\"Unexpected keys: {load_result.unexpected_keys}\")\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage (you need to define num_labels based on your training data)\n",
        "# Let's assume num_labels is the number of unique categories in your training data.\n",
        "# You would need to get this value from your original data loading step.\n",
        "# For demonstration, let's assume you know the number of categories.\n",
        "# In a real scenario, you might save the number of labels during training or reload the data.\n",
        "# For now, replace 'YOUR_NUMBER_OF_LABELS' with the actual number of unique categories.\n",
        "# You can get this from the 'category_names' variable after running the data loading cell.\n",
        "\n",
        "# Assuming 'category_names' is available from previous execution\n",
        "if 'category_names' in locals():\n",
        "    num_labels = len(category_names)\n",
        "    print(f\"Detected {num_labels} labels from previous execution.\")\n",
        "    try:\n",
        "        finetuned_model = load_finetuned_clip_model(\n",
        "            pth_path=\"new_clip_product_classifier.pth\",\n",
        "            num_labels=num_labels,\n",
        "            device=device # Use the device defined in the first cell\n",
        "        )\n",
        "        print(\"‚úÖ Fine-tuned model loaded for inference.\")\n",
        "        # You can now use 'finetuned_model' for predictions or feature extraction\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå Error: 'new_clip_product_classifier.pth' not found. Please run the fine-tuning cell first.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An error occurred during model loading: {str(e)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è 'category_names' variable not found. Please run the data loading cell (Cell 2) first to define it.\")\n",
        "    print(\"You will need to manually set 'num_labels' or ensure 'category_names' is available before running this cell.\")"
      ],
      "id": "0dccf28c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}